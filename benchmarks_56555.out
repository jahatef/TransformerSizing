1.13.1 

[2023-12-01 16:08:48,368] [INFO] [distributed.py:36:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...
[2023-12-01 16:08:48,833] [INFO] [distributed.py:83:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=26.0.154.86, master_port=6000
[2023-12-01 16:08:48,834] [INFO] [distributed.py:46:init_distributed] Initializing torch distributed with backend: nccl
[2023-12-01 16:08:50,103] [INFO] [checkpointing.py:223:model_parallel_cuda_manual_seed] > initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234
num_attention_heads: 128, hidden_size: 16384, train_micro_batch_size_per_gpu: 4, tensor_mp_size: 1, pipeline_mp_size: 1, dp_size: 1


Actual
------
QKV Transform: 2.0957372188568115
Flash: 0.02521038055419922
Attention linproj: 0.02225780487060547
QKV Transform: 0.050678253173828125
Flash: 0.010976791381835938
Attention linproj: 0.016387224197387695
QKV Transform: 0.052136898040771484
Flash: 0.010479450225830078
Attention linproj: 0.01639842987060547
QKV Transform: 0.050913333892822266
Flash: 0.010759830474853516
Attention linproj: 0.016470909118652344
QKV Transform: 0.05108785629272461
Flash: 0.010709047317504883
Attention linproj: 0.016503572463989258
QKV Transform: 0.05082893371582031
Flash: 0.010677099227905273
Attention linproj: 0.016787290573120117
QKV Transform: 0.0512850284576416
Flash: 0.011601924896240234
Attention linproj: 0.016866207122802734
QKV Transform: 0.051273345947265625
Flash: 0.010557889938354492
Attention linproj: 0.01694798469543457
QKV Transform: 0.051444292068481445
Flash: 0.011542320251464844
Attention linproj: 0.01688361167907715
QKV Transform: 0.051192283630371094
Flash: 0.010718107223510742
Attention linproj: 0.0169525146484375
QKV Transform: 0.05238151550292969
Flash: 0.010601282119750977
Attention linproj: 0.01679825782775879
QKV Transform: 0.051753997802734375
Flash: 0.011256694793701172
Attention linproj: 0.016534090042114258
QKV Transform: 0.05145454406738281
Flash: 0.011327266693115234
Attention linproj: 0.016522645950317383
QKV Transform: 0.05163288116455078
Flash: 0.01123666763305664
Attention linproj: 0.016798019409179688
QKV Transform: 0.0517117977142334
Flash: 0.011168718338012695
Attention linproj: 0.016806840896606445
QKV Transform: 0.05184125900268555
Flash: 0.011083126068115234
Attention linproj: 0.016866207122802734
QKV Transform: 0.05187344551086426
Flash: 0.011126518249511719
Attention linproj: 0.016916513442993164
QKV Transform: 0.05176091194152832
Flash: 0.011257410049438477
Attention linproj: 0.01684856414794922
QKV Transform: 0.05141091346740723
Flash: 0.010455846786499023
Attention linproj: 0.01662611961364746
QKV Transform: 0.0516817569732666
Flash: 0.01220393180847168
Attention linproj: 0.016506195068359375
QKV Transform: 0.05130910873413086
Flash: 0.010419607162475586
Attention linproj: 0.01656794548034668
QKV Transform: 0.05105996131896973
Flash: 0.011314630508422852
Attention linproj: 0.016809701919555664
QKV Transform: 0.05182337760925293
Flash: 0.011237382888793945
Attention linproj: 0.017141342163085938
QKV Transform: 0.052167654037475586
Flash: 0.010799646377563477
Attention linproj: 0.016948938369750977
QKV Transform: 0.05160951614379883
Flash: 0.011343955993652344
Attention linproj: 0.016885757446289062
QKV Transform: 0.051619768142700195
Flash: 0.011284112930297852
Attention linproj: 0.01678466796875
QKV Transform: 0.05180835723876953
Flash: 0.011106252670288086
Attention linproj: 0.017418622970581055
QKV Transform: 0.05141949653625488
Flash: 0.011353731155395508
Attention linproj: 0.016577959060668945
QKV Transform: 0.0513758659362793
Flash: 0.01130986213684082
Attention linproj: 0.01700758934020996
QKV Transform: 0.05158877372741699
Flash: 0.01080179214477539
Attention linproj: 0.01706218719482422
QKV Transform: 0.05220293998718262
Flash: 0.010810613632202148
Attention linproj: 0.01699090003967285
QKV Transform: 0.05172109603881836
Flash: 0.011292695999145508
Attention linproj: 0.01686692237854004
QKV Transform: 0.05189371109008789
Flash: 0.011084556579589844
Attention linproj: 0.01657867431640625
QKV Transform: 0.05166006088256836
Flash: 0.011129140853881836
Attention linproj: 0.016543865203857422
QKV Transform: 0.05199909210205078
Flash: 0.0109100341796875
Attention linproj: 0.01681971549987793
QKV Transform: 0.05237984657287598
Flash: 0.010672569274902344
Attention linproj: 0.017199277877807617
QKV Transform: 0.05241894721984863
Flash: 0.011716842651367188
Attention linproj: 0.017075538635253906
QKV Transform: 0.05161905288696289
Flash: 0.011238813400268555
Attention linproj: 0.01680469512939453
QKV Transform: 0.05163431167602539
Flash: 0.012304067611694336
Attention linproj: 0.01663517951965332
QKV Transform: 0.05190563201904297
Flash: 0.010949850082397461
Attention linproj: 0.0165250301361084
QKV Transform: 0.051603078842163086
Flash: 0.01118612289428711
Attention linproj: 0.016573429107666016
QKV Transform: 0.0515131950378418
Flash: 0.011138916015625
Attention linproj: 0.01722264289855957
QKV Transform: 0.05243396759033203
Flash: 0.011702775955200195
Attention linproj: 0.017174959182739258
QKV Transform: 0.05190873146057129
Flash: 0.011087894439697266
Attention linproj: 0.016881704330444336
QKV Transform: 0.05130434036254883
Flash: 0.011524438858032227
Attention linproj: 0.01653003692626953
QKV Transform: 0.05171918869018555
Flash: 0.011069297790527344
Attention linproj: 0.01655411720275879
QKV Transform: 0.051543474197387695
Flash: 0.011315345764160156
Attention linproj: 0.016570329666137695
QKV Transform: 0.052702903747558594
Flash: 0.010507345199584961
Attention linproj: 0.01681208610534668
QKV Transform: 0.051732540130615234
Flash: 0.011221170425415039
Attention linproj: 0.016860246658325195
QKV Transform: 0.05194902420043945
Flash: 0.011110305786132812
Attention linproj: 0.016559123992919922
QKV Transform: 0.05208730697631836
Flash: 0.010803461074829102
Attention linproj: 0.01657390594482422
QKV Transform: 0.051671743392944336
Flash: 0.013233184814453125
Attention linproj: 0.01697826385498047
QKV Transform: 0.051520586013793945
Flash: 0.011162519454956055
Attention linproj: 0.01689887046813965
QKV Transform: 0.05153155326843262
Flash: 0.0113067626953125
Attention linproj: 0.01679396629333496
QKV Transform: 0.05174875259399414
Flash: 0.01116633415222168
Attention linproj: 0.01655411720275879
QKV Transform: 0.05177164077758789
Flash: 0.011072874069213867
Attention linproj: 0.016544818878173828
QKV Transform: 0.05185055732727051
Flash: 0.011100530624389648
Attention linproj: 0.016806602478027344
QKV Transform: 0.05192685127258301
Flash: 0.011209964752197266
Attention linproj: 0.01716899871826172
QKV Transform: 0.05220365524291992
Flash: 0.010771036148071289
Attention linproj: 0.016982555389404297
QKV Transform: 0.052031755447387695
Flash: 0.010953664779663086
Attention linproj: 0.016918182373046875
QKV Transform: 0.05190634727478027
Flash: 0.011092901229858398
Attention linproj: 0.01687479019165039
QKV Transform: 0.05265641212463379
Flash: 0.011196613311767578
Attention linproj: 0.016581058502197266
QKV Transform: 0.05179476737976074
Flash: 0.011038541793823242
Attention linproj: 0.01672506332397461
QKV Transform: 0.05211615562438965
Flash: 0.010943412780761719
Attention linproj: 0.017191171646118164
QKV Transform: 0.052561044692993164
Flash: 0.011612653732299805
Attention linproj: 0.017110109329223633
QKV Transform: 0.05227208137512207
Flash: 0.010790109634399414
Attention linproj: 0.016930580139160156
QKV Transform: 0.05186319351196289
Flash: 0.01113581657409668
Attention linproj: 0.016648054122924805
QKV Transform: 0.05179405212402344
Flash: 0.011039257049560547
Attention linproj: 0.016547441482543945
QKV Transform: 0.051819562911987305
Flash: 0.011002540588378906
Attention linproj: 0.016573667526245117
QKV Transform: 0.05113506317138672
Flash: 0.013287782669067383
Attention linproj: 0.0168609619140625
QKV Transform: 0.05173850059509277
Flash: 0.011303424835205078
Attention linproj: 0.01695561408996582
QKV Transform: 0.052286624908447266
Flash: 0.010758399963378906
Attention linproj: 0.01696634292602539
QKV Transform: 0.0516362190246582
Flash: 0.011295557022094727
Attention linproj: 0.01677083969116211
QKV Transform: 0.05180001258850098
Flash: 0.011168718338012695
Attention linproj: 0.016553163528442383
QKV Transform: 0.051740169525146484
Flash: 0.011067628860473633
Attention linproj: 0.016583681106567383
QKV Transform: 0.05181002616882324
Flash: 0.01133418083190918
Attention linproj: 0.016996383666992188
QKV Transform: 0.05179858207702637
Flash: 0.011186838150024414
Attention linproj: 0.016949892044067383
QKV Transform: 0.05172228813171387
Flash: 0.011255025863647461
Attention linproj: 0.01688671112060547
QKV Transform: 0.05173754692077637
Flash: 0.011151790618896484
Attention linproj: 0.016791820526123047
QKV Transform: 0.05154109001159668
Flash: 0.0113067626953125
Attention linproj: 0.01651477813720703
QKV Transform: 0.05161690711975098
Flash: 0.011137723922729492
Attention linproj: 0.016545772552490234
QKV Transform: 0.05178189277648926
Flash: 0.011081695556640625
Attention linproj: 0.016812801361083984
QKV Transform: 0.05187106132507324
Flash: 0.011094808578491211
Attention linproj: 0.0171511173248291
QKV Transform: 0.05196380615234375
Flash: 0.010961532592773438
Attention linproj: 0.016958236694335938
QKV Transform: 0.051753997802734375
Flash: 0.011154890060424805
Attention linproj: 0.016886234283447266
QKV Transform: 0.051743268966674805
Flash: 0.011215686798095703
Attention linproj: 0.016872406005859375
QKV Transform: 0.05170583724975586
Flash: 0.01119375228881836
Attention linproj: 0.01655101776123047
QKV Transform: 0.05177021026611328
Flash: 0.011075258255004883
Attention linproj: 0.0167081356048584
QKV Transform: 0.05193591117858887
Flash: 0.011348485946655273
Attention linproj: 0.01700115203857422
QKV Transform: 0.052002668380737305
Flash: 0.010964393615722656
Attention linproj: 0.016968250274658203
QKV Transform: 0.051687002182006836
Flash: 0.011271238327026367
Attention linproj: 0.016947031021118164
QKV Transform: 0.05120587348937988
Flash: 0.012307882308959961
Attention linproj: 0.016859054565429688
QKV Transform: 0.05162239074707031
Flash: 0.014306783676147461
Attention linproj: 0.016505718231201172
QKV Transform: 0.051415205001831055
Flash: 0.01353311538696289
Attention linproj: 0.016680479049682617
QKV Transform: 0.051029205322265625
Flash: 0.014542579650878906
Attention linproj: 0.016878128051757812
QKV Transform: 0.051633596420288086
Flash: 0.011342525482177734
Attention linproj: 0.016796112060546875
QKV Transform: 0.05152630805969238
Flash: 0.011444091796875
Attention linproj: 0.016512393951416016
QKV Transform: 0.05176138877868652
Flash: 0.0111083984375
Attention linproj: 0.01659250259399414
QKV Transform: 0.05184125900268555
Flash: 0.01114034652709961
Attention linproj: 0.016822338104248047
QKV Transform: 0.051624298095703125
Flash: 0.011429309844970703
Attention linproj: 0.017002105712890625
QKV Transform: 0.05170702934265137
Flash: 0.011289596557617188
Attention linproj: 0.01696491241455078
QKV Transform: 0.051708221435546875
Flash: 0.011315345764160156
Attention linproj: 0.016901731491088867
QKV Transform: 0.05164170265197754
Flash: 0.01130819320678711
Attention linproj: 0.016789674758911133
QKV Transform: 0.05178332328796387
Flash: 0.011118412017822266
Attention linproj: 0.016534805297851562
QKV Transform: 0.05156755447387695
Flash: 0.011260747909545898
Attention linproj: 0.016533374786376953
QKV Transform: 0.05162167549133301
Flash: 0.011284351348876953
Attention linproj: 0.016809701919555664
QKV Transform: 0.051781654357910156
Flash: 0.01134181022644043
Attention linproj: 0.016957998275756836
QKV Transform: 0.05164790153503418
Flash: 0.011304855346679688
Attention linproj: 0.01689004898071289
QKV Transform: 0.05174851417541504
Flash: 0.011186599731445312
Attention linproj: 0.016855716705322266
QKV Transform: 0.05170702934265137
Flash: 0.011211872100830078
Attention linproj: 0.01652359962463379
QKV Transform: 0.05167698860168457
Flash: 0.011121749877929688
Attention linproj: 0.016613245010375977
QKV Transform: 0.05130743980407715
Flash: 0.011139869689941406
Attention linproj: 0.0167236328125
QKV Transform: 0.05185389518737793
Flash: 0.011155843734741211
Attention linproj: 0.017154693603515625
QKV Transform: 0.05213737487792969
Flash: 0.010858535766601562
Attention linproj: 0.0169527530670166
QKV Transform: 0.05181527137756348
Flash: 0.01640176773071289
Attention linproj: 0.01653885841369629
QKV Transform: 0.05173134803771973
Flash: 0.011133193969726562
Attention linproj: 0.016609668731689453
QKV Transform: 0.05193185806274414
Flash: 0.010915756225585938
Attention linproj: 0.016806602478027344
QKV Transform: 0.05169963836669922
Flash: 0.011298656463623047
Attention linproj: 0.017020225524902344
QKV Transform: 0.052024126052856445
Flash: 0.011002063751220703
Attention linproj: 0.01695108413696289
QKV Transform: 0.05183839797973633
Flash: 0.011202812194824219
Attention linproj: 0.016895532608032227
QKV Transform: 0.051850318908691406
Flash: 0.012243270874023438
Attention linproj: 0.016765594482421875
QKV Transform: 0.051766157150268555
Flash: 0.011098384857177734
Attention linproj: 0.016511917114257812
QKV Transform: 0.05127406120300293
Flash: 0.011419296264648438
Attention linproj: 0.01654362678527832
QKV Transform: 0.051518917083740234
Flash: 0.011407852172851562
Attention linproj: 0.016814470291137695
QKV Transform: 0.05187082290649414
Flash: 0.011133909225463867
Attention linproj: 0.017111539840698242
QKV Transform: 0.0521693229675293
Flash: 0.01078033447265625
Attention linproj: 0.01703953742980957
QKV Transform: 0.05194711685180664
Flash: 0.011054515838623047
Attention linproj: 0.01686716079711914
QKV Transform: 0.051702022552490234
Flash: 0.01121664047241211
Attention linproj: 0.016677379608154297
QKV Transform: 0.0520167350769043
Flash: 0.011097192764282227
Attention linproj: 0.0165557861328125
QKV Transform: 0.0514378547668457
Flash: 0.011328935623168945
Attention linproj: 0.016704082489013672
QKV Transform: 0.05150747299194336
Flash: 0.011472702026367188
Attention linproj: 0.016985416412353516
QKV Transform: 0.05190443992614746
Flash: 0.010993719100952148
Attention linproj: 0.016962051391601562
QKV Transform: 0.0515294075012207
Flash: 0.011393308639526367
Attention linproj: 0.01689934730529785
QKV Transform: 0.05134296417236328
Flash: 0.010525941848754883
Attention linproj: 0.01681232452392578
QKV Transform: 0.051419734954833984
Flash: 0.011520624160766602
Attention linproj: 0.01669621467590332
QKV Transform: 0.05146646499633789
Flash: 0.012383699417114258
Attention linproj: 0.016515254974365234
QKV Transform: 0.0513768196105957
Flash: 0.010406732559204102
Attention linproj: 0.016724586486816406
QKV Transform: 0.05167722702026367
Flash: 0.010925531387329102
Attention linproj: 0.017067432403564453
QKV Transform: 0.052484750747680664
Flash: 0.011627912521362305
Attention linproj: 0.01717400550842285
QKV Transform: 0.05205202102661133
Flash: 0.010932207107543945
Attention linproj: 0.01689600944519043
QKV Transform: 0.05155038833618164
Flash: 0.011381149291992188
Attention linproj: 0.016787052154541016
QKV Transform: 0.05139565467834473
Flash: 0.010465383529663086
Attention linproj: 0.016767263412475586
QKV Transform: 0.0515294075012207
Flash: 0.011325836181640625
Attention linproj: 0.01653575897216797
QKV Transform: 0.051460981369018555
Flash: 0.011406660079956055
Attention linproj: 0.016571998596191406
QKV Transform: 0.05115771293640137
Flash: 0.011470794677734375
Attention linproj: 0.0167996883392334
QKV Transform: 0.051642656326293945
Flash: 0.011435270309448242
Attention linproj: 0.016983747482299805
QKV Transform: 0.05189108848571777
Flash: 0.011168956756591797
Attention linproj: 0.016919851303100586
QKV Transform: 0.051712989807128906
Flash: 0.01125645637512207
Attention linproj: 0.016827106475830078
QKV Transform: 0.05150461196899414
Flash: 0.011367559432983398
Attention linproj: 0.016640186309814453
QKV Transform: 0.05178952217102051
Flash: 0.011156558990478516
Attention linproj: 0.016543865203857422
Attention duration (in seconds): 0.0842
Attention throughput (in TFLOP/s): 222.089
MLP_h_4h: 2.2086234092712402
MLP_4h_h: 0.06809353828430176
MLP_h_4h: 0.07111287117004395
MLP_4h_h: 0.06891536712646484
MLP_h_4h: 0.07164764404296875
MLP_4h_h: 0.06876564025878906
MLP_h_4h: 0.07103991508483887
MLP_4h_h: 0.06946277618408203
MLP_h_4h: 0.07176589965820312
MLP_4h_h: 0.0695796012878418
MLP_h_4h: 0.07010865211486816
MLP_4h_h: 0.06937360763549805
MLP_h_4h: 0.07006359100341797
MLP_4h_h: 0.06916213035583496
MLP_h_4h: 0.07135677337646484
MLP_4h_h: 0.0709540843963623
MLP_h_4h: 0.07143950462341309
MLP_4h_h: 0.06992173194885254
MLP_h_4h: 0.07240486145019531
MLP_4h_h: 0.06961774826049805
MLP_h_4h: 0.07042837142944336
MLP_4h_h: 0.06913280487060547
MLP_h_4h: 0.07209038734436035
MLP_4h_h: 0.06883478164672852
MLP_h_4h: 0.0698850154876709
MLP_4h_h: 0.07013535499572754
MLP_h_4h: 0.07183074951171875
MLP_4h_h: 0.06945133209228516
MLP_h_4h: 0.07226300239562988
MLP_4h_h: 0.06864547729492188
MLP_h_4h: 0.06989884376525879
MLP_4h_h: 0.07001566886901855
MLP_h_4h: 0.0719594955444336
MLP_4h_h: 0.06963825225830078
MLP_h_4h: 0.0720052719116211
MLP_4h_h: 0.06955933570861816
MLP_h_4h: 0.07195162773132324
MLP_4h_h: 0.0692739486694336
MLP_h_4h: 0.07205939292907715
MLP_4h_h: 0.06930756568908691
MLP_h_4h: 0.07245707511901855
MLP_4h_h: 0.07019758224487305
MLP_h_4h: 0.07200431823730469
MLP_4h_h: 0.069366455078125
MLP_h_4h: 0.07247805595397949
MLP_4h_h: 0.06938457489013672
MLP_h_4h: 0.06993603706359863
MLP_4h_h: 0.06943106651306152
MLP_h_4h: 0.07310318946838379
MLP_4h_h: 0.06899642944335938
MLP_h_4h: 0.07148575782775879
MLP_4h_h: 0.07048940658569336
MLP_h_4h: 0.07209110260009766
MLP_4h_h: 0.06960296630859375
MLP_h_4h: 0.07250785827636719
MLP_4h_h: 0.06915068626403809
MLP_h_4h: 0.07102036476135254
MLP_4h_h: 0.06928682327270508
MLP_h_4h: 0.07202887535095215
MLP_4h_h: 0.06925010681152344
MLP_h_4h: 0.07271075248718262
MLP_4h_h: 0.06923270225524902
MLP_h_4h: 0.07200169563293457
MLP_4h_h: 0.06939697265625
MLP_h_4h: 0.07210302352905273
MLP_4h_h: 0.06925201416015625
MLP_h_4h: 0.07196331024169922
MLP_4h_h: 0.06935977935791016
MLP_h_4h: 0.0724785327911377
MLP_4h_h: 0.06921505928039551
MLP_h_4h: 0.07108592987060547
MLP_4h_h: 0.06924629211425781
MLP_h_4h: 0.0720210075378418
MLP_4h_h: 0.06919288635253906
MLP_h_4h: 0.07054018974304199
MLP_4h_h: 0.06912851333618164
MLP_h_4h: 0.07107257843017578
MLP_4h_h: 0.06957221031188965
MLP_h_4h: 0.07138848304748535
MLP_4h_h: 0.0690925121307373
MLP_h_4h: 0.07138538360595703
MLP_4h_h: 0.07017827033996582
MLP_h_4h: 0.0723412036895752
MLP_4h_h: 0.06960248947143555
MLP_h_4h: 0.07194876670837402
MLP_4h_h: 0.06926822662353516
MLP_h_4h: 0.07123923301696777
MLP_4h_h: 0.07120656967163086
MLP_h_4h: 0.07205057144165039
MLP_4h_h: 0.07038593292236328
MLP_h_4h: 0.07194280624389648
MLP_4h_h: 0.06906509399414062
MLP_h_4h: 0.06984353065490723
MLP_4h_h: 0.0696401596069336
MLP_h_4h: 0.07241511344909668
MLP_4h_h: 0.06928563117980957
MLP_h_4h: 0.0711979866027832
MLP_4h_h: 0.07042527198791504
MLP_h_4h: 0.07209610939025879
MLP_4h_h: 0.0698232650756836
MLP_h_4h: 0.07114291191101074
MLP_4h_h: 0.06937313079833984
MLP_h_4h: 0.07169699668884277
MLP_4h_h: 0.06983685493469238
MLP_h_4h: 0.07270169258117676
MLP_4h_h: 0.06882834434509277
MLP_h_4h: 0.0705254077911377
MLP_4h_h: 0.06984114646911621
MLP_h_4h: 0.07189369201660156
MLP_4h_h: 0.07015752792358398
MLP_h_4h: 0.07199263572692871
MLP_4h_h: 0.06915068626403809
MLP_h_4h: 0.07165813446044922
MLP_4h_h: 0.06906723976135254
MLP_h_4h: 0.07211041450500488
MLP_4h_h: 0.06928539276123047
MLP_h_4h: 0.07221865653991699
MLP_4h_h: 0.06905651092529297
MLP_h_4h: 0.07205510139465332
MLP_4h_h: 0.06932711601257324
MLP_h_4h: 0.07211685180664062
MLP_4h_h: 0.06913542747497559
MLP_h_4h: 0.07167649269104004
MLP_4h_h: 0.06944394111633301
MLP_h_4h: 0.07218813896179199
MLP_4h_h: 0.06928634643554688
MLP_h_4h: 0.07195305824279785
MLP_4h_h: 0.06929373741149902
MLP_h_4h: 0.07186031341552734
MLP_4h_h: 0.06943416595458984
MLP_h_4h: 0.07170557975769043
MLP_4h_h: 0.06928896903991699
MLP_h_4h: 0.07045435905456543
MLP_4h_h: 0.06936383247375488
MLP_h_4h: 0.07186770439147949
MLP_4h_h: 0.06937050819396973
MLP_h_4h: 0.07063722610473633
MLP_4h_h: 0.06903314590454102
MLP_h_4h: 0.07134366035461426
MLP_4h_h: 0.06960177421569824
MLP_h_4h: 0.07239508628845215
MLP_4h_h: 0.06961488723754883
MLP_h_4h: 0.06991815567016602
MLP_4h_h: 0.06944942474365234
MLP_h_4h: 0.07244658470153809
MLP_4h_h: 0.06969261169433594
MLP_h_4h: 0.0725395679473877
MLP_4h_h: 0.0693216323852539
MLP_h_4h: 0.07166385650634766
MLP_4h_h: 0.06985592842102051
MLP_h_4h: 0.07223010063171387
MLP_4h_h: 0.06930780410766602
MLP_h_4h: 0.07073426246643066
MLP_4h_h: 0.06948113441467285
MLP_h_4h: 0.07238030433654785
MLP_4h_h: 0.0695333480834961
MLP_h_4h: 0.07106661796569824
MLP_4h_h: 0.06927013397216797
MLP_h_4h: 0.07159304618835449
MLP_4h_h: 0.06936240196228027
MLP_h_4h: 0.07247376441955566
MLP_4h_h: 0.06900858879089355
MLP_h_4h: 0.07079482078552246
MLP_4h_h: 0.0690317153930664
MLP_h_4h: 0.07245516777038574
MLP_4h_h: 0.06990766525268555
MLP_h_4h: 0.07215094566345215
MLP_4h_h: 0.06934118270874023
MLP_h_4h: 0.07189106941223145
MLP_4h_h: 0.06932330131530762
MLP_h_4h: 0.07247138023376465
MLP_4h_h: 0.06898617744445801
MLP_h_4h: 0.07168698310852051
MLP_4h_h: 0.07028460502624512
MLP_h_4h: 0.07210516929626465
MLP_4h_h: 0.07007670402526855
MLP_h_4h: 0.07193493843078613
MLP_4h_h: 0.0694131851196289
MLP_h_4h: 0.07169723510742188
MLP_4h_h: 0.06917548179626465
MLP_h_4h: 0.07191205024719238
MLP_4h_h: 0.06940507888793945
MLP_h_4h: 0.07118606567382812
MLP_4h_h: 0.06912660598754883
MLP_h_4h: 0.07181358337402344
MLP_4h_h: 0.07051324844360352
MLP_h_4h: 0.07212281227111816
MLP_4h_h: 0.06923460960388184
MLP_h_4h: 0.0706338882446289
MLP_4h_h: 0.0691683292388916
MLP_h_4h: 0.07187247276306152
MLP_4h_h: 0.06966447830200195
MLP_h_4h: 0.0705878734588623
MLP_4h_h: 0.06991958618164062
MLP_h_4h: 0.07235860824584961
MLP_4h_h: 0.07041049003601074
MLP_h_4h: 0.07192611694335938
MLP_4h_h: 0.06961441040039062
MLP_h_4h: 0.0704798698425293
MLP_4h_h: 0.06912803649902344
MLP_h_4h: 0.0718526840209961
MLP_4h_h: 0.06955170631408691
MLP_h_4h: 0.07059597969055176
MLP_4h_h: 0.06982874870300293
MLP_h_4h: 0.07241988182067871
MLP_4h_h: 0.06937956809997559
MLP_h_4h: 0.07219576835632324
MLP_4h_h: 0.06963419914245605
MLP_h_4h: 0.07048535346984863
MLP_4h_h: 0.06959128379821777
MLP_h_4h: 0.07178425788879395
MLP_4h_h: 0.06958794593811035
MLP_h_4h: 0.07222867012023926
MLP_4h_h: 0.06860184669494629
MLP_h_4h: 0.06968283653259277
MLP_4h_h: 0.06984543800354004
MLP_h_4h: 0.07253098487854004
MLP_4h_h: 0.06905770301818848
MLP_h_4h: 0.07149338722229004
MLP_4h_h: 0.07047080993652344
MLP_h_4h: 0.0719902515411377
MLP_4h_h: 0.06923246383666992
MLP_h_4h: 0.07205653190612793
MLP_4h_h: 0.0690760612487793
MLP_h_4h: 0.07178115844726562
MLP_4h_h: 0.06938624382019043
MLP_h_4h: 0.07215428352355957
MLP_4h_h: 0.06916427612304688
MLP_h_4h: 0.07207560539245605
MLP_4h_h: 0.06923842430114746
MLP_h_4h: 0.07209420204162598
MLP_4h_h: 0.06979823112487793
MLP_h_4h: 0.0727224349975586
MLP_4h_h: 0.06946635246276855
MLP_h_4h: 0.07107973098754883
MLP_4h_h: 0.07126855850219727
MLP_h_4h: 0.07210326194763184
MLP_4h_h: 0.06949734687805176
MLP_h_4h: 0.07319045066833496
MLP_4h_h: 0.07045841217041016
MLP_h_4h: 0.07201814651489258
MLP_4h_h: 0.06912684440612793
MLP_h_4h: 0.07204532623291016
MLP_4h_h: 0.06907320022583008
MLP_h_4h: 0.0719137191772461
MLP_4h_h: 0.06927990913391113
MLP_h_4h: 0.07210135459899902
MLP_4h_h: 0.06977224349975586
MLP_h_4h: 0.07209134101867676
MLP_4h_h: 0.06947731971740723
MLP_h_4h: 0.0720510482788086
MLP_4h_h: 0.069122314453125
MLP_h_4h: 0.07205486297607422
MLP_4h_h: 0.0692911148071289
MLP_h_4h: 0.0720207691192627
MLP_4h_h: 0.06909680366516113
MLP_h_4h: 0.07204747200012207
MLP_4h_h: 0.06939101219177246
MLP_h_4h: 0.07206583023071289
MLP_4h_h: 0.06909656524658203
MLP_h_4h: 0.07208895683288574
MLP_4h_h: 0.0692596435546875
MLP_h_4h: 0.0718376636505127
MLP_4h_h: 0.06907320022583008
MLP_h_4h: 0.07095098495483398
MLP_4h_h: 0.06963539123535156
MLP_h_4h: 0.0720982551574707
MLP_4h_h: 0.06931734085083008
MLP_h_4h: 0.07105016708374023
MLP_4h_h: 0.0692286491394043
MLP_h_4h: 0.07182526588439941
MLP_4h_h: 0.06999492645263672
MLP_h_4h: 0.07123970985412598
MLP_4h_h: 0.06907868385314941
MLP_h_4h: 0.07063531875610352
MLP_4h_h: 0.06923770904541016
MLP_h_4h: 0.07128310203552246
MLP_4h_h: 0.06910085678100586
MLP_h_4h: 0.07071089744567871
MLP_4h_h: 0.06891274452209473
MLP_h_4h: 0.07070350646972656
MLP_4h_h: 0.069091796875
MLP_h_4h: 0.07159256935119629
MLP_4h_h: 0.0697317123413086
MLP_h_4h: 0.07186341285705566
MLP_4h_h: 0.06981086730957031
MLP_h_4h: 0.07178735733032227
MLP_4h_h: 0.06975030899047852
MLP_h_4h: 0.07181477546691895
MLP_4h_h: 0.0699608325958252
MLP_h_4h: 0.07181620597839355
MLP_4h_h: 0.06995344161987305
MLP_h_4h: 0.07184791564941406
MLP_4h_h: 0.0694119930267334
MLP_h_4h: 0.07185602188110352
MLP_4h_h: 0.06948471069335938
MLP_h_4h: 0.07187032699584961
MLP_4h_h: 0.0695950984954834
MLP_h_4h: 0.07189726829528809
MLP_4h_h: 0.06944823265075684
MLP duration (in seconds): 0.1414
MLP throughput (in TFLOP/s): 248.854
LN1: 0.00538182258605957
QKV Transform: 0.05148482322692871
Flash: 0.0078105926513671875
Attention linproj: 0.01678323745727539
Post-attention Dropout: 0.07263016700744629
Post-attention residual: 0.004481792449951172
LN2: 0.0007414817810058594
MLP_h_4h: 0.06799530982971191
MLP_4h_h: 0.06854605674743652
Post-MLP residual: 0.003475666046142578
Attention layer time: 0.30037736892700195
LN1: 0.0007178783416748047
QKV Transform: 0.05190849304199219
Flash: 0.008511543273925781
Attention linproj: 0.016796588897705078
Post-attention Dropout: 0.0018274784088134766
Post-attention residual: 0.0006036758422851562
LN2: 0.0006785392761230469
MLP_h_4h: 0.07147979736328125
MLP_4h_h: 0.06931877136230469
Post-MLP residual: 0.0018575191497802734
Attention layer time: 0.22457170486450195
LN1: 0.0007178783416748047
QKV Transform: 0.052504777908325195
Flash: 0.010503053665161133
Attention linproj: 0.01688551902770996
Post-attention Dropout: 0.0018513202667236328
Post-attention residual: 0.0006260871887207031
LN2: 0.0006954669952392578
MLP_h_4h: 0.0713963508605957
MLP_4h_h: 0.0689997673034668
Post-MLP residual: 0.0018470287322998047
Attention layer time: 0.2269153594970703
LN1: 0.0007195472717285156
QKV Transform: 0.05192089080810547
Flash: 0.008452653884887695
Attention linproj: 0.016683101654052734
Post-attention Dropout: 0.0018684864044189453
Post-attention residual: 0.0006191730499267578
LN2: 0.0006952285766601562
MLP_h_4h: 0.07149887084960938
MLP_4h_h: 0.0690605640411377
Post-MLP residual: 0.0018529891967773438
Attention layer time: 0.22423863410949707
LN1: 0.0007154941558837891
QKV Transform: 0.053087711334228516
Flash: 0.008141279220581055
Attention linproj: 0.017031431198120117
Post-attention Dropout: 0.0018634796142578125
Post-attention residual: 0.0006210803985595703
LN2: 0.0006947517395019531
MLP_h_4h: 0.07205963134765625
MLP_4h_h: 0.06965494155883789
Post-MLP residual: 0.0018551349639892578
Attention layer time: 0.22660493850708008
LN1: 0.0007140636444091797
QKV Transform: 0.0515592098236084
Flash: 0.00818943977355957
Attention linproj: 0.0166623592376709
Post-attention Dropout: 0.001871347427368164
Post-attention residual: 0.0006194114685058594
LN2: 0.0006935596466064453
MLP_h_4h: 0.07074975967407227
MLP_4h_h: 0.06925249099731445
Post-MLP residual: 0.001842498779296875
Attention layer time: 0.2230069637298584
LN1: 0.0007128715515136719
QKV Transform: 0.05311083793640137
Flash: 0.008398056030273438
Attention linproj: 0.016814231872558594
Post-attention Dropout: 0.001855611801147461
Post-attention residual: 0.0006237030029296875
LN2: 0.0006990432739257812
MLP_h_4h: 0.07134389877319336
MLP_4h_h: 0.06928443908691406
Post-MLP residual: 0.0018589496612548828
Attention layer time: 0.22556853294372559
LN1: 0.0007157325744628906
QKV Transform: 0.05247902870178223
Flash: 0.008456230163574219
Attention linproj: 0.016882658004760742
Post-attention Dropout: 0.0018591880798339844
Post-attention residual: 0.0006268024444580078
LN2: 0.0006952285766601562
MLP_h_4h: 0.07148456573486328
MLP_4h_h: 0.06878852844238281
Post-MLP residual: 0.0018534660339355469
Attention layer time: 0.22470974922180176
LN1: 0.0007138252258300781
QKV Transform: 0.05149722099304199
Flash: 0.008195877075195312
Attention linproj: 0.01664876937866211
Post-attention Dropout: 0.0018494129180908203
Post-attention residual: 0.0006220340728759766
LN2: 0.0006921291351318359
MLP_h_4h: 0.07146072387695312
MLP_4h_h: 0.07038426399230957
Post-MLP residual: 0.0018737316131591797
Attention layer time: 0.22480154037475586
LN1: 0.0007152557373046875
QKV Transform: 0.05238795280456543
Flash: 0.008269309997558594
Attention linproj: 0.016687870025634766
Post-attention Dropout: 0.0018603801727294922
Post-attention residual: 0.0006191730499267578
LN2: 0.0006935596466064453
MLP_h_4h: 0.0716853141784668
MLP_4h_h: 0.0692286491394043
Post-MLP residual: 0.001852273941040039
Attention layer time: 0.2248530387878418
LN1: 0.0007143020629882812
QKV Transform: 0.052498579025268555
Flash: 0.00836801528930664
Attention linproj: 0.01689600944519043
Post-attention Dropout: 0.0018591880798339844
Post-attention residual: 0.0006222724914550781
LN2: 0.0006949901580810547
MLP_h_4h: 0.0719294548034668
MLP_4h_h: 0.06971955299377441
Post-MLP residual: 0.0018720626831054688
Attention layer time: 0.22603702545166016
LN1: 0.0007128715515136719
QKV Transform: 0.0518488883972168
Flash: 0.007950782775878906
Attention linproj: 0.016828298568725586
Post-attention Dropout: 0.0018663406372070312
Post-attention residual: 0.0006215572357177734
LN2: 0.0006964206695556641
MLP_h_4h: 0.07164883613586426
MLP_4h_h: 0.06963562965393066
Post-MLP residual: 0.001844644546508789
Attention layer time: 0.2245192527770996
LN1: 0.0007162094116210938
QKV Transform: 0.05244755744934082
Flash: 0.007998228073120117
Attention linproj: 0.016672372817993164
Post-attention Dropout: 0.0018558502197265625
Post-attention residual: 0.0006210803985595703
LN2: 0.0006964206695556641
MLP_h_4h: 0.07141733169555664
MLP_4h_h: 0.06946539878845215
Post-MLP residual: 0.0018715858459472656
Attention layer time: 0.224639892578125
LN1: 0.0007200241088867188
QKV Transform: 0.05272793769836426
Flash: 0.00798344612121582
Attention linproj: 0.016815900802612305
Post-attention Dropout: 0.0018625259399414062
Post-attention residual: 0.0006222724914550781
LN2: 0.0006949901580810547
MLP_h_4h: 0.0711514949798584
MLP_4h_h: 0.06883645057678223
Post-MLP residual: 0.001836538314819336
Attention layer time: 0.22411251068115234
LN1: 0.0007150173187255859
QKV Transform: 0.051672935485839844
Flash: 0.008040666580200195
Attention linproj: 0.01685476303100586
Post-attention Dropout: 0.001857757568359375
Post-attention residual: 0.0006194114685058594
LN2: 0.0006978511810302734
MLP_h_4h: 0.07092761993408203
MLP_4h_h: 0.06952714920043945
Post-MLP residual: 0.001844644546508789
Attention layer time: 0.22361350059509277
LN1: 0.0007114410400390625
QKV Transform: 0.05189704895019531
Flash: 0.007866859436035156
Attention linproj: 0.016823291778564453
Post-attention Dropout: 0.001859426498413086
Post-attention residual: 0.0006210803985595703
LN2: 0.0006933212280273438
MLP_h_4h: 0.0722053050994873
MLP_4h_h: 0.06912040710449219
Post-MLP residual: 0.0018434524536132812
Attention layer time: 0.22450542449951172
LN1: 0.0007157325744628906
QKV Transform: 0.05318331718444824
Flash: 0.008651971817016602
Attention linproj: 0.01691889762878418
Post-attention Dropout: 0.0018558502197265625
Post-attention residual: 0.0006210803985595703
LN2: 0.000698089599609375
MLP_h_4h: 0.07201838493347168
MLP_4h_h: 0.07008218765258789
Post-MLP residual: 0.001865386962890625
Attention layer time: 0.2274794578552246
LN1: 0.0007319450378417969
QKV Transform: 0.052460670471191406
Flash: 0.008235454559326172
Attention linproj: 0.016839981079101562
Post-attention Dropout: 0.0018563270568847656
Post-attention residual: 0.0006198883056640625
LN2: 0.0006961822509765625
MLP_h_4h: 0.07050204277038574
MLP_4h_h: 0.06871533393859863
Post-MLP residual: 0.0018436908721923828
Attention layer time: 0.22338390350341797
LN1: 0.0007112026214599609
QKV Transform: 0.05132484436035156
Flash: 0.008378028869628906
Attention linproj: 0.01663994789123535
Post-attention Dropout: 0.0018496513366699219
Post-attention residual: 0.0006208419799804688
LN2: 0.00069427490234375
MLP_h_4h: 0.07083821296691895
MLP_4h_h: 0.06921935081481934
Post-MLP residual: 0.0018477439880371094
Attention layer time: 0.22297930717468262
LN1: 0.0007307529449462891
QKV Transform: 0.05265998840332031
Flash: 0.008080005645751953
Attention linproj: 0.01664900779724121
Post-attention Dropout: 0.0018663406372070312
Post-attention residual: 0.0006194114685058594
LN2: 0.0006945133209228516
MLP_h_4h: 0.07159757614135742
MLP_4h_h: 0.06925463676452637
Post-MLP residual: 0.001856088638305664
Attention layer time: 0.22486591339111328
LN1: 0.0007159709930419922
QKV Transform: 0.05260610580444336
Flash: 0.008292198181152344
Attention linproj: 0.01700878143310547
Post-attention Dropout: 0.0018641948699951172
Post-attention residual: 0.0006196498870849609
LN2: 0.0007004737854003906
MLP_h_4h: 0.07239532470703125
MLP_4h_h: 0.06882262229919434
Post-MLP residual: 0.0018513202667236328
Attention layer time: 0.22577667236328125
LN1: 0.0007116794586181641
QKV Transform: 0.05150341987609863
Flash: 0.00816655158996582
Attention linproj: 0.016742467880249023
Post-attention Dropout: 0.0018482208251953125
Post-attention residual: 0.0006227493286132812
LN2: 0.000705718994140625
MLP_h_4h: 0.07087421417236328
MLP_4h_h: 0.0694284439086914
Post-MLP residual: 0.001863718032836914
Attention layer time: 0.22333550453186035
LN1: 0.0007119178771972656
QKV Transform: 0.05201911926269531
Flash: 0.00855708122253418
Attention linproj: 0.016588687896728516
Post-attention Dropout: 0.0018584728240966797
Post-attention residual: 0.000621795654296875
LN2: 0.0006949901580810547
MLP_h_4h: 0.0709238052368164
MLP_4h_h: 0.06894803047180176
Post-MLP residual: 0.0018486976623535156
Attention layer time: 0.22362422943115234
LN1: 0.0007171630859375
QKV Transform: 0.05306434631347656
Flash: 0.008718013763427734
Attention linproj: 0.016808509826660156
Post-attention Dropout: 0.0018618106842041016
Post-attention residual: 0.0006201267242431641
LN2: 0.0006985664367675781
MLP_h_4h: 0.07089543342590332
MLP_4h_h: 0.06899189949035645
Post-MLP residual: 0.0018515586853027344
Attention layer time: 0.22509479522705078
LN1: 0.0007143020629882812
QKV Transform: 0.05163145065307617
Flash: 0.008030891418457031
Attention linproj: 0.016749858856201172
Post-attention Dropout: 0.0018527507781982422
Post-attention residual: 0.0006222724914550781
LN2: 0.0007009506225585938
MLP_h_4h: 0.07084965705871582
MLP_4h_h: 0.06934857368469238
Post-MLP residual: 0.0018603801727294922
Attention layer time: 0.22324728965759277
LN1: 0.0007174015045166016
QKV Transform: 0.05206298828125
Flash: 0.008746862411499023
Attention linproj: 0.016675233840942383
Post-attention Dropout: 0.0018527507781982422
Post-attention residual: 0.0006208419799804688
LN2: 0.0006961822509765625
MLP_h_4h: 0.07091522216796875
MLP_4h_h: 0.06935477256774902
Post-MLP residual: 0.0018427371978759766
Attention layer time: 0.22437596321105957
LN1: 0.0007169246673583984
QKV Transform: 0.052788496017456055
Flash: 0.008661746978759766
Attention linproj: 0.016824007034301758
Post-attention Dropout: 0.0018541812896728516
Post-attention residual: 0.0006237030029296875
LN2: 0.0006961822509765625
MLP_h_4h: 0.07149362564086914
MLP_4h_h: 0.06972074508666992
Post-MLP residual: 0.001863241195678711
Attention layer time: 0.22613787651062012
LN1: 0.0007152557373046875
QKV Transform: 0.05211830139160156
Flash: 0.007885217666625977
Attention linproj: 0.016859054565429688
Post-attention Dropout: 0.0018734931945800781
Post-attention residual: 0.0006210803985595703
LN2: 0.0006966590881347656
MLP_h_4h: 0.07118391990661621
MLP_4h_h: 0.06876301765441895
Post-MLP residual: 0.0018432140350341797
Attention layer time: 0.22343230247497559
LN1: 0.0007135868072509766
QKV Transform: 0.05138516426086426
Flash: 0.008338689804077148
Attention linproj: 0.01669144630432129
Post-attention Dropout: 0.0018656253814697266
Post-attention residual: 0.0006244182586669922
LN2: 0.0006957054138183594
MLP_h_4h: 0.07091426849365234
MLP_4h_h: 0.06949210166931152
Post-MLP residual: 0.0018610954284667969
Attention layer time: 0.22344684600830078
LN1: 0.0007145404815673828
QKV Transform: 0.05247831344604492
Flash: 0.008260011672973633
Attention linproj: 0.016641855239868164
Post-attention Dropout: 0.0018682479858398438
Post-attention residual: 0.0006208419799804688
LN2: 0.0007081031799316406
MLP_h_4h: 0.07122945785522461
MLP_4h_h: 0.06920862197875977
Post-MLP residual: 0.0018651485443115234
Attention layer time: 0.22445249557495117
LN1: 0.0007176399230957031
QKV Transform: 0.05255770683288574
Flash: 0.008233070373535156
Attention linproj: 0.016791820526123047
Post-attention Dropout: 0.0018565654754638672
Post-attention residual: 0.0006208419799804688
LN2: 0.0006961822509765625
MLP_h_4h: 0.07049083709716797
MLP_4h_h: 0.06925630569458008
Post-MLP residual: 0.0018770694732666016
Attention layer time: 0.2239689826965332
LN1: 0.0007166862487792969
QKV Transform: 0.05191850662231445
Flash: 0.008553743362426758
Attention linproj: 0.01687169075012207
Post-attention Dropout: 0.0019562244415283203
Post-attention residual: 0.0006234645843505859
LN2: 0.0007512569427490234
MLP_h_4h: 0.07138419151306152
MLP_4h_h: 0.06959342956542969
Post-MLP residual: 0.0018565654754638672
Attention layer time: 0.22520804405212402
LN1: 0.0007174015045166016
QKV Transform: 0.0518946647644043
Flash: 0.007808208465576172
Attention linproj: 0.016570568084716797
Post-attention Dropout: 0.0018639564514160156
Post-attention residual: 0.0006186962127685547
LN2: 0.0006947517395019531
MLP_h_4h: 0.07116055488586426
MLP_4h_h: 0.06925415992736816
Post-MLP residual: 0.0018451213836669922
Attention layer time: 0.22337985038757324
LN1: 0.0007166862487792969
QKV Transform: 0.05317234992980957
Flash: 0.008677482604980469
Attention linproj: 0.016788959503173828
Post-attention Dropout: 0.0018749237060546875
Post-attention residual: 0.000621795654296875
LN2: 0.0006964206695556641
MLP_h_4h: 0.07109808921813965
MLP_4h_h: 0.06929349899291992
Post-MLP residual: 0.0018627643585205078
Attention layer time: 0.22565984725952148
LN1: 0.0007166862487792969
QKV Transform: 0.05252242088317871
Flash: 0.008300304412841797
Attention linproj: 0.017023801803588867
Post-attention Dropout: 0.0018565654754638672
Post-attention residual: 0.0006194114685058594
LN2: 0.0006966590881347656
MLP_h_4h: 0.07201814651489258
MLP_4h_h: 0.07042789459228516
Post-MLP residual: 0.0018663406372070312
Attention layer time: 0.2269272804260254
LN1: 0.0007147789001464844
QKV Transform: 0.05206441879272461
Flash: 0.007881402969360352
Attention linproj: 0.016715526580810547
Post-attention Dropout: 0.0018596649169921875
Post-attention residual: 0.0006206035614013672
LN2: 0.00069427490234375
MLP_h_4h: 0.07158994674682617
MLP_4h_h: 0.06969189643859863
Post-MLP residual: 0.0018336772918701172
Attention layer time: 0.22452783584594727
LN1: 0.0007131099700927734
QKV Transform: 0.05264616012573242
Flash: 0.008095264434814453
Attention linproj: 0.016831159591674805
Post-attention Dropout: 0.0018558502197265625
Post-attention residual: 0.0006186962127685547
LN2: 0.0006988048553466797
MLP_h_4h: 0.07139396667480469
MLP_4h_h: 0.06966209411621094
Post-MLP residual: 0.0018627643585205078
Attention layer time: 0.22524380683898926
LN1: 0.0007152557373046875
QKV Transform: 0.05208706855773926
Flash: 0.008746147155761719
Attention linproj: 0.016844511032104492
Post-attention Dropout: 0.0018727779388427734
Post-attention residual: 0.0006186962127685547
LN2: 0.0006928443908691406
MLP_h_4h: 0.07058334350585938
MLP_4h_h: 0.06878805160522461
Post-MLP residual: 0.001834869384765625
Attention layer time: 0.22367119789123535
LN1: 0.0007333755493164062
QKV Transform: 0.05133318901062012
Flash: 0.00809788703918457
Attention linproj: 0.016713619232177734
Post-attention Dropout: 0.0018532276153564453
Post-attention residual: 0.0006210803985595703
LN2: 0.0006968975067138672
MLP_h_4h: 0.07091760635375977
MLP_4h_h: 0.06938290596008301
Post-MLP residual: 0.0018489360809326172
Attention layer time: 0.2230668067932129
LN1: 0.0007107257843017578
QKV Transform: 0.052440643310546875
Flash: 0.008362531661987305
Attention linproj: 0.016669750213623047
Post-attention Dropout: 0.0018572807312011719
Post-attention residual: 0.0006210803985595703
LN2: 0.0006954669952392578
MLP_h_4h: 0.07143592834472656
MLP_4h_h: 0.06922221183776855
Post-MLP residual: 0.0018541812896728516
Attention layer time: 0.22473788261413574
LN1: 0.0007185935974121094
QKV Transform: 0.05278277397155762
Flash: 0.008005619049072266
Attention linproj: 0.01681351661682129
Post-attention Dropout: 0.0018739700317382812
Post-attention residual: 0.0006186962127685547
LN2: 0.0006940364837646484
MLP_h_4h: 0.0713953971862793
MLP_4h_h: 0.07077860832214355
Post-MLP residual: 0.0019440650939941406
Attention layer time: 0.2265458106994629
LN1: 0.0007381439208984375
QKV Transform: 0.05263352394104004
Flash: 0.008312463760375977
Attention linproj: 0.016799449920654297
Post-attention Dropout: 0.0018601417541503906
Post-attention residual: 0.0006244182586669922
LN2: 0.0007152557373046875
MLP_h_4h: 0.0712428092956543
MLP_4h_h: 0.06893467903137207
Post-MLP residual: 0.0018367767333984375
Attention layer time: 0.22463440895080566
LN1: 0.0007126331329345703
QKV Transform: 0.052393436431884766
Flash: 0.008358001708984375
Attention linproj: 0.016646385192871094
Post-attention Dropout: 0.0018587112426757812
Post-attention residual: 0.0006206035614013672
LN2: 0.0006947517395019531
MLP_h_4h: 0.0714106559753418
MLP_4h_h: 0.06929278373718262
Post-MLP residual: 0.0018658638000488281
Attention layer time: 0.22470951080322266
LN1: 0.0007150173187255859
QKV Transform: 0.05261564254760742
Flash: 0.008157968521118164
Attention linproj: 0.01679515838623047
Post-attention Dropout: 0.0018618106842041016
Post-attention residual: 0.0006208419799804688
LN2: 0.0006973743438720703
MLP_h_4h: 0.07036375999450684
MLP_4h_h: 0.06857585906982422
Post-MLP residual: 0.0018358230590820312
Attention layer time: 0.22311902046203613
LN1: 0.0007119178771972656
QKV Transform: 0.05148744583129883
Flash: 0.008186578750610352
Attention linproj: 0.016725778579711914
Post-attention Dropout: 0.0018579959869384766
Post-attention residual: 0.0006191730499267578
LN2: 0.0006952285766601562
MLP_h_4h: 0.07087564468383789
MLP_4h_h: 0.06989741325378418
Post-MLP residual: 0.001850128173828125
Attention layer time: 0.2237703800201416
LN1: 0.0007123947143554688
QKV Transform: 0.05190134048461914
Flash: 0.007869482040405273
Attention linproj: 0.016712665557861328
Post-attention Dropout: 0.001873016357421875
Post-attention residual: 0.0006213188171386719
LN2: 0.0006930828094482422
MLP_h_4h: 0.07100033760070801
MLP_4h_h: 0.06982135772705078
Post-MLP residual: 0.001844644546508789
Attention layer time: 0.2239093780517578
LN1: 0.0007128715515136719
QKV Transform: 0.052591800689697266
Flash: 0.008095264434814453
Attention linproj: 0.01679062843322754
Post-attention Dropout: 0.001859903335571289
Post-attention residual: 0.0006201267242431641
LN2: 0.0006976127624511719
MLP_h_4h: 0.07118463516235352
MLP_4h_h: 0.0693812370300293
Post-MLP residual: 0.0018625259399414062
Attention layer time: 0.22467303276062012
LN1: 0.0007159709930419922
QKV Transform: 0.05243039131164551
Flash: 0.008415699005126953
Attention linproj: 0.016872644424438477
Post-attention Dropout: 0.0018699169158935547
Post-attention residual: 0.0006198883056640625
LN2: 0.0006935596466064453
MLP_h_4h: 0.07179594039916992
MLP_4h_h: 0.06964850425720215
Post-MLP residual: 0.0018527507781982422
Attention layer time: 0.2257859706878662
LN1: 0.0007145404815673828
QKV Transform: 0.05153250694274902
Flash: 0.008080244064331055
Attention linproj: 0.016694307327270508
Post-attention Dropout: 0.0018544197082519531
Post-attention residual: 0.0006234645843505859
LN2: 0.00069427490234375
MLP_h_4h: 0.07103514671325684
MLP_4h_h: 0.06959271430969238
Post-MLP residual: 0.0018527507781982422
Attention layer time: 0.22354364395141602
LN1: 0.0007126331329345703
QKV Transform: 0.05314040184020996
Flash: 0.008412599563598633
Attention linproj: 0.016640186309814453
Post-attention Dropout: 0.0018610954284667969
Post-attention residual: 0.0006189346313476562
LN2: 0.0006988048553466797
MLP_h_4h: 0.0715799331665039
MLP_4h_h: 0.06920242309570312
Post-MLP residual: 0.0018568038940429688
Attention layer time: 0.22558355331420898
LN1: 0.0007164478302001953
QKV Transform: 0.05249953269958496
Flash: 0.008385896682739258
Attention linproj: 0.016893625259399414
Post-attention Dropout: 0.0018658638000488281
Post-attention residual: 0.0006196498870849609
LN2: 0.0006954669952392578
MLP_h_4h: 0.07186508178710938
MLP_4h_h: 0.06876921653747559
Post-MLP residual: 0.0018486976623535156
Attention layer time: 0.2250211238861084
LN1: 0.0007114410400390625
QKV Transform: 0.05135965347290039
Flash: 0.008355855941772461
Attention linproj: 0.016717195510864258
Post-attention Dropout: 0.001863718032836914
Post-attention residual: 0.0006210803985595703
LN2: 0.0006937980651855469
MLP_h_4h: 0.07062959671020508
MLP_4h_h: 0.06910991668701172
Post-MLP residual: 0.0018496513366699219
Attention layer time: 0.22276759147644043
LN1: 0.000713348388671875
QKV Transform: 0.052068471908569336
Flash: 0.008731365203857422
Attention linproj: 0.0166018009185791
Post-attention Dropout: 0.0018520355224609375
Post-attention residual: 0.00061798095703125
LN2: 0.0006940364837646484
MLP_h_4h: 0.0713200569152832
MLP_4h_h: 0.06955838203430176
Post-MLP residual: 0.0018591880798339844
Attention layer time: 0.22490763664245605
LN1: 0.0007138252258300781
QKV Transform: 0.05245828628540039
Flash: 0.008406400680541992
Attention linproj: 0.017240285873413086
Post-attention Dropout: 0.0018672943115234375
Post-attention residual: 0.0006198883056640625
LN2: 0.0006995201110839844
MLP_h_4h: 0.0716700553894043
MLP_4h_h: 0.06977248191833496
Post-MLP residual: 0.0018863677978515625
Attention layer time: 0.22629570960998535
LN1: 0.0007259845733642578
QKV Transform: 0.0516200065612793
Flash: 0.007971048355102539
Attention linproj: 0.01670217514038086
Post-attention Dropout: 0.0018723011016845703
Post-attention residual: 0.0006241798400878906
LN2: 0.0006937980651855469
MLP_h_4h: 0.07103562355041504
MLP_4h_h: 0.06979751586914062
Post-MLP residual: 0.0018532276153564453
Attention layer time: 0.22379088401794434
LN1: 0.0007140636444091797
QKV Transform: 0.051772117614746094
Flash: 0.007972478866577148
Attention linproj: 0.016718387603759766
Post-attention Dropout: 0.0018603801727294922
Post-attention residual: 0.0006198883056640625
LN2: 0.0006947517395019531
MLP_h_4h: 0.07133960723876953
MLP_4h_h: 0.0694732666015625
Post-MLP residual: 0.0018453598022460938
Attention layer time: 0.22386908531188965
LN1: 0.0007147789001464844
QKV Transform: 0.05333232879638672
Flash: 0.008463859558105469
Attention linproj: 0.016797542572021484
Post-attention Dropout: 0.0018618106842041016
Post-attention residual: 0.0006198883056640625
LN2: 0.0006978511810302734
MLP_h_4h: 0.07215452194213867
MLP_4h_h: 0.06891751289367676
Post-MLP residual: 0.0018489360809326172
Attention layer time: 0.2262709140777588
LN1: 0.0007147789001464844
QKV Transform: 0.05204963684082031
Flash: 0.007844686508178711
Attention linproj: 0.016889095306396484
Post-attention Dropout: 0.0018575191497802734
Post-attention residual: 0.0006210803985595703
LN2: 0.00069427490234375
MLP_h_4h: 0.07173824310302734
MLP_4h_h: 0.06974935531616211
Post-MLP residual: 0.0018460750579833984
Attention layer time: 0.22488713264465332
LN1: 0.0007147789001464844
QKV Transform: 0.05137753486633301
Flash: 0.008327484130859375
Attention linproj: 0.016634464263916016
Post-attention Dropout: 0.0018475055694580078
Post-attention residual: 0.0006184577941894531
LN2: 0.0007071495056152344
MLP_h_4h: 0.07134461402893066
MLP_4h_h: 0.06978511810302734
Post-MLP residual: 0.0018565654754638672
Attention layer time: 0.22407007217407227
LN1: 0.0007131099700927734
QKV Transform: 0.052762508392333984
Flash: 0.00799417495727539
Attention linproj: 0.016811370849609375
Post-attention Dropout: 0.0018756389617919922
Post-attention residual: 0.0006198883056640625
LN2: 0.0006983280181884766
MLP_h_4h: 0.07155609130859375
MLP_4h_h: 0.06862258911132812
Post-MLP residual: 0.001847982406616211
Attention layer time: 0.22438669204711914
LN1: 0.0007123947143554688
QKV Transform: 0.05207347869873047
Flash: 0.007843494415283203
Attention linproj: 0.016911983489990234
Post-attention Dropout: 0.0018649101257324219
Post-attention residual: 0.0006196498870849609
LN2: 0.0006973743438720703
MLP_h_4h: 0.07272958755493164
MLP_4h_h: 0.07035279273986816
Post-MLP residual: 0.0018546581268310547
Attention layer time: 0.22652816772460938
LN1: 0.0007131099700927734
QKV Transform: 0.05152249336242676
Flash: 0.008156776428222656
Attention linproj: 0.016655921936035156
Post-attention Dropout: 0.0018529891967773438
Post-attention residual: 0.0006196498870849609
LN2: 0.0006971359252929688
MLP_h_4h: 0.07127189636230469
MLP_4h_h: 0.06972861289978027
Post-MLP residual: 0.0018546581268310547
Attention layer time: 0.2239670753479004
LN1: 0.0007236003875732422
QKV Transform: 0.05248403549194336
Flash: 0.008256673812866211
Attention linproj: 0.01666998863220215
Post-attention Dropout: 0.001855611801147461
Post-attention residual: 0.0006222724914550781
LN2: 0.0006990432739257812
MLP_h_4h: 0.0720968246459961
MLP_4h_h: 0.06994199752807617
Post-MLP residual: 0.0018620491027832031
Attention layer time: 0.22610187530517578
LN1: 0.0007162094116210938
QKV Transform: 0.05249142646789551
Flash: 0.008302927017211914
Attention linproj: 0.017009496688842773
Post-attention Dropout: 0.001861572265625
Post-attention residual: 0.0006229877471923828
LN2: 0.0006968975067138672
MLP_h_4h: 0.07173347473144531
MLP_4h_h: 0.06931495666503906
Post-MLP residual: 0.0018393993377685547
Attention layer time: 0.22546100616455078
LN1: 0.0007126331329345703
QKV Transform: 0.051605939865112305
Flash: 0.00819087028503418
Attention linproj: 0.01667332649230957
Post-attention Dropout: 0.0018551349639892578
Post-attention residual: 0.0006194114685058594
LN2: 0.0006973743438720703
MLP_h_4h: 0.07139229774475098
MLP_4h_h: 0.06954479217529297
Post-MLP residual: 0.0018498897552490234
Attention layer time: 0.22400593757629395
LN1: 0.0007171630859375
QKV Transform: 0.052428245544433594
Flash: 0.008294105529785156
Attention linproj: 0.016835927963256836
Post-attention Dropout: 0.001861572265625
Post-attention residual: 0.0006213188171386719
LN2: 0.0006945133209228516
MLP_h_4h: 0.0713348388671875
MLP_4h_h: 0.0693655014038086
Post-MLP residual: 0.0018646717071533203
Attention layer time: 0.22491216659545898
LN1: 0.0007140636444091797
QKV Transform: 0.052486419677734375
Flash: 0.00835108757019043
Attention linproj: 0.01698899269104004
Post-attention Dropout: 0.0018644332885742188
Post-attention residual: 0.000621795654296875
LN2: 0.0006973743438720703
MLP_h_4h: 0.0714883804321289
MLP_4h_h: 0.06955075263977051
Post-MLP residual: 0.0018570423126220703
Attention layer time: 0.22551393508911133
LN1: 0.0007131099700927734
QKV Transform: 0.05200648307800293
Flash: 0.007767677307128906
Attention linproj: 0.016706466674804688
Post-attention Dropout: 0.0018515586853027344
Post-attention residual: 0.0006225109100341797
LN2: 0.0006964206695556641
MLP_h_4h: 0.07138538360595703
MLP_4h_h: 0.06958246231079102
Post-MLP residual: 0.0018465518951416016
Attention layer time: 0.2240464687347412
LN1: 0.0007138252258300781
QKV Transform: 0.0519566535949707
Flash: 0.008687257766723633
Attention linproj: 0.01656031608581543
Post-attention Dropout: 0.001867055892944336
Post-attention residual: 0.0006203651428222656
LN2: 0.0006940364837646484
MLP_h_4h: 0.07088923454284668
MLP_4h_h: 0.06909608840942383
Post-MLP residual: 0.001861572265625
Attention layer time: 0.22379541397094727
LN1: 0.0007171630859375
QKV Transform: 0.052654266357421875
Flash: 0.008168458938598633
Attention linproj: 0.01678776741027832
Post-attention Dropout: 0.0018572807312011719
Post-attention residual: 0.0006198883056640625
LN2: 0.0006940364837646484
MLP_h_4h: 0.07121157646179199
MLP_4h_h: 0.06954717636108398
Post-MLP residual: 0.001859903335571289
Attention layer time: 0.22497773170471191
LN1: 0.0007169246673583984
QKV Transform: 0.05192160606384277
Flash: 0.007869720458984375
Attention linproj: 0.016826868057250977
Post-attention Dropout: 0.0018558502197265625
Post-attention residual: 0.0006172657012939453
LN2: 0.0006976127624511719
MLP_h_4h: 0.07126688957214355
MLP_4h_h: 0.0692899227142334
Post-MLP residual: 0.001850128173828125
Attention layer time: 0.22379398345947266
LN1: 0.0007119178771972656
QKV Transform: 0.05210447311401367
Flash: 0.008708000183105469
Attention linproj: 0.01658773422241211
Post-attention Dropout: 0.00185394287109375
Post-attention residual: 0.0006265640258789062
LN2: 0.0006971359252929688
MLP_h_4h: 0.07112455368041992
MLP_4h_h: 0.06921839714050293
Post-MLP residual: 0.0018401145935058594
Attention layer time: 0.22434139251708984
LN1: 0.0007178783416748047
QKV Transform: 0.05271005630493164
Flash: 0.008090734481811523
Attention linproj: 0.01680159568786621
Post-attention Dropout: 0.0018568038940429688
Post-attention residual: 0.0006198883056640625
LN2: 0.0006937980651855469
MLP_h_4h: 0.07108783721923828
MLP_4h_h: 0.06941676139831543
Post-MLP residual: 0.001874685287475586
Attention layer time: 0.22472739219665527
LN1: 0.0007140636444091797
QKV Transform: 0.0524289608001709
Flash: 0.008427143096923828
Attention linproj: 0.016948938369750977
Post-attention Dropout: 0.0018584728240966797
Post-attention residual: 0.0006191730499267578
LN2: 0.0006947517395019531
MLP_h_4h: 0.07145547866821289
MLP_4h_h: 0.06958389282226562
Post-MLP residual: 0.0018658638000488281
Attention layer time: 0.22546958923339844
LN1: 0.0007126331329345703
QKV Transform: 0.051961421966552734
Flash: 0.007829427719116211
Attention linproj: 0.016591548919677734
Post-attention Dropout: 0.0018641948699951172
Post-attention residual: 0.0006237030029296875
LN2: 0.0006968975067138672
MLP_h_4h: 0.07088112831115723
MLP_4h_h: 0.06909298896789551
Post-MLP residual: 0.0018544197082519531
Attention layer time: 0.22298383712768555
LN1: 0.000713348388671875
QKV Transform: 0.05260491371154785
Flash: 0.008214473724365234
Attention linproj: 0.017124176025390625
Post-attention Dropout: 0.0018639564514160156
Post-attention residual: 0.0006210803985595703
LN2: 0.0006959438323974609
MLP_h_4h: 0.07195925712585449
MLP_4h_h: 0.06913352012634277
Post-MLP residual: 0.0018544197082519531
Attention layer time: 0.22566723823547363
LN1: 0.0007162094116210938
QKV Transform: 0.05265498161315918
Flash: 0.00811624526977539
Attention linproj: 0.0171966552734375
Post-attention Dropout: 0.001873016357421875
Post-attention residual: 0.0006208419799804688
LN2: 0.0006988048553466797
MLP_h_4h: 0.07129454612731934
MLP_4h_h: 0.06915140151977539
Post-MLP residual: 0.001855611801147461
Attention layer time: 0.22506141662597656
LN1: 0.0007140636444091797
QKV Transform: 0.05175971984863281
Flash: 0.008005619049072266
Attention linproj: 0.016819000244140625
Post-attention Dropout: 0.0018723011016845703
Post-attention residual: 0.0006234645843505859
LN2: 0.0006973743438720703
MLP_h_4h: 0.07082700729370117
MLP_4h_h: 0.06951570510864258
Post-MLP residual: 0.0018587112426757812
Attention layer time: 0.22356128692626953
LN1: 0.0007112026214599609
QKV Transform: 0.05254817008972168
Flash: 0.008206605911254883
Attention linproj: 0.016694068908691406
Post-attention Dropout: 0.0018546581268310547
Post-attention residual: 0.0006210803985595703
LN2: 0.0006966590881347656
MLP_h_4h: 0.07118558883666992
MLP_4h_h: 0.06935906410217285
Post-MLP residual: 0.0018870830535888672
Attention layer time: 0.22463750839233398
LN1: 0.0007283687591552734
QKV Transform: 0.05264115333557129
Flash: 0.008147239685058594
Attention linproj: 0.016799449920654297
Post-attention Dropout: 0.0018553733825683594
Post-attention residual: 0.0006206035614013672
LN2: 0.0006933212280273438
MLP_h_4h: 0.07165312767028809
MLP_4h_h: 0.06981778144836426
Post-MLP residual: 0.0018417835235595703
Attention layer time: 0.22565960884094238
LN1: 0.0007123947143554688
QKV Transform: 0.05191469192504883
Flash: 0.007880210876464844
Attention linproj: 0.016797780990600586
Post-attention Dropout: 0.0018591880798339844
Post-attention residual: 0.0006189346313476562
LN2: 0.0006964206695556641
MLP_h_4h: 0.0721893310546875
MLP_4h_h: 0.06965303421020508
Post-MLP residual: 0.0018601417541503906
Attention layer time: 0.22505807876586914
LN1: 0.0007143020629882812
QKV Transform: 0.052440643310546875
Flash: 0.008317708969116211
Attention linproj: 0.016818761825561523
Post-attention Dropout: 0.0018618106842041016
Post-attention residual: 0.0006237030029296875
LN2: 0.0006959438323974609
MLP_h_4h: 0.07133698463439941
MLP_4h_h: 0.0692586898803711
Post-MLP residual: 0.0018575191497802734
Attention layer time: 0.2247915267944336
LN1: 0.0007128715515136719
QKV Transform: 0.05225729942321777
Flash: 0.008387565612792969
Attention linproj: 0.016988515853881836
Post-attention Dropout: 0.0018608570098876953
Post-attention residual: 0.0006208419799804688
LN2: 0.0006954669952392578
MLP_h_4h: 0.0719461441040039
MLP_4h_h: 0.0696561336517334
Post-MLP residual: 0.0018572807312011719
Attention layer time: 0.22586536407470703
LN1: 0.0007143020629882812
QKV Transform: 0.05145668983459473
Flash: 0.008244991302490234
Attention linproj: 0.016634225845336914
Post-attention Dropout: 0.0018568038940429688
Post-attention residual: 0.0006239414215087891
LN2: 0.0006978511810302734
MLP_h_4h: 0.07091426849365234
MLP_4h_h: 0.06913447380065918
Post-MLP residual: 0.0018451213836669922
Attention layer time: 0.22303414344787598
LN1: 0.0007135868072509766
QKV Transform: 0.052748918533325195
Flash: 0.008042335510253906
Attention linproj: 0.016651630401611328
Post-attention Dropout: 0.0018582344055175781
Post-attention residual: 0.0006220340728759766
LN2: 0.0006971359252929688
MLP_h_4h: 0.07129454612731934
MLP_4h_h: 0.06915926933288574
Post-MLP residual: 0.001873016357421875
Attention layer time: 0.22453641891479492
LN1: 0.0007176399230957031
QKV Transform: 0.05270099639892578
Flash: 0.00823354721069336
Attention linproj: 0.017001628875732422
Post-attention Dropout: 0.0018677711486816406
Post-attention residual: 0.0006194114685058594
LN2: 0.0006940364837646484
MLP_h_4h: 0.07265639305114746
MLP_4h_h: 0.07053184509277344
Post-MLP residual: 0.0018510818481445312
Attention layer time: 0.22776007652282715
LN1: 0.0007147789001464844
QKV Transform: 0.0516667366027832
Flash: 0.00805354118347168
Attention linproj: 0.01667475700378418
Post-attention Dropout: 0.0018527507781982422
Post-attention residual: 0.0006227493286132812
LN2: 0.0006966590881347656
MLP_h_4h: 0.07078409194946289
MLP_4h_h: 0.0694279670715332
Post-MLP residual: 0.0018572807312011719
Attention layer time: 0.22322940826416016
LN1: 0.0007171630859375
QKV Transform: 0.053285837173461914
Flash: 0.008586406707763672
Attention linproj: 0.01682114601135254
Post-attention Dropout: 0.0018811225891113281
Post-attention residual: 0.000621795654296875
LN2: 0.0006973743438720703
MLP_h_4h: 0.0715017318725586
MLP_4h_h: 0.06893062591552734
Post-MLP residual: 0.0018467903137207031
Attention layer time: 0.22576284408569336
LN1: 0.0007128715515136719
QKV Transform: 0.05210065841674805
Flash: 0.008722066879272461
Attention linproj: 0.01689004898071289
Post-attention Dropout: 0.0018758773803710938
Post-attention residual: 0.0006206035614013672
LN2: 0.0006973743438720703
MLP_h_4h: 0.07120656967163086
MLP_4h_h: 0.06902480125427246
Post-MLP residual: 0.0018506050109863281
Attention layer time: 0.22459626197814941
LN1: 0.0007309913635253906
QKV Transform: 0.05160880088806152
Flash: 0.008159160614013672
Attention linproj: 0.01666569709777832
Post-attention Dropout: 0.0018510818481445312
Post-attention residual: 0.0006241798400878906
LN2: 0.0006971359252929688
MLP_h_4h: 0.0713651180267334
MLP_4h_h: 0.06954216957092285
Post-MLP residual: 0.0018391609191894531
Attention layer time: 0.2239668369293213
LN1: 0.0007154941558837891
QKV Transform: 0.05266618728637695
Flash: 0.008092641830444336
Attention linproj: 0.016843080520629883
Post-attention Dropout: 0.0018575191497802734
Post-attention residual: 0.0006201267242431641
LN2: 0.0006957054138183594
MLP_h_4h: 0.0710606575012207
MLP_4h_h: 0.06902408599853516
Post-MLP residual: 0.001875162124633789
Attention layer time: 0.2243359088897705
LN1: 0.0007176399230957031
QKV Transform: 0.052407264709472656
Flash: 0.008386373519897461
Attention linproj: 0.016895532608032227
Post-attention Dropout: 0.0018608570098876953
Post-attention residual: 0.0006194114685058594
LN2: 0.0006968975067138672
MLP_h_4h: 0.07158231735229492
MLP_4h_h: 0.06890463829040527
Post-MLP residual: 0.0018444061279296875
Attention layer time: 0.22479677200317383
LN1: 0.0007135868072509766
QKV Transform: 0.05250120162963867
Flash: 0.008187055587768555
Attention linproj: 0.01666259765625
Post-attention Dropout: 0.0018494129180908203
Post-attention residual: 0.0006206035614013672
LN2: 0.0006968975067138672
MLP_h_4h: 0.07127642631530762
MLP_4h_h: 0.0696561336517334
Post-MLP residual: 0.0018546581268310547
Attention layer time: 0.22490477561950684
LN1: 0.0007166862487792969
QKV Transform: 0.05232405662536621
Flash: 0.008379220962524414
Attention linproj: 0.016820192337036133
Post-attention Dropout: 0.001886129379272461
Post-attention residual: 0.0006198883056640625
LN2: 0.0006949901580810547
MLP_h_4h: 0.07131743431091309
MLP_4h_h: 0.06932282447814941
Post-MLP residual: 0.0018568038940429688
Attention layer time: 0.22480201721191406
LN1: 0.0007145404815673828
QKV Transform: 0.05256080627441406
Flash: 0.008295536041259766
Attention linproj: 0.016999483108520508
Post-attention Dropout: 0.0018718242645263672
Post-attention residual: 0.0006194114685058594
LN2: 0.0006957054138183594
MLP_h_4h: 0.07182741165161133
MLP_4h_h: 0.06975269317626953
Post-MLP residual: 0.0018565654754638672
Attention layer time: 0.2260751724243164
LN1: 0.0007147789001464844
QKV Transform: 0.051217079162597656
Flash: 0.008296728134155273
Attention linproj: 0.016591787338256836
Post-attention Dropout: 0.0018591880798339844
Post-attention residual: 0.0006229877471923828
LN2: 0.0006992816925048828
MLP_h_4h: 0.07097101211547852
MLP_4h_h: 0.06951069831848145
Post-MLP residual: 0.0018467903137207031
Attention layer time: 0.2232046127319336
LN1: 0.0007135868072509766
QKV Transform: 0.05205059051513672
Flash: 0.007742643356323242
Attention linproj: 0.016558408737182617
Post-attention Dropout: 0.0018646717071533203
Post-attention residual: 0.000621795654296875
LN2: 0.0006971359252929688
MLP_h_4h: 0.07116460800170898
MLP_4h_h: 0.0689702033996582
Post-MLP residual: 0.0018529891967773438
Attention layer time: 0.22308993339538574
LN1: 0.0007152557373046875
QKV Transform: 0.05214238166809082
Flash: 0.008374929428100586
Attention linproj: 0.016921520233154297
Post-attention Dropout: 0.0018656253814697266
Post-attention residual: 0.0006206035614013672
LN2: 0.0006952285766601562
MLP_h_4h: 0.07217144966125488
MLP_4h_h: 0.06879162788391113
Post-MLP residual: 0.001844644546508789
Attention layer time: 0.2250211238861084
LN1: 0.0007109642028808594
QKV Transform: 0.05171966552734375
Flash: 0.008055686950683594
Attention linproj: 0.016879796981811523
Post-attention Dropout: 0.0018551349639892578
Post-attention residual: 0.0006341934204101562
LN2: 0.0006978511810302734
MLP_h_4h: 0.07148027420043945
MLP_4h_h: 0.06908488273620605
Post-MLP residual: 0.0018525123596191406
Attention layer time: 0.2238469123840332
LN1: 0.0007126331329345703
QKV Transform: 0.05193901062011719
Flash: 0.007816553115844727
Attention linproj: 0.016587018966674805
Post-attention Dropout: 0.0018665790557861328
Post-attention residual: 0.0006186962127685547
LN2: 0.0006945133209228516
MLP_h_4h: 0.07051801681518555
MLP_4h_h: 0.06906604766845703
Post-MLP residual: 0.001840829849243164
Attention layer time: 0.2225334644317627
LN1: 0.0007162094116210938
QKV Transform: 0.05303788185119629
Flash: 0.008742094039916992
Attention linproj: 0.016817808151245117
Post-attention Dropout: 0.0018625259399414062
Post-attention residual: 0.0006222724914550781
LN2: 0.0006964206695556641
MLP_h_4h: 0.07146811485290527
MLP_4h_h: 0.06932759284973145
Post-MLP residual: 0.0018610954284667969
Attention layer time: 0.22602391242980957
LN1: 0.0007164478302001953
QKV Transform: 0.05260753631591797
Flash: 0.008259057998657227
Attention linproj: 0.016962528228759766
Post-attention Dropout: 0.0018572807312011719
Post-attention residual: 0.0006196498870849609
LN2: 0.0006964206695556641
MLP_h_4h: 0.07196664810180664
MLP_4h_h: 0.06968951225280762
Post-MLP residual: 0.0018477439880371094
Attention layer time: 0.2261042594909668
LN1: 0.0007238388061523438
QKV Transform: 0.05204129219055176
Flash: 0.00868368148803711
Attention linproj: 0.01657700538635254
Post-attention Dropout: 0.0018630027770996094
Post-attention residual: 0.0006225109100341797
LN2: 0.0006966590881347656
MLP_h_4h: 0.07123446464538574
MLP_4h_h: 0.0686805248260498
Post-MLP residual: 0.0018491744995117188
Attention layer time: 0.22385859489440918
LN1: 0.0007123947143554688
QKV Transform: 0.05176830291748047
Flash: 0.007869243621826172
Attention linproj: 0.016651630401611328
Post-attention Dropout: 0.0018570423126220703
Post-attention residual: 0.0006189346313476562
LN2: 0.0007045269012451172
MLP_h_4h: 0.07131052017211914
MLP_4h_h: 0.06908488273620605
Post-MLP residual: 0.0018775463104248047
Attention layer time: 0.2233281135559082
LN1: 0.0007274150848388672
QKV Transform: 0.05255484580993652
Flash: 0.008142948150634766
Attention linproj: 0.016779661178588867
Post-attention Dropout: 0.0018684864044189453
Post-attention residual: 0.0006222724914550781
LN2: 0.000698089599609375
MLP_h_4h: 0.07060384750366211
MLP_4h_h: 0.06912493705749512
Post-MLP residual: 0.0018525123596191406
Attention layer time: 0.223876953125
LN1: 0.0007131099700927734
QKV Transform: 0.05187034606933594
Flash: 0.007899045944213867
Attention linproj: 0.016844749450683594
Post-attention Dropout: 0.0018627643585205078
Post-attention residual: 0.0006210803985595703
LN2: 0.0006966590881347656
MLP_h_4h: 0.07094025611877441
MLP_4h_h: 0.06951475143432617
Post-MLP residual: 0.0018393993377685547
Attention layer time: 0.2236800193786621
LN1: 0.0007138252258300781
QKV Transform: 0.05175638198852539
Flash: 0.008697271347045898
Attention linproj: 0.016536712646484375
Post-attention Dropout: 0.0018444061279296875
Post-attention residual: 0.0006248950958251953
LN2: 0.0006945133209228516
MLP_h_4h: 0.07081031799316406
MLP_4h_h: 0.0693655014038086
Post-MLP residual: 0.001842498779296875
Attention layer time: 0.22374773025512695
LN1: 0.0007190704345703125
QKV Transform: 0.05200982093811035
Flash: 0.008080720901489258
Attention linproj: 0.01679229736328125
Post-attention Dropout: 0.0018641948699951172
Post-attention residual: 0.0006203651428222656
LN2: 0.0006952285766601562
MLP_h_4h: 0.07155609130859375
MLP_4h_h: 0.07064032554626465
Post-MLP residual: 0.0018641948699951172
Attention layer time: 0.2257072925567627
LN1: 0.0007164478302001953
QKV Transform: 0.051848649978637695
Flash: 0.0078046321868896484
Attention linproj: 0.016698122024536133
Post-attention Dropout: 0.0018537044525146484
Post-attention residual: 0.0006198883056640625
LN2: 0.0006952285766601562
MLP_h_4h: 0.07109642028808594
MLP_4h_h: 0.0697331428527832
Post-MLP residual: 0.0018472671508789062
Attention layer time: 0.22381019592285156
LN1: 0.000713348388671875
QKV Transform: 0.05202817916870117
Flash: 0.008749723434448242
Attention linproj: 0.0165860652923584
Post-attention Dropout: 0.0018680095672607422
Post-attention residual: 0.0006248950958251953
LN2: 0.0006999969482421875
MLP_h_4h: 0.07138395309448242
MLP_4h_h: 0.06921601295471191
Post-MLP residual: 0.0018429756164550781
Attention layer time: 0.2246079444885254
LN1: 0.0007166862487792969
QKV Transform: 0.05247163772583008
Flash: 0.008083581924438477
Attention linproj: 0.016808271408081055
Post-attention Dropout: 0.0018582344055175781
Post-attention residual: 0.0006229877471923828
LN2: 0.0006937980651855469
MLP_h_4h: 0.07175207138061523
MLP_4h_h: 0.06957602500915527
Post-MLP residual: 0.001859903335571289
Attention layer time: 0.22530746459960938
LN1: 0.0007138252258300781
QKV Transform: 0.05193662643432617
Flash: 0.007886648178100586
Attention linproj: 0.016848087310791016
Post-attention Dropout: 0.001861572265625
Post-attention residual: 0.0006186962127685547
LN2: 0.0006933212280273438
MLP_h_4h: 0.0717167854309082
MLP_4h_h: 0.06948351860046387
Post-MLP residual: 0.001844644546508789
Attention layer time: 0.2244706153869629
LN1: 0.0007123947143554688
QKV Transform: 0.05223798751831055
Flash: 0.008598089218139648
Attention linproj: 0.01667618751525879
Post-attention Dropout: 0.0018579959869384766
Post-attention residual: 0.0006206035614013672
LN2: 0.0006961822509765625
MLP_h_4h: 0.07193922996520996
MLP_4h_h: 0.06948113441467285
Post-MLP residual: 0.0018339157104492188
Attention layer time: 0.22552752494812012
LN1: 0.0007162094116210938
QKV Transform: 0.05255842208862305
Flash: 0.008114814758300781
Attention linproj: 0.016791105270385742
Post-attention Dropout: 0.0018608570098876953
Post-attention residual: 0.0006184577941894531
LN2: 0.0006937980651855469
MLP_h_4h: 0.07112812995910645
MLP_4h_h: 0.06933474540710449
Post-MLP residual: 0.001859903335571289
Attention layer time: 0.22454094886779785
LN1: 0.0007164478302001953
QKV Transform: 0.052149295806884766
Flash: 0.008656978607177734
Attention linproj: 0.016707420349121094
Post-attention Dropout: 0.0018715858459472656
Post-attention residual: 0.0006237030029296875
LN2: 0.000698089599609375
MLP_h_4h: 0.07095193862915039
MLP_4h_h: 0.06982231140136719
Post-MLP residual: 0.0018472671508789062
Attention layer time: 0.2249155044555664
LN1: 0.0007128715515136719
QKV Transform: 0.05203866958618164
Flash: 0.007862329483032227
Attention linproj: 0.01668238639831543
Post-attention Dropout: 0.0018627643585205078
Post-attention residual: 0.000621795654296875
LN2: 0.0006964206695556641
MLP_h_4h: 0.07173538208007812
MLP_4h_h: 0.06972408294677734
Post-MLP residual: 0.0018279552459716797
Attention layer time: 0.22464299201965332
LN1: 0.0007147789001464844
QKV Transform: 0.05241751670837402
Flash: 0.008306741714477539
Attention linproj: 0.017061471939086914
Post-attention Dropout: 0.0018610954284667969
Post-attention residual: 0.0006210803985595703
LN2: 0.0006978511810302734
MLP_h_4h: 0.07214045524597168
MLP_4h_h: 0.06991028785705566
Post-MLP residual: 0.0018513202667236328
Attention layer time: 0.22647571563720703
LN1: 0.0007128715515136719
QKV Transform: 0.05213475227355957
Flash: 0.008756637573242188
Attention linproj: 0.01670527458190918
Post-attention Dropout: 0.0018682479858398438
Post-attention residual: 0.0006189346313476562
LN2: 0.0006923675537109375
MLP_h_4h: 0.07115983963012695
MLP_4h_h: 0.06960511207580566
Post-MLP residual: 0.0018515586853027344
Attention layer time: 0.2249743938446045
LN1: 0.0007114410400390625
QKV Transform: 0.052342891693115234
Flash: 0.008377790451049805
Attention linproj: 0.016659259796142578
Post-attention Dropout: 0.0018620491027832031
Post-attention residual: 0.0006194114685058594
LN2: 0.0006973743438720703
MLP_h_4h: 0.07162761688232422
MLP_4h_h: 0.06929206848144531
Post-MLP residual: 0.0018796920776367188
Attention layer time: 0.22493910789489746
LN1: 0.0007154941558837891
QKV Transform: 0.05277705192565918
Flash: 0.00812077522277832
Attention linproj: 0.0170137882232666
Post-attention Dropout: 0.0018813610076904297
Post-attention residual: 0.0006186962127685547
LN2: 0.0006947517395019531
MLP_h_4h: 0.07220625877380371
MLP_4h_h: 0.0697011947631836
Post-MLP residual: 0.0018591880798339844
Attention layer time: 0.22646689414978027
LN1: 0.0007147789001464844
QKV Transform: 0.05136847496032715
Flash: 0.008033990859985352
Attention linproj: 0.016703367233276367
Post-attention Dropout: 0.0018677711486816406
Post-attention residual: 0.0006213188171386719
LN2: 0.0007128715515136719
MLP_h_4h: 0.0713200569152832
MLP_4h_h: 0.06985664367675781
Post-MLP residual: 0.001857757568359375
Attention layer time: 0.22394323348999023
LN1: 0.0007166862487792969
QKV Transform: 0.05276823043823242
Flash: 0.007957696914672852
Attention linproj: 0.016632556915283203
Post-attention Dropout: 0.0018606185913085938
Post-attention residual: 0.0006191730499267578
LN2: 0.0006928443908691406
MLP_h_4h: 0.07144689559936523
MLP_4h_h: 0.07035589218139648
Post-MLP residual: 0.0018661022186279297
Attention layer time: 0.22577643394470215
LN1: 0.0007174015045166016
QKV Transform: 0.05254006385803223
Flash: 0.00821232795715332
Attention linproj: 0.016759157180786133
Post-attention Dropout: 0.0018527507781982422
Post-attention residual: 0.0006206035614013672
LN2: 0.0006983280181884766
MLP_h_4h: 0.07104253768920898
MLP_4h_h: 0.07027745246887207
Post-MLP residual: 0.0018572807312011719
Attention layer time: 0.2254471778869629
LN1: 0.0007154941558837891
QKV Transform: 0.05158877372741699
Flash: 0.008055925369262695
Attention linproj: 0.01660442352294922
Post-attention Dropout: 0.0018684864044189453
Post-attention residual: 0.0006198883056640625
LN2: 0.0006973743438720703
MLP_h_4h: 0.07362747192382812
MLP_4h_h: 0.07011675834655762
Post-MLP residual: 0.0018520355224609375
Attention layer time: 0.2266230583190918
LN1: 0.0007178783416748047
QKV Transform: 0.05282282829284668
Flash: 0.0078067779541015625
Attention linproj: 0.016793251037597656
Post-attention Dropout: 0.0018544197082519531
Post-attention residual: 0.0006237030029296875
LN2: 0.0006952285766601562
MLP_h_4h: 0.07189178466796875
MLP_4h_h: 0.06891345977783203
Post-MLP residual: 0.0018587112426757812
Attention layer time: 0.22484827041625977
LN1: 0.0007116794586181641
QKV Transform: 0.05246782302856445
Flash: 0.008370161056518555
Attention linproj: 0.016857385635375977
Post-attention Dropout: 0.001863241195678711
Post-attention residual: 0.0006194114685058594
LN2: 0.0006954669952392578
MLP_h_4h: 0.07187414169311523
MLP_4h_h: 0.0697782039642334
Post-MLP residual: 0.0018422603607177734
Attention layer time: 0.22599148750305176
LN1: 0.0007143020629882812
QKV Transform: 0.052102088928222656
Flash: 0.008635282516479492
Attention linproj: 0.016545772552490234
Post-attention Dropout: 0.001851797103881836
Post-attention residual: 0.0006203651428222656
LN2: 0.00069427490234375
MLP_h_4h: 0.07137775421142578
MLP_4h_h: 0.06866121292114258
Post-MLP residual: 0.0018529891967773438
Attention layer time: 0.22391891479492188
LN1: 0.0007140636444091797
QKV Transform: 0.05226540565490723
Flash: 0.008463621139526367
Attention linproj: 0.017089128494262695
Post-attention Dropout: 0.0018706321716308594
Post-attention residual: 0.0006196498870849609
LN2: 0.0006952285766601562
MLP_h_4h: 0.07232069969177246
MLP_4h_h: 0.06965017318725586
Post-MLP residual: 0.001833200454711914
Attention layer time: 0.2263932228088379
LN1: 0.0007140636444091797
QKV Transform: 0.05160641670227051
Flash: 0.008112907409667969
Attention linproj: 0.01673722267150879
Post-attention Dropout: 0.0018520355224609375
Post-attention residual: 0.0006215572357177734
LN2: 0.0006966590881347656
MLP_h_4h: 0.0706324577331543
MLP_4h_h: 0.0694584846496582
Post-MLP residual: 0.001855611801147461
Attention layer time: 0.22317266464233398
LN1: 0.0007116794586181641
QKV Transform: 0.05233025550842285
Flash: 0.008571863174438477
Attention linproj: 0.016733169555664062
Post-attention Dropout: 0.0018584728240966797
Post-attention residual: 0.0006208419799804688
LN2: 0.0006985664367675781
MLP_h_4h: 0.07172560691833496
MLP_4h_h: 0.0697946548461914
Post-MLP residual: 0.0018436908721923828
Attention layer time: 0.2257704734802246
LN1: 0.0007157325744628906
QKV Transform: 0.052785634994506836
Flash: 0.008143424987792969
Attention linproj: 0.017064571380615234
Post-attention Dropout: 0.00186920166015625
Post-attention residual: 0.0006201267242431641
LN2: 0.0006990432739257812
MLP_h_4h: 0.07231903076171875
MLP_4h_h: 0.0697946548461914
Post-MLP residual: 0.0018625259399414062
Attention layer time: 0.226759672164917
LN1: 0.0007126331329345703
QKV Transform: 0.05153059959411621
Flash: 0.008091211318969727
Attention linproj: 0.016730785369873047
Post-attention Dropout: 0.0018563270568847656
Post-attention residual: 0.000621795654296875
LN2: 0.000698089599609375
MLP_h_4h: 0.07096338272094727
MLP_4h_h: 0.06949996948242188
Post-MLP residual: 0.0018434524536132812
Attention layer time: 0.22341251373291016
LN1: 0.0007116794586181641
QKV Transform: 0.05195760726928711
Flash: 0.007789134979248047
Attention linproj: 0.01657581329345703
Post-attention Dropout: 0.0018506050109863281
Post-attention residual: 0.0006206035614013672
LN2: 0.0006940364837646484
MLP_h_4h: 0.07108664512634277
MLP_4h_h: 0.06944775581359863
Post-MLP residual: 0.0018508434295654297
Attention layer time: 0.22344303131103516
LN1: 0.0007183551788330078
QKV Transform: 0.05325889587402344
Flash: 0.00790858268737793
Attention linproj: 0.016800403594970703
Post-attention Dropout: 0.001859903335571289
Post-attention residual: 0.0006208419799804688
LN2: 0.0006973743438720703
MLP_h_4h: 0.07118535041809082
MLP_4h_h: 0.06945228576660156
Post-MLP residual: 0.0018668174743652344
Attention layer time: 0.22524213790893555
LN1: 0.000732421875
QKV Transform: 0.0523526668548584
Flash: 0.008173942565917969
Attention linproj: 0.016964435577392578
Post-attention Dropout: 0.0018584728240966797
Post-attention residual: 0.0006182193756103516
LN2: 0.0006966590881347656
MLP_h_4h: 0.07213759422302246
MLP_4h_h: 0.06973099708557129
Post-MLP residual: 0.0018534660339355469
Attention layer time: 0.22599005699157715
LN1: 0.0007109642028808594
QKV Transform: 0.05211997032165527
Flash: 0.00868368148803711
Attention linproj: 0.016565799713134766
Post-attention Dropout: 0.0018727779388427734
Post-attention residual: 0.0006227493286132812
LN2: 0.0006966590881347656
MLP_h_4h: 0.07095742225646973
MLP_4h_h: 0.06905889511108398
Post-MLP residual: 0.0018525123596191406
Attention layer time: 0.22400951385498047
LN1: 0.0007176399230957031
QKV Transform: 0.05280470848083496
Flash: 0.008005857467651367
Attention linproj: 0.016802549362182617
Post-attention Dropout: 0.0018568038940429688
Post-attention residual: 0.0006182193756103516
LN2: 0.0006976127624511719
MLP_h_4h: 0.07171988487243652
MLP_4h_h: 0.06882095336914062
Post-MLP residual: 0.0018520355224609375
Attention layer time: 0.22475576400756836
LN1: 0.0007114410400390625
QKV Transform: 0.05212140083312988
Flash: 0.00877070426940918
Attention linproj: 0.016869544982910156
Post-attention Dropout: 0.0018620491027832031
Post-attention residual: 0.0006196498870849609
LN2: 0.0006966590881347656
MLP_h_4h: 0.07140469551086426
MLP_4h_h: 0.0693352222442627
Post-MLP residual: 0.001855611801147461
Attention layer time: 0.22513699531555176
LN1: 0.0007162094116210938
QKV Transform: 0.0521693229675293
Flash: 0.008517265319824219
Attention linproj: 0.01657867431640625
Post-attention Dropout: 0.001851797103881836
Post-attention residual: 0.0006215572357177734
LN2: 0.0006990432739257812
MLP_h_4h: 0.07146644592285156
MLP_4h_h: 0.06959867477416992
Post-MLP residual: 0.0018489360809326172
Attention layer time: 0.22493338584899902
LN1: 0.0007157325744628906
QKV Transform: 0.05203104019165039
Flash: 0.00809168815612793
Attention linproj: 0.016797780990600586
Post-attention Dropout: 0.0018587112426757812
Post-attention residual: 0.0006194114685058594
LN2: 0.0006949901580810547
MLP_h_4h: 0.07151579856872559
MLP_4h_h: 0.06883502006530762
Post-MLP residual: 0.0018434524536132812
Attention layer time: 0.2238914966583252
LN1: 0.0007107257843017578
QKV Transform: 0.05152606964111328
Flash: 0.008147478103637695
Attention linproj: 0.016726970672607422
Post-attention Dropout: 0.001851797103881836
Post-attention residual: 0.0006177425384521484
LN2: 0.0006937980651855469
MLP_h_4h: 0.0712578296661377
MLP_4h_h: 0.06975841522216797
Post-MLP residual: 0.0020241737365722656
Attention layer time: 0.22428584098815918
LN1: 0.000766754150390625
QKV Transform: 0.05184197425842285
Flash: 0.008066415786743164
Attention linproj: 0.0166170597076416
Post-attention Dropout: 0.0018680095672607422
Post-attention residual: 0.0006232261657714844
LN2: 0.0006966590881347656
MLP_h_4h: 0.07143592834472656
MLP_4h_h: 0.06966233253479004
Post-MLP residual: 0.0018463134765625
Attention layer time: 0.2243802547454834
LN1: 0.0007164478302001953
QKV Transform: 0.05255436897277832
Flash: 0.008258581161499023
Attention linproj: 0.01693415641784668
Post-attention Dropout: 0.0018672943115234375
Post-attention residual: 0.0006186962127685547
LN2: 0.0006952285766601562
MLP_h_4h: 0.07245802879333496
MLP_4h_h: 0.06883835792541504
Post-MLP residual: 0.0018508434295654297
Attention layer time: 0.22566843032836914
LN1: 0.00072479248046875
QKV Transform: 0.05159807205200195
Flash: 0.008139371871948242
Attention linproj: 0.016749143600463867
Post-attention Dropout: 0.001855611801147461
Post-attention residual: 0.0006220340728759766
LN2: 0.0006930828094482422
MLP_h_4h: 0.07098913192749023
MLP_4h_h: 0.06998205184936523
Post-MLP residual: 0.0018496513366699219
Attention layer time: 0.22406959533691406
LN1: 0.0007121562957763672
QKV Transform: 0.05206012725830078
Flash: 0.0087738037109375
Attention linproj: 0.01662421226501465
Post-attention Dropout: 0.001856088638305664
Post-attention residual: 0.0006196498870849609
LN2: 0.0006959438323974609
MLP_h_4h: 0.07071781158447266
MLP_4h_h: 0.06940221786499023
Post-MLP residual: 0.0018558502197265625
Attention layer time: 0.22420787811279297
LN1: 0.0007197856903076172
QKV Transform: 0.0529172420501709
Flash: 0.008619546890258789
Attention linproj: 0.016809701919555664
Post-attention Dropout: 0.0018625259399414062
Post-attention residual: 0.0006206035614013672
LN2: 0.0006940364837646484
MLP_h_4h: 0.07211184501647949
MLP_4h_h: 0.06929183006286621
Post-MLP residual: 0.0018544197082519531
Attention layer time: 0.2263658046722412
LN1: 0.0007197856903076172
QKV Transform: 0.05249428749084473
Flash: 0.008311033248901367
Attention linproj: 0.016857624053955078
Post-attention Dropout: 0.0018584728240966797
Post-attention residual: 0.0006234645843505859
LN2: 0.0006966590881347656
MLP_h_4h: 0.07065677642822266
MLP_4h_h: 0.06965994834899902
Post-MLP residual: 0.0018568038940429688
Attention layer time: 0.22464418411254883
LN1: 0.0007159709930419922
QKV Transform: 0.05215954780578613
Flash: 0.008736848831176758
Attention linproj: 0.016608238220214844
Post-attention Dropout: 0.0018537044525146484
Post-attention residual: 0.0006203651428222656
LN2: 0.0006937980651855469
MLP_h_4h: 0.07092118263244629
MLP_4h_h: 0.0691072940826416
Post-MLP residual: 0.0018477439880371094
Attention layer time: 0.22416067123413086
LN1: 0.0007176399230957031
QKV Transform: 0.05257272720336914
Flash: 0.008147478103637695
Attention linproj: 0.01680302619934082
Post-attention Dropout: 0.0018780231475830078
Post-attention residual: 0.0006206035614013672
LN2: 0.0006959438323974609
MLP_h_4h: 0.07154369354248047
MLP_4h_h: 0.06905889511108398
Post-MLP residual: 0.0018558502197265625
Attention layer time: 0.2247772216796875
LN1: 0.0007126331329345703
QKV Transform: 0.052257537841796875
Flash: 0.00864100456237793
Attention linproj: 0.01691913604736328
Post-attention Dropout: 0.0018622875213623047
Post-attention residual: 0.0006225109100341797
LN2: 0.0006966590881347656
MLP_h_4h: 0.0713801383972168
MLP_4h_h: 0.06935667991638184
Post-MLP residual: 0.0018463134765625
Attention layer time: 0.225175142288208
Transformer duration (in seconds): 0.2294
Transformer throughput (in TFLOP/s): 234.866
========================================================================================================================

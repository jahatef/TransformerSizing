num_attention_heads: 128, hidden_size: 16384, train_micro_batch_size_per_gpu: 4, tensor_mp_size: 1, pipeline_mp_size: 1, dp_size: 1

Actual
------
MLP duration (in seconds): 0.1414
MLP throughput (in TFLOP/s): 248.854
LN1: 0.00538182258605957
QKV Transform: 0.05148482322692871
Flash: 0.0078105926513671875
Attention linproj: 0.01678323745727539
Post-attention Dropout: 0.07263016700744629
Post-attention residual: 0.004481792449951172
LN2: 0.0007414817810058594
MLP_h_4h: 0.06799530982971191
MLP_4h_h: 0.06854605674743652
Post-MLP residual: 0.003475666046142578
Attention layer time: 0.30037736892700195
LN1: 0.0007178783416748047
QKV Transform: 0.05190849304199219
Flash: 0.008511543273925781
Attention linproj: 0.016796588897705078
Post-attention Dropout: 0.0018274784088134766
Post-attention residual: 0.0006036758422851562
LN2: 0.0006785392761230469
MLP_h_4h: 0.07147979736328125
MLP_4h_h: 0.06931877136230469
Post-MLP residual: 0.0018575191497802734
Attention layer time: 0.22457170486450195
LN1: 0.0007178783416748047
QKV Transform: 0.052504777908325195
Flash: 0.010503053665161133
Attention linproj: 0.01688551902770996
Post-attention Dropout: 0.0018513202667236328
Post-attention residual: 0.0006260871887207031
LN2: 0.0006954669952392578
MLP_h_4h: 0.0713963508605957
MLP_4h_h: 0.0689997673034668
Post-MLP residual: 0.0018470287322998047
Attention layer time: 0.2269153594970703
LN1: 0.0007195472717285156
QKV Transform: 0.05192089080810547
Flash: 0.008452653884887695
Attention linproj: 0.016683101654052734
Post-attention Dropout: 0.0018684864044189453
Post-attention residual: 0.0006191730499267578
LN2: 0.0006952285766601562
MLP_h_4h: 0.07149887084960938
MLP_4h_h: 0.0690605640411377
Post-MLP residual: 0.0018529891967773438
Attention layer time: 0.22423863410949707
LN1: 0.0007154941558837891
QKV Transform: 0.053087711334228516
Flash: 0.008141279220581055
Attention linproj: 0.017031431198120117
Post-attention Dropout: 0.0018634796142578125
Post-attention residual: 0.0006210803985595703
LN2: 0.0006947517395019531
MLP_h_4h: 0.07205963134765625
MLP_4h_h: 0.06965494155883789
Post-MLP residual: 0.0018551349639892578
Attention layer time: 0.22660493850708008
LN1: 0.0007140636444091797
QKV Transform: 0.0515592098236084
Flash: 0.00818943977355957
Attention linproj: 0.0166623592376709
Post-attention Dropout: 0.001871347427368164
Post-attention residual: 0.0006194114685058594
LN2: 0.0006935596466064453
MLP_h_4h: 0.07074975967407227
MLP_4h_h: 0.06925249099731445
Post-MLP residual: 0.001842498779296875
Attention layer time: 0.2230069637298584
LN1: 0.0007128715515136719
QKV Transform: 0.05311083793640137
Flash: 0.008398056030273438
Attention linproj: 0.016814231872558594
Post-attention Dropout: 0.001855611801147461
Post-attention residual: 0.0006237030029296875
LN2: 0.0006990432739257812
MLP_h_4h: 0.07134389877319336
MLP_4h_h: 0.06928443908691406
Post-MLP residual: 0.0018589496612548828
Attention layer time: 0.22556853294372559
LN1: 0.0007157325744628906
QKV Transform: 0.05247902870178223
Flash: 0.008456230163574219
Attention linproj: 0.016882658004760742
Post-attention Dropout: 0.0018591880798339844
Post-attention residual: 0.0006268024444580078
LN2: 0.0006952285766601562
MLP_h_4h: 0.07148456573486328
MLP_4h_h: 0.06878852844238281
Post-MLP residual: 0.0018534660339355469
Attention layer time: 0.22470974922180176
LN1: 0.0007138252258300781
QKV Transform: 0.05149722099304199
Flash: 0.008195877075195312
Attention linproj: 0.01664876937866211
Post-attention Dropout: 0.0018494129180908203
Post-attention residual: 0.0006220340728759766
LN2: 0.0006921291351318359
MLP_h_4h: 0.07146072387695312
MLP_4h_h: 0.07038426399230957
Post-MLP residual: 0.0018737316131591797
Attention layer time: 0.22480154037475586
LN1: 0.0007152557373046875
QKV Transform: 0.05238795280456543
Flash: 0.008269309997558594
Attention linproj: 0.016687870025634766
Post-attention Dropout: 0.0018603801727294922
Post-attention residual: 0.0006191730499267578
LN2: 0.0006935596466064453
MLP_h_4h: 0.0716853141784668
MLP_4h_h: 0.0692286491394043
Post-MLP residual: 0.001852273941040039
Attention layer time: 0.2248530387878418
LN1: 0.0007143020629882812
QKV Transform: 0.052498579025268555
Flash: 0.00836801528930664
Attention linproj: 0.01689600944519043
Post-attention Dropout: 0.0018591880798339844
Post-attention residual: 0.0006222724914550781
LN2: 0.0006949901580810547
MLP_h_4h: 0.0719294548034668
MLP_4h_h: 0.06971955299377441
Post-MLP residual: 0.0018720626831054688
Attention layer time: 0.22603702545166016
LN1: 0.0007128715515136719
QKV Transform: 0.0518488883972168
Flash: 0.007950782775878906
Attention linproj: 0.016828298568725586
Post-attention Dropout: 0.0018663406372070312
Post-attention residual: 0.0006215572357177734
LN2: 0.0006964206695556641
MLP_h_4h: 0.07164883613586426
MLP_4h_h: 0.06963562965393066
Post-MLP residual: 0.001844644546508789
Attention layer time: 0.2245192527770996
LN1: 0.0007162094116210938
QKV Transform: 0.05244755744934082
Flash: 0.007998228073120117
Attention linproj: 0.016672372817993164
Post-attention Dropout: 0.0018558502197265625
Post-attention residual: 0.0006210803985595703
LN2: 0.0006964206695556641
MLP_h_4h: 0.07141733169555664
MLP_4h_h: 0.06946539878845215
Post-MLP residual: 0.0018715858459472656
Attention layer time: 0.224639892578125
LN1: 0.0007200241088867188
QKV Transform: 0.05272793769836426
Flash: 0.00798344612121582
Attention linproj: 0.016815900802612305
Post-attention Dropout: 0.0018625259399414062
Post-attention residual: 0.0006222724914550781
LN2: 0.0006949901580810547
MLP_h_4h: 0.0711514949798584
MLP_4h_h: 0.06883645057678223
Post-MLP residual: 0.001836538314819336
Attention layer time: 0.22411251068115234
LN1: 0.0007150173187255859
QKV Transform: 0.051672935485839844
Flash: 0.008040666580200195
Attention linproj: 0.01685476303100586
Post-attention Dropout: 0.001857757568359375
Post-attention residual: 0.0006194114685058594
LN2: 0.0006978511810302734
MLP_h_4h: 0.07092761993408203
MLP_4h_h: 0.06952714920043945
Post-MLP residual: 0.001844644546508789
Attention layer time: 0.22361350059509277
LN1: 0.0007114410400390625
QKV Transform: 0.05189704895019531
Flash: 0.007866859436035156
Attention linproj: 0.016823291778564453
Post-attention Dropout: 0.001859426498413086
Post-attention residual: 0.0006210803985595703
LN2: 0.0006933212280273438
MLP_h_4h: 0.0722053050994873
MLP_4h_h: 0.06912040710449219
Post-MLP residual: 0.0018434524536132812
Attention layer time: 0.22450542449951172
LN1: 0.0007157325744628906
QKV Transform: 0.05318331718444824
Flash: 0.008651971817016602
Attention linproj: 0.01691889762878418
Post-attention Dropout: 0.0018558502197265625
Post-attention residual: 0.0006210803985595703
LN2: 0.000698089599609375
MLP_h_4h: 0.07201838493347168
MLP_4h_h: 0.07008218765258789
Post-MLP residual: 0.001865386962890625
Attention layer time: 0.2274794578552246
LN1: 0.0007319450378417969
QKV Transform: 0.052460670471191406
Flash: 0.008235454559326172
Attention linproj: 0.016839981079101562
Post-attention Dropout: 0.0018563270568847656
Post-attention residual: 0.0006198883056640625
LN2: 0.0006961822509765625
MLP_h_4h: 0.07050204277038574
MLP_4h_h: 0.06871533393859863
Post-MLP residual: 0.0018436908721923828
Attention layer time: 0.22338390350341797
LN1: 0.0007112026214599609
QKV Transform: 0.05132484436035156
Flash: 0.008378028869628906
Attention linproj: 0.01663994789123535
Post-attention Dropout: 0.0018496513366699219
Post-attention residual: 0.0006208419799804688
LN2: 0.00069427490234375
MLP_h_4h: 0.07083821296691895
MLP_4h_h: 0.06921935081481934
Post-MLP residual: 0.0018477439880371094
Attention layer time: 0.22297930717468262
LN1: 0.0007307529449462891
QKV Transform: 0.05265998840332031
Flash: 0.008080005645751953
Attention linproj: 0.01664900779724121
Post-attention Dropout: 0.0018663406372070312
Post-attention residual: 0.0006194114685058594
LN2: 0.0006945133209228516
MLP_h_4h: 0.07159757614135742
MLP_4h_h: 0.06925463676452637
Post-MLP residual: 0.001856088638305664
Attention layer time: 0.22486591339111328
LN1: 0.0007159709930419922
QKV Transform: 0.05260610580444336
Flash: 0.008292198181152344
Attention linproj: 0.01700878143310547
Post-attention Dropout: 0.0018641948699951172
Post-attention residual: 0.0006196498870849609
LN2: 0.0007004737854003906
MLP_h_4h: 0.07239532470703125
MLP_4h_h: 0.06882262229919434
Post-MLP residual: 0.0018513202667236328
Attention layer time: 0.22577667236328125
LN1: 0.0007116794586181641
QKV Transform: 0.05150341987609863
Flash: 0.00816655158996582
Attention linproj: 0.016742467880249023
Post-attention Dropout: 0.0018482208251953125
Post-attention residual: 0.0006227493286132812
LN2: 0.000705718994140625
MLP_h_4h: 0.07087421417236328
MLP_4h_h: 0.0694284439086914
Post-MLP residual: 0.001863718032836914
Attention layer time: 0.22333550453186035
LN1: 0.0007119178771972656
QKV Transform: 0.05201911926269531
Flash: 0.00855708122253418
Attention linproj: 0.016588687896728516
Post-attention Dropout: 0.0018584728240966797
Post-attention residual: 0.000621795654296875
LN2: 0.0006949901580810547
MLP_h_4h: 0.0709238052368164
MLP_4h_h: 0.06894803047180176
Post-MLP residual: 0.0018486976623535156
Attention layer time: 0.22362422943115234
LN1: 0.0007171630859375
QKV Transform: 0.05306434631347656
Flash: 0.008718013763427734
Attention linproj: 0.016808509826660156
Post-attention Dropout: 0.0018618106842041016
Post-attention residual: 0.0006201267242431641
LN2: 0.0006985664367675781
MLP_h_4h: 0.07089543342590332
MLP_4h_h: 0.06899189949035645
Post-MLP residual: 0.0018515586853027344
Attention layer time: 0.22509479522705078
LN1: 0.0007143020629882812
QKV Transform: 0.05163145065307617
Flash: 0.008030891418457031
Attention linproj: 0.016749858856201172
Post-attention Dropout: 0.0018527507781982422
Post-attention residual: 0.0006222724914550781
LN2: 0.0007009506225585938
MLP_h_4h: 0.07084965705871582
MLP_4h_h: 0.06934857368469238
Post-MLP residual: 0.0018603801727294922
Attention layer time: 0.22324728965759277
LN1: 0.0007174015045166016
QKV Transform: 0.05206298828125
Flash: 0.008746862411499023
Attention linproj: 0.016675233840942383
Post-attention Dropout: 0.0018527507781982422
Post-attention residual: 0.0006208419799804688
LN2: 0.0006961822509765625
MLP_h_4h: 0.07091522216796875
MLP_4h_h: 0.06935477256774902
Post-MLP residual: 0.0018427371978759766
Attention layer time: 0.22437596321105957
LN1: 0.0007169246673583984
QKV Transform: 0.052788496017456055
Flash: 0.008661746978759766
Attention linproj: 0.016824007034301758
Post-attention Dropout: 0.0018541812896728516
Post-attention residual: 0.0006237030029296875
LN2: 0.0006961822509765625
MLP_h_4h: 0.07149362564086914
MLP_4h_h: 0.06972074508666992
Post-MLP residual: 0.001863241195678711
Attention layer time: 0.22613787651062012
LN1: 0.0007152557373046875
QKV Transform: 0.05211830139160156
Flash: 0.007885217666625977
Attention linproj: 0.016859054565429688
Post-attention Dropout: 0.0018734931945800781
Post-attention residual: 0.0006210803985595703
LN2: 0.0006966590881347656
MLP_h_4h: 0.07118391990661621
MLP_4h_h: 0.06876301765441895
Post-MLP residual: 0.0018432140350341797
Attention layer time: 0.22343230247497559
LN1: 0.0007135868072509766
QKV Transform: 0.05138516426086426
Flash: 0.008338689804077148
Attention linproj: 0.01669144630432129
Post-attention Dropout: 0.0018656253814697266
Post-attention residual: 0.0006244182586669922
LN2: 0.0006957054138183594
MLP_h_4h: 0.07091426849365234
MLP_4h_h: 0.06949210166931152
Post-MLP residual: 0.0018610954284667969
Attention layer time: 0.22344684600830078
LN1: 0.0007145404815673828
QKV Transform: 0.05247831344604492
Flash: 0.008260011672973633
Attention linproj: 0.016641855239868164
Post-attention Dropout: 0.0018682479858398438
Post-attention residual: 0.0006208419799804688
LN2: 0.0007081031799316406
MLP_h_4h: 0.07122945785522461
MLP_4h_h: 0.06920862197875977
Post-MLP residual: 0.0018651485443115234
Attention layer time: 0.22445249557495117
LN1: 0.0007176399230957031
QKV Transform: 0.05255770683288574
Flash: 0.008233070373535156
Attention linproj: 0.016791820526123047
Post-attention Dropout: 0.0018565654754638672
Post-attention residual: 0.0006208419799804688
LN2: 0.0006961822509765625
MLP_h_4h: 0.07049083709716797
MLP_4h_h: 0.06925630569458008
Post-MLP residual: 0.0018770694732666016
Attention layer time: 0.2239689826965332
LN1: 0.0007166862487792969
QKV Transform: 0.05191850662231445
Flash: 0.008553743362426758
Attention linproj: 0.01687169075012207
Post-attention Dropout: 0.0019562244415283203
Post-attention residual: 0.0006234645843505859
LN2: 0.0007512569427490234
MLP_h_4h: 0.07138419151306152
MLP_4h_h: 0.06959342956542969
Post-MLP residual: 0.0018565654754638672
Attention layer time: 0.22520804405212402
LN1: 0.0007174015045166016
QKV Transform: 0.0518946647644043
Flash: 0.007808208465576172
Attention linproj: 0.016570568084716797
Post-attention Dropout: 0.0018639564514160156
Post-attention residual: 0.0006186962127685547
LN2: 0.0006947517395019531
MLP_h_4h: 0.07116055488586426
MLP_4h_h: 0.06925415992736816
Post-MLP residual: 0.0018451213836669922
Attention layer time: 0.22337985038757324
LN1: 0.0007166862487792969
QKV Transform: 0.05317234992980957
Flash: 0.008677482604980469
Attention linproj: 0.016788959503173828
Post-attention Dropout: 0.0018749237060546875
Post-attention residual: 0.000621795654296875
LN2: 0.0006964206695556641
MLP_h_4h: 0.07109808921813965
MLP_4h_h: 0.06929349899291992
Post-MLP residual: 0.0018627643585205078
Attention layer time: 0.22565984725952148
LN1: 0.0007166862487792969
QKV Transform: 0.05252242088317871
Flash: 0.008300304412841797
Attention linproj: 0.017023801803588867
Post-attention Dropout: 0.0018565654754638672
Post-attention residual: 0.0006194114685058594
LN2: 0.0006966590881347656
MLP_h_4h: 0.07201814651489258
MLP_4h_h: 0.07042789459228516
Post-MLP residual: 0.0018663406372070312
Attention layer time: 0.2269272804260254
LN1: 0.0007147789001464844
QKV Transform: 0.05206441879272461
Flash: 0.007881402969360352
Attention linproj: 0.016715526580810547
Post-attention Dropout: 0.0018596649169921875
Post-attention residual: 0.0006206035614013672
LN2: 0.00069427490234375
MLP_h_4h: 0.07158994674682617
MLP_4h_h: 0.06969189643859863
Post-MLP residual: 0.0018336772918701172
Attention layer time: 0.22452783584594727
LN1: 0.0007131099700927734
QKV Transform: 0.05264616012573242
Flash: 0.008095264434814453
Attention linproj: 0.016831159591674805
Post-attention Dropout: 0.0018558502197265625
Post-attention residual: 0.0006186962127685547
LN2: 0.0006988048553466797
MLP_h_4h: 0.07139396667480469
MLP_4h_h: 0.06966209411621094
Post-MLP residual: 0.0018627643585205078
Attention layer time: 0.22524380683898926
LN1: 0.0007152557373046875
QKV Transform: 0.05208706855773926
Flash: 0.008746147155761719
Attention linproj: 0.016844511032104492
Post-attention Dropout: 0.0018727779388427734
Post-attention residual: 0.0006186962127685547
LN2: 0.0006928443908691406
MLP_h_4h: 0.07058334350585938
MLP_4h_h: 0.06878805160522461
Post-MLP residual: 0.001834869384765625
Attention layer time: 0.22367119789123535
LN1: 0.0007333755493164062
QKV Transform: 0.05133318901062012
Flash: 0.00809788703918457
Attention linproj: 0.016713619232177734
Post-attention Dropout: 0.0018532276153564453
Post-attention residual: 0.0006210803985595703
LN2: 0.0006968975067138672
MLP_h_4h: 0.07091760635375977
MLP_4h_h: 0.06938290596008301
Post-MLP residual: 0.0018489360809326172
Attention layer time: 0.2230668067932129
LN1: 0.0007107257843017578
QKV Transform: 0.052440643310546875
Flash: 0.008362531661987305
Attention linproj: 0.016669750213623047
Post-attention Dropout: 0.0018572807312011719
Post-attention residual: 0.0006210803985595703
LN2: 0.0006954669952392578
MLP_h_4h: 0.07143592834472656
MLP_4h_h: 0.06922221183776855
Post-MLP residual: 0.0018541812896728516
Attention layer time: 0.22473788261413574
LN1: 0.0007185935974121094
QKV Transform: 0.05278277397155762
Flash: 0.008005619049072266
Attention linproj: 0.01681351661682129
Post-attention Dropout: 0.0018739700317382812
Post-attention residual: 0.0006186962127685547
LN2: 0.0006940364837646484
MLP_h_4h: 0.0713953971862793
MLP_4h_h: 0.07077860832214355
Post-MLP residual: 0.0019440650939941406
Attention layer time: 0.2265458106994629
LN1: 0.0007381439208984375
QKV Transform: 0.05263352394104004
Flash: 0.008312463760375977
Attention linproj: 0.016799449920654297
Post-attention Dropout: 0.0018601417541503906
Post-attention residual: 0.0006244182586669922
LN2: 0.0007152557373046875
MLP_h_4h: 0.0712428092956543
MLP_4h_h: 0.06893467903137207
Post-MLP residual: 0.0018367767333984375
Attention layer time: 0.22463440895080566
LN1: 0.0007126331329345703
QKV Transform: 0.052393436431884766
Flash: 0.008358001708984375
Attention linproj: 0.016646385192871094
Post-attention Dropout: 0.0018587112426757812
Post-attention residual: 0.0006206035614013672
LN2: 0.0006947517395019531
MLP_h_4h: 0.0714106559753418
MLP_4h_h: 0.06929278373718262
Post-MLP residual: 0.0018658638000488281
Attention layer time: 0.22470951080322266
LN1: 0.0007150173187255859
QKV Transform: 0.05261564254760742
Flash: 0.008157968521118164
Attention linproj: 0.01679515838623047
Post-attention Dropout: 0.0018618106842041016
Post-attention residual: 0.0006208419799804688
LN2: 0.0006973743438720703
MLP_h_4h: 0.07036375999450684
MLP_4h_h: 0.06857585906982422
Post-MLP residual: 0.0018358230590820312
Attention layer time: 0.22311902046203613
LN1: 0.0007119178771972656
QKV Transform: 0.05148744583129883
Flash: 0.008186578750610352
Attention linproj: 0.016725778579711914
Post-attention Dropout: 0.0018579959869384766
Post-attention residual: 0.0006191730499267578
LN2: 0.0006952285766601562
MLP_h_4h: 0.07087564468383789
MLP_4h_h: 0.06989741325378418
Post-MLP residual: 0.001850128173828125
Attention layer time: 0.2237703800201416
LN1: 0.0007123947143554688
QKV Transform: 0.05190134048461914
Flash: 0.007869482040405273
Attention linproj: 0.016712665557861328
Post-attention Dropout: 0.001873016357421875
Post-attention residual: 0.0006213188171386719
LN2: 0.0006930828094482422
MLP_h_4h: 0.07100033760070801
MLP_4h_h: 0.06982135772705078
Post-MLP residual: 0.001844644546508789
Attention layer time: 0.2239093780517578
LN1: 0.0007128715515136719
QKV Transform: 0.052591800689697266
Flash: 0.008095264434814453
Attention linproj: 0.01679062843322754
Post-attention Dropout: 0.001859903335571289
Post-attention residual: 0.0006201267242431641
LN2: 0.0006976127624511719
MLP_h_4h: 0.07118463516235352
MLP_4h_h: 0.0693812370300293
Post-MLP residual: 0.0018625259399414062
Attention layer time: 0.22467303276062012
LN1: 0.0007159709930419922
QKV Transform: 0.05243039131164551
Flash: 0.008415699005126953
Attention linproj: 0.016872644424438477
Post-attention Dropout: 0.0018699169158935547
Post-attention residual: 0.0006198883056640625
LN2: 0.0006935596466064453
MLP_h_4h: 0.07179594039916992
MLP_4h_h: 0.06964850425720215
Post-MLP residual: 0.0018527507781982422
Attention layer time: 0.2257859706878662
LN1: 0.0007145404815673828
QKV Transform: 0.05153250694274902
Flash: 0.008080244064331055
Attention linproj: 0.016694307327270508
Post-attention Dropout: 0.0018544197082519531
Post-attention residual: 0.0006234645843505859
LN2: 0.00069427490234375
MLP_h_4h: 0.07103514671325684
MLP_4h_h: 0.06959271430969238
Post-MLP residual: 0.0018527507781982422
Attention layer time: 0.22354364395141602
LN1: 0.0007126331329345703
QKV Transform: 0.05314040184020996
Flash: 0.008412599563598633
Attention linproj: 0.016640186309814453
Post-attention Dropout: 0.0018610954284667969
Post-attention residual: 0.0006189346313476562
LN2: 0.0006988048553466797
MLP_h_4h: 0.0715799331665039
MLP_4h_h: 0.06920242309570312
Post-MLP residual: 0.0018568038940429688
Attention layer time: 0.22558355331420898
LN1: 0.0007164478302001953
QKV Transform: 0.05249953269958496
Flash: 0.008385896682739258
Attention linproj: 0.016893625259399414
Post-attention Dropout: 0.0018658638000488281
Post-attention residual: 0.0006196498870849609
LN2: 0.0006954669952392578
MLP_h_4h: 0.07186508178710938
MLP_4h_h: 0.06876921653747559
Post-MLP residual: 0.0018486976623535156
Attention layer time: 0.2250211238861084
LN1: 0.0007114410400390625
QKV Transform: 0.05135965347290039
Flash: 0.008355855941772461
Attention linproj: 0.016717195510864258
Post-attention Dropout: 0.001863718032836914
Post-attention residual: 0.0006210803985595703
LN2: 0.0006937980651855469
MLP_h_4h: 0.07062959671020508
MLP_4h_h: 0.06910991668701172
Post-MLP residual: 0.0018496513366699219
Attention layer time: 0.22276759147644043
LN1: 0.000713348388671875
QKV Transform: 0.052068471908569336
Flash: 0.008731365203857422
Attention linproj: 0.0166018009185791
Post-attention Dropout: 0.0018520355224609375
Post-attention residual: 0.00061798095703125
LN2: 0.0006940364837646484
MLP_h_4h: 0.0713200569152832
MLP_4h_h: 0.06955838203430176
Post-MLP residual: 0.0018591880798339844
Attention layer time: 0.22490763664245605
LN1: 0.0007138252258300781
QKV Transform: 0.05245828628540039
Flash: 0.008406400680541992
Attention linproj: 0.017240285873413086
Post-attention Dropout: 0.0018672943115234375
Post-attention residual: 0.0006198883056640625
LN2: 0.0006995201110839844
MLP_h_4h: 0.0716700553894043
MLP_4h_h: 0.06977248191833496
Post-MLP residual: 0.0018863677978515625
Attention layer time: 0.22629570960998535
LN1: 0.0007259845733642578
QKV Transform: 0.0516200065612793
Flash: 0.007971048355102539
Attention linproj: 0.01670217514038086
Post-attention Dropout: 0.0018723011016845703
Post-attention residual: 0.0006241798400878906
LN2: 0.0006937980651855469
MLP_h_4h: 0.07103562355041504
MLP_4h_h: 0.06979751586914062
Post-MLP residual: 0.0018532276153564453
Attention layer time: 0.22379088401794434
LN1: 0.0007140636444091797
QKV Transform: 0.051772117614746094
Flash: 0.007972478866577148
Attention linproj: 0.016718387603759766
Post-attention Dropout: 0.0018603801727294922
Post-attention residual: 0.0006198883056640625
LN2: 0.0006947517395019531
MLP_h_4h: 0.07133960723876953
MLP_4h_h: 0.0694732666015625
Post-MLP residual: 0.0018453598022460938
Attention layer time: 0.22386908531188965
LN1: 0.0007147789001464844
QKV Transform: 0.05333232879638672
Flash: 0.008463859558105469
Attention linproj: 0.016797542572021484
Post-attention Dropout: 0.0018618106842041016
Post-attention residual: 0.0006198883056640625
LN2: 0.0006978511810302734
MLP_h_4h: 0.07215452194213867
MLP_4h_h: 0.06891751289367676
Post-MLP residual: 0.0018489360809326172
Attention layer time: 0.2262709140777588
LN1: 0.0007147789001464844
QKV Transform: 0.05204963684082031
Flash: 0.007844686508178711
Attention linproj: 0.016889095306396484
Post-attention Dropout: 0.0018575191497802734
Post-attention residual: 0.0006210803985595703
LN2: 0.00069427490234375
MLP_h_4h: 0.07173824310302734
MLP_4h_h: 0.06974935531616211
Post-MLP residual: 0.0018460750579833984
Attention layer time: 0.22488713264465332
LN1: 0.0007147789001464844
QKV Transform: 0.05137753486633301
Flash: 0.008327484130859375
Attention linproj: 0.016634464263916016
Post-attention Dropout: 0.0018475055694580078
Post-attention residual: 0.0006184577941894531
LN2: 0.0007071495056152344
MLP_h_4h: 0.07134461402893066
MLP_4h_h: 0.06978511810302734
Post-MLP residual: 0.0018565654754638672
Attention layer time: 0.22407007217407227
LN1: 0.0007131099700927734
QKV Transform: 0.052762508392333984
Flash: 0.00799417495727539
Attention linproj: 0.016811370849609375
Post-attention Dropout: 0.0018756389617919922
Post-attention residual: 0.0006198883056640625
LN2: 0.0006983280181884766
MLP_h_4h: 0.07155609130859375
MLP_4h_h: 0.06862258911132812
Post-MLP residual: 0.001847982406616211
Attention layer time: 0.22438669204711914
LN1: 0.0007123947143554688
QKV Transform: 0.05207347869873047
Flash: 0.007843494415283203
Attention linproj: 0.016911983489990234
Post-attention Dropout: 0.0018649101257324219
Post-attention residual: 0.0006196498870849609
LN2: 0.0006973743438720703
MLP_h_4h: 0.07272958755493164
MLP_4h_h: 0.07035279273986816
Post-MLP residual: 0.0018546581268310547
Attention layer time: 0.22652816772460938
LN1: 0.0007131099700927734
QKV Transform: 0.05152249336242676
Flash: 0.008156776428222656
Attention linproj: 0.016655921936035156
Post-attention Dropout: 0.0018529891967773438
Post-attention residual: 0.0006196498870849609
LN2: 0.0006971359252929688
MLP_h_4h: 0.07127189636230469
MLP_4h_h: 0.06972861289978027
Post-MLP residual: 0.0018546581268310547
Attention layer time: 0.2239670753479004
LN1: 0.0007236003875732422
QKV Transform: 0.05248403549194336
Flash: 0.008256673812866211
Attention linproj: 0.01666998863220215
Post-attention Dropout: 0.001855611801147461
Post-attention residual: 0.0006222724914550781
LN2: 0.0006990432739257812
MLP_h_4h: 0.0720968246459961
MLP_4h_h: 0.06994199752807617
Post-MLP residual: 0.0018620491027832031
Attention layer time: 0.22610187530517578
LN1: 0.0007162094116210938
QKV Transform: 0.05249142646789551
Flash: 0.008302927017211914
Attention linproj: 0.017009496688842773
Post-attention Dropout: 0.001861572265625
Post-attention residual: 0.0006229877471923828
LN2: 0.0006968975067138672
MLP_h_4h: 0.07173347473144531
MLP_4h_h: 0.06931495666503906
Post-MLP residual: 0.0018393993377685547
Attention layer time: 0.22546100616455078
LN1: 0.0007126331329345703
QKV Transform: 0.051605939865112305
Flash: 0.00819087028503418
Attention linproj: 0.01667332649230957
Post-attention Dropout: 0.0018551349639892578
Post-attention residual: 0.0006194114685058594
LN2: 0.0006973743438720703
MLP_h_4h: 0.07139229774475098
MLP_4h_h: 0.06954479217529297
Post-MLP residual: 0.0018498897552490234
Attention layer time: 0.22400593757629395
LN1: 0.0007171630859375
QKV Transform: 0.052428245544433594
Flash: 0.008294105529785156
Attention linproj: 0.016835927963256836
Post-attention Dropout: 0.001861572265625
Post-attention residual: 0.0006213188171386719
LN2: 0.0006945133209228516
MLP_h_4h: 0.0713348388671875
MLP_4h_h: 0.0693655014038086
Post-MLP residual: 0.0018646717071533203
Attention layer time: 0.22491216659545898
LN1: 0.0007140636444091797
QKV Transform: 0.052486419677734375
Flash: 0.00835108757019043
Attention linproj: 0.01698899269104004
Post-attention Dropout: 0.0018644332885742188
Post-attention residual: 0.000621795654296875
LN2: 0.0006973743438720703
MLP_h_4h: 0.0714883804321289
MLP_4h_h: 0.06955075263977051
Post-MLP residual: 0.0018570423126220703
Attention layer time: 0.22551393508911133
LN1: 0.0007131099700927734
QKV Transform: 0.05200648307800293
Flash: 0.007767677307128906
Attention linproj: 0.016706466674804688
Post-attention Dropout: 0.0018515586853027344
Post-attention residual: 0.0006225109100341797
LN2: 0.0006964206695556641
MLP_h_4h: 0.07138538360595703
MLP_4h_h: 0.06958246231079102
Post-MLP residual: 0.0018465518951416016
Attention layer time: 0.2240464687347412
LN1: 0.0007138252258300781
QKV Transform: 0.0519566535949707
Flash: 0.008687257766723633
Attention linproj: 0.01656031608581543
Post-attention Dropout: 0.001867055892944336
Post-attention residual: 0.0006203651428222656
LN2: 0.0006940364837646484
MLP_h_4h: 0.07088923454284668
MLP_4h_h: 0.06909608840942383
Post-MLP residual: 0.001861572265625
Attention layer time: 0.22379541397094727
LN1: 0.0007171630859375
QKV Transform: 0.052654266357421875
Flash: 0.008168458938598633
Attention linproj: 0.01678776741027832
Post-attention Dropout: 0.0018572807312011719
Post-attention residual: 0.0006198883056640625
LN2: 0.0006940364837646484
MLP_h_4h: 0.07121157646179199
MLP_4h_h: 0.06954717636108398
Post-MLP residual: 0.001859903335571289
Attention layer time: 0.22497773170471191
LN1: 0.0007169246673583984
QKV Transform: 0.05192160606384277
Flash: 0.007869720458984375
Attention linproj: 0.016826868057250977
Post-attention Dropout: 0.0018558502197265625
Post-attention residual: 0.0006172657012939453
LN2: 0.0006976127624511719
MLP_h_4h: 0.07126688957214355
MLP_4h_h: 0.0692899227142334
Post-MLP residual: 0.001850128173828125
Attention layer time: 0.22379398345947266
LN1: 0.0007119178771972656
QKV Transform: 0.05210447311401367
Flash: 0.008708000183105469
Attention linproj: 0.01658773422241211
Post-attention Dropout: 0.00185394287109375
Post-attention residual: 0.0006265640258789062
LN2: 0.0006971359252929688
MLP_h_4h: 0.07112455368041992
MLP_4h_h: 0.06921839714050293
Post-MLP residual: 0.0018401145935058594
Attention layer time: 0.22434139251708984
LN1: 0.0007178783416748047
QKV Transform: 0.05271005630493164
Flash: 0.008090734481811523
Attention linproj: 0.01680159568786621
Post-attention Dropout: 0.0018568038940429688
Post-attention residual: 0.0006198883056640625
LN2: 0.0006937980651855469
MLP_h_4h: 0.07108783721923828
MLP_4h_h: 0.06941676139831543
Post-MLP residual: 0.001874685287475586
Attention layer time: 0.22472739219665527
LN1: 0.0007140636444091797
QKV Transform: 0.0524289608001709
Flash: 0.008427143096923828
Attention linproj: 0.016948938369750977
Post-attention Dropout: 0.0018584728240966797
Post-attention residual: 0.0006191730499267578
LN2: 0.0006947517395019531
MLP_h_4h: 0.07145547866821289
MLP_4h_h: 0.06958389282226562
Post-MLP residual: 0.0018658638000488281
Attention layer time: 0.22546958923339844
LN1: 0.0007126331329345703
QKV Transform: 0.051961421966552734
Flash: 0.007829427719116211
Attention linproj: 0.016591548919677734
Post-attention Dropout: 0.0018641948699951172
Post-attention residual: 0.0006237030029296875
LN2: 0.0006968975067138672
MLP_h_4h: 0.07088112831115723
MLP_4h_h: 0.06909298896789551
Post-MLP residual: 0.0018544197082519531
Attention layer time: 0.22298383712768555
LN1: 0.000713348388671875
QKV Transform: 0.05260491371154785
Flash: 0.008214473724365234
Attention linproj: 0.017124176025390625
Post-attention Dropout: 0.0018639564514160156
Post-attention residual: 0.0006210803985595703
LN2: 0.0006959438323974609
MLP_h_4h: 0.07195925712585449
MLP_4h_h: 0.06913352012634277
Post-MLP residual: 0.0018544197082519531
Attention layer time: 0.22566723823547363
LN1: 0.0007162094116210938
QKV Transform: 0.05265498161315918
Flash: 0.00811624526977539
Attention linproj: 0.0171966552734375
Post-attention Dropout: 0.001873016357421875
Post-attention residual: 0.0006208419799804688
LN2: 0.0006988048553466797
MLP_h_4h: 0.07129454612731934
MLP_4h_h: 0.06915140151977539
Post-MLP residual: 0.001855611801147461
Attention layer time: 0.22506141662597656
LN1: 0.0007140636444091797
QKV Transform: 0.05175971984863281
Flash: 0.008005619049072266
Attention linproj: 0.016819000244140625
Post-attention Dropout: 0.0018723011016845703
Post-attention residual: 0.0006234645843505859
LN2: 0.0006973743438720703
MLP_h_4h: 0.07082700729370117
MLP_4h_h: 0.06951570510864258
Post-MLP residual: 0.0018587112426757812
Attention layer time: 0.22356128692626953
LN1: 0.0007112026214599609
QKV Transform: 0.05254817008972168
Flash: 0.008206605911254883
Attention linproj: 0.016694068908691406
Post-attention Dropout: 0.0018546581268310547
Post-attention residual: 0.0006210803985595703
LN2: 0.0006966590881347656
MLP_h_4h: 0.07118558883666992
MLP_4h_h: 0.06935906410217285
Post-MLP residual: 0.0018870830535888672
Attention layer time: 0.22463750839233398
LN1: 0.0007283687591552734
QKV Transform: 0.05264115333557129
Flash: 0.008147239685058594
Attention linproj: 0.016799449920654297
Post-attention Dropout: 0.0018553733825683594
Post-attention residual: 0.0006206035614013672
LN2: 0.0006933212280273438
MLP_h_4h: 0.07165312767028809
MLP_4h_h: 0.06981778144836426
Post-MLP residual: 0.0018417835235595703
Attention layer time: 0.22565960884094238
LN1: 0.0007123947143554688
QKV Transform: 0.05191469192504883
Flash: 0.007880210876464844
Attention linproj: 0.016797780990600586
Post-attention Dropout: 0.0018591880798339844
Post-attention residual: 0.0006189346313476562
LN2: 0.0006964206695556641
MLP_h_4h: 0.0721893310546875
MLP_4h_h: 0.06965303421020508
Post-MLP residual: 0.0018601417541503906
Attention layer time: 0.22505807876586914
LN1: 0.0007143020629882812
QKV Transform: 0.052440643310546875
Flash: 0.008317708969116211
Attention linproj: 0.016818761825561523
Post-attention Dropout: 0.0018618106842041016
Post-attention residual: 0.0006237030029296875
LN2: 0.0006959438323974609
MLP_h_4h: 0.07133698463439941
MLP_4h_h: 0.0692586898803711
Post-MLP residual: 0.0018575191497802734
Attention layer time: 0.2247915267944336
LN1: 0.0007128715515136719
QKV Transform: 0.05225729942321777
Flash: 0.008387565612792969
Attention linproj: 0.016988515853881836
Post-attention Dropout: 0.0018608570098876953
Post-attention residual: 0.0006208419799804688
LN2: 0.0006954669952392578
MLP_h_4h: 0.0719461441040039
MLP_4h_h: 0.0696561336517334
Post-MLP residual: 0.0018572807312011719
Attention layer time: 0.22586536407470703
LN1: 0.0007143020629882812
QKV Transform: 0.05145668983459473
Flash: 0.008244991302490234
Attention linproj: 0.016634225845336914
Post-attention Dropout: 0.0018568038940429688
Post-attention residual: 0.0006239414215087891
LN2: 0.0006978511810302734
MLP_h_4h: 0.07091426849365234
MLP_4h_h: 0.06913447380065918
Post-MLP residual: 0.0018451213836669922
Attention layer time: 0.22303414344787598
LN1: 0.0007135868072509766
QKV Transform: 0.052748918533325195
Flash: 0.008042335510253906
Attention linproj: 0.016651630401611328
Post-attention Dropout: 0.0018582344055175781
Post-attention residual: 0.0006220340728759766
LN2: 0.0006971359252929688
MLP_h_4h: 0.07129454612731934
MLP_4h_h: 0.06915926933288574
Post-MLP residual: 0.001873016357421875
Attention layer time: 0.22453641891479492
LN1: 0.0007176399230957031
QKV Transform: 0.05270099639892578
Flash: 0.00823354721069336
Attention linproj: 0.017001628875732422
Post-attention Dropout: 0.0018677711486816406
Post-attention residual: 0.0006194114685058594
LN2: 0.0006940364837646484
MLP_h_4h: 0.07265639305114746
MLP_4h_h: 0.07053184509277344
Post-MLP residual: 0.0018510818481445312
Attention layer time: 0.22776007652282715
LN1: 0.0007147789001464844
QKV Transform: 0.0516667366027832
Flash: 0.00805354118347168
Attention linproj: 0.01667475700378418
Post-attention Dropout: 0.0018527507781982422
Post-attention residual: 0.0006227493286132812
LN2: 0.0006966590881347656
MLP_h_4h: 0.07078409194946289
MLP_4h_h: 0.0694279670715332
Post-MLP residual: 0.0018572807312011719
Attention layer time: 0.22322940826416016
LN1: 0.0007171630859375
QKV Transform: 0.053285837173461914
Flash: 0.008586406707763672
Attention linproj: 0.01682114601135254
Post-attention Dropout: 0.0018811225891113281
Post-attention residual: 0.000621795654296875
LN2: 0.0006973743438720703
MLP_h_4h: 0.0715017318725586
MLP_4h_h: 0.06893062591552734
Post-MLP residual: 0.0018467903137207031
Attention layer time: 0.22576284408569336
LN1: 0.0007128715515136719
QKV Transform: 0.05210065841674805
Flash: 0.008722066879272461
Attention linproj: 0.01689004898071289
Post-attention Dropout: 0.0018758773803710938
Post-attention residual: 0.0006206035614013672
LN2: 0.0006973743438720703
MLP_h_4h: 0.07120656967163086
MLP_4h_h: 0.06902480125427246
Post-MLP residual: 0.0018506050109863281
Attention layer time: 0.22459626197814941
LN1: 0.0007309913635253906
QKV Transform: 0.05160880088806152
Flash: 0.008159160614013672
Attention linproj: 0.01666569709777832
Post-attention Dropout: 0.0018510818481445312
Post-attention residual: 0.0006241798400878906
LN2: 0.0006971359252929688
MLP_h_4h: 0.0713651180267334
MLP_4h_h: 0.06954216957092285
Post-MLP residual: 0.0018391609191894531
Attention layer time: 0.2239668369293213
LN1: 0.0007154941558837891
QKV Transform: 0.05266618728637695
Flash: 0.008092641830444336
Attention linproj: 0.016843080520629883
Post-attention Dropout: 0.0018575191497802734
Post-attention residual: 0.0006201267242431641
LN2: 0.0006957054138183594
MLP_h_4h: 0.0710606575012207
MLP_4h_h: 0.06902408599853516
Post-MLP residual: 0.001875162124633789
Attention layer time: 0.2243359088897705
LN1: 0.0007176399230957031
QKV Transform: 0.052407264709472656
Flash: 0.008386373519897461
Attention linproj: 0.016895532608032227
Post-attention Dropout: 0.0018608570098876953
Post-attention residual: 0.0006194114685058594
LN2: 0.0006968975067138672
MLP_h_4h: 0.07158231735229492
MLP_4h_h: 0.06890463829040527
Post-MLP residual: 0.0018444061279296875
Attention layer time: 0.22479677200317383
LN1: 0.0007135868072509766
QKV Transform: 0.05250120162963867
Flash: 0.008187055587768555
Attention linproj: 0.01666259765625
Post-attention Dropout: 0.0018494129180908203
Post-attention residual: 0.0006206035614013672
LN2: 0.0006968975067138672
MLP_h_4h: 0.07127642631530762
MLP_4h_h: 0.0696561336517334
Post-MLP residual: 0.0018546581268310547
Attention layer time: 0.22490477561950684
LN1: 0.0007166862487792969
QKV Transform: 0.05232405662536621
Flash: 0.008379220962524414
Attention linproj: 0.016820192337036133
Post-attention Dropout: 0.001886129379272461
Post-attention residual: 0.0006198883056640625
LN2: 0.0006949901580810547
MLP_h_4h: 0.07131743431091309
MLP_4h_h: 0.06932282447814941
Post-MLP residual: 0.0018568038940429688
Attention layer time: 0.22480201721191406
LN1: 0.0007145404815673828
QKV Transform: 0.05256080627441406
Flash: 0.008295536041259766
Attention linproj: 0.016999483108520508
Post-attention Dropout: 0.0018718242645263672
Post-attention residual: 0.0006194114685058594
LN2: 0.0006957054138183594
MLP_h_4h: 0.07182741165161133
MLP_4h_h: 0.06975269317626953
Post-MLP residual: 0.0018565654754638672
Attention layer time: 0.2260751724243164
LN1: 0.0007147789001464844
QKV Transform: 0.051217079162597656
Flash: 0.008296728134155273
Attention linproj: 0.016591787338256836
Post-attention Dropout: 0.0018591880798339844
Post-attention residual: 0.0006229877471923828
LN2: 0.0006992816925048828
MLP_h_4h: 0.07097101211547852
MLP_4h_h: 0.06951069831848145
Post-MLP residual: 0.0018467903137207031
Attention layer time: 0.2232046127319336
LN1: 0.0007135868072509766
QKV Transform: 0.05205059051513672
Flash: 0.007742643356323242
Attention linproj: 0.016558408737182617
Post-attention Dropout: 0.0018646717071533203
Post-attention residual: 0.000621795654296875
LN2: 0.0006971359252929688
MLP_h_4h: 0.07116460800170898
MLP_4h_h: 0.0689702033996582
Post-MLP residual: 0.0018529891967773438
Attention layer time: 0.22308993339538574
LN1: 0.0007152557373046875
QKV Transform: 0.05214238166809082
Flash: 0.008374929428100586
Attention linproj: 0.016921520233154297
Post-attention Dropout: 0.0018656253814697266
Post-attention residual: 0.0006206035614013672
LN2: 0.0006952285766601562
MLP_h_4h: 0.07217144966125488
MLP_4h_h: 0.06879162788391113
Post-MLP residual: 0.001844644546508789
Attention layer time: 0.2250211238861084
LN1: 0.0007109642028808594
QKV Transform: 0.05171966552734375
Flash: 0.008055686950683594
Attention linproj: 0.016879796981811523
Post-attention Dropout: 0.0018551349639892578
Post-attention residual: 0.0006341934204101562
LN2: 0.0006978511810302734
MLP_h_4h: 0.07148027420043945
MLP_4h_h: 0.06908488273620605
Post-MLP residual: 0.0018525123596191406
Attention layer time: 0.2238469123840332
LN1: 0.0007126331329345703
QKV Transform: 0.05193901062011719
Flash: 0.007816553115844727
Attention linproj: 0.016587018966674805
Post-attention Dropout: 0.0018665790557861328
Post-attention residual: 0.0006186962127685547
LN2: 0.0006945133209228516
MLP_h_4h: 0.07051801681518555
MLP_4h_h: 0.06906604766845703
Post-MLP residual: 0.001840829849243164
Attention layer time: 0.2225334644317627
LN1: 0.0007162094116210938
QKV Transform: 0.05303788185119629
Flash: 0.008742094039916992
Attention linproj: 0.016817808151245117
Post-attention Dropout: 0.0018625259399414062
Post-attention residual: 0.0006222724914550781
LN2: 0.0006964206695556641
MLP_h_4h: 0.07146811485290527
MLP_4h_h: 0.06932759284973145
Post-MLP residual: 0.0018610954284667969
Attention layer time: 0.22602391242980957
LN1: 0.0007164478302001953
QKV Transform: 0.05260753631591797
Flash: 0.008259057998657227
Attention linproj: 0.016962528228759766
Post-attention Dropout: 0.0018572807312011719
Post-attention residual: 0.0006196498870849609
LN2: 0.0006964206695556641
MLP_h_4h: 0.07196664810180664
MLP_4h_h: 0.06968951225280762
Post-MLP residual: 0.0018477439880371094
Attention layer time: 0.2261042594909668
LN1: 0.0007238388061523438
QKV Transform: 0.05204129219055176
Flash: 0.00868368148803711
Attention linproj: 0.01657700538635254
Post-attention Dropout: 0.0018630027770996094
Post-attention residual: 0.0006225109100341797
LN2: 0.0006966590881347656
MLP_h_4h: 0.07123446464538574
MLP_4h_h: 0.0686805248260498
Post-MLP residual: 0.0018491744995117188
Attention layer time: 0.22385859489440918
LN1: 0.0007123947143554688
QKV Transform: 0.05176830291748047
Flash: 0.007869243621826172
Attention linproj: 0.016651630401611328
Post-attention Dropout: 0.0018570423126220703
Post-attention residual: 0.0006189346313476562
LN2: 0.0007045269012451172
MLP_h_4h: 0.07131052017211914
MLP_4h_h: 0.06908488273620605
Post-MLP residual: 0.0018775463104248047
Attention layer time: 0.2233281135559082
LN1: 0.0007274150848388672
QKV Transform: 0.05255484580993652
Flash: 0.008142948150634766
Attention linproj: 0.016779661178588867
Post-attention Dropout: 0.0018684864044189453
Post-attention residual: 0.0006222724914550781
LN2: 0.000698089599609375
MLP_h_4h: 0.07060384750366211
MLP_4h_h: 0.06912493705749512
Post-MLP residual: 0.0018525123596191406
Attention layer time: 0.223876953125
LN1: 0.0007131099700927734
QKV Transform: 0.05187034606933594
Flash: 0.007899045944213867
Attention linproj: 0.016844749450683594
Post-attention Dropout: 0.0018627643585205078
Post-attention residual: 0.0006210803985595703
LN2: 0.0006966590881347656
MLP_h_4h: 0.07094025611877441
MLP_4h_h: 0.06951475143432617
Post-MLP residual: 0.0018393993377685547
Attention layer time: 0.2236800193786621
LN1: 0.0007138252258300781
QKV Transform: 0.05175638198852539
Flash: 0.008697271347045898
Attention linproj: 0.016536712646484375
Post-attention Dropout: 0.0018444061279296875
Post-attention residual: 0.0006248950958251953
LN2: 0.0006945133209228516
MLP_h_4h: 0.07081031799316406
MLP_4h_h: 0.0693655014038086
Post-MLP residual: 0.001842498779296875
Attention layer time: 0.22374773025512695
LN1: 0.0007190704345703125
QKV Transform: 0.05200982093811035
Flash: 0.008080720901489258
Attention linproj: 0.01679229736328125
Post-attention Dropout: 0.0018641948699951172
Post-attention residual: 0.0006203651428222656
LN2: 0.0006952285766601562
MLP_h_4h: 0.07155609130859375
MLP_4h_h: 0.07064032554626465
Post-MLP residual: 0.0018641948699951172
Attention layer time: 0.2257072925567627
LN1: 0.0007164478302001953
QKV Transform: 0.051848649978637695
Flash: 0.0078046321868896484
Attention linproj: 0.016698122024536133
Post-attention Dropout: 0.0018537044525146484
Post-attention residual: 0.0006198883056640625
LN2: 0.0006952285766601562
MLP_h_4h: 0.07109642028808594
MLP_4h_h: 0.0697331428527832
Post-MLP residual: 0.0018472671508789062
Attention layer time: 0.22381019592285156
LN1: 0.000713348388671875
QKV Transform: 0.05202817916870117
Flash: 0.008749723434448242
Attention linproj: 0.0165860652923584
Post-attention Dropout: 0.0018680095672607422
Post-attention residual: 0.0006248950958251953
LN2: 0.0006999969482421875
MLP_h_4h: 0.07138395309448242
MLP_4h_h: 0.06921601295471191
Post-MLP residual: 0.0018429756164550781
Attention layer time: 0.2246079444885254
LN1: 0.0007166862487792969
QKV Transform: 0.05247163772583008
Flash: 0.008083581924438477
Attention linproj: 0.016808271408081055
Post-attention Dropout: 0.0018582344055175781
Post-attention residual: 0.0006229877471923828
LN2: 0.0006937980651855469
MLP_h_4h: 0.07175207138061523
MLP_4h_h: 0.06957602500915527
Post-MLP residual: 0.001859903335571289
Attention layer time: 0.22530746459960938
LN1: 0.0007138252258300781
QKV Transform: 0.05193662643432617
Flash: 0.007886648178100586
Attention linproj: 0.016848087310791016
Post-attention Dropout: 0.001861572265625
Post-attention residual: 0.0006186962127685547
LN2: 0.0006933212280273438
MLP_h_4h: 0.0717167854309082
MLP_4h_h: 0.06948351860046387
Post-MLP residual: 0.001844644546508789
Attention layer time: 0.2244706153869629
LN1: 0.0007123947143554688
QKV Transform: 0.05223798751831055
Flash: 0.008598089218139648
Attention linproj: 0.01667618751525879
Post-attention Dropout: 0.0018579959869384766
Post-attention residual: 0.0006206035614013672
LN2: 0.0006961822509765625
MLP_h_4h: 0.07193922996520996
MLP_4h_h: 0.06948113441467285
Post-MLP residual: 0.0018339157104492188
Attention layer time: 0.22552752494812012
LN1: 0.0007162094116210938
QKV Transform: 0.05255842208862305
Flash: 0.008114814758300781
Attention linproj: 0.016791105270385742
Post-attention Dropout: 0.0018608570098876953
Post-attention residual: 0.0006184577941894531
LN2: 0.0006937980651855469
MLP_h_4h: 0.07112812995910645
MLP_4h_h: 0.06933474540710449
Post-MLP residual: 0.001859903335571289
Attention layer time: 0.22454094886779785
LN1: 0.0007164478302001953
QKV Transform: 0.052149295806884766
Flash: 0.008656978607177734
Attention linproj: 0.016707420349121094
Post-attention Dropout: 0.0018715858459472656
Post-attention residual: 0.0006237030029296875
LN2: 0.000698089599609375
MLP_h_4h: 0.07095193862915039
MLP_4h_h: 0.06982231140136719
Post-MLP residual: 0.0018472671508789062
Attention layer time: 0.2249155044555664
LN1: 0.0007128715515136719
QKV Transform: 0.05203866958618164
Flash: 0.007862329483032227
Attention linproj: 0.01668238639831543
Post-attention Dropout: 0.0018627643585205078
Post-attention residual: 0.000621795654296875
LN2: 0.0006964206695556641
MLP_h_4h: 0.07173538208007812
MLP_4h_h: 0.06972408294677734
Post-MLP residual: 0.0018279552459716797
Attention layer time: 0.22464299201965332
LN1: 0.0007147789001464844
QKV Transform: 0.05241751670837402
Flash: 0.008306741714477539
Attention linproj: 0.017061471939086914
Post-attention Dropout: 0.0018610954284667969
Post-attention residual: 0.0006210803985595703
LN2: 0.0006978511810302734
MLP_h_4h: 0.07214045524597168
MLP_4h_h: 0.06991028785705566
Post-MLP residual: 0.0018513202667236328
Attention layer time: 0.22647571563720703
LN1: 0.0007128715515136719
QKV Transform: 0.05213475227355957
Flash: 0.008756637573242188
Attention linproj: 0.01670527458190918
Post-attention Dropout: 0.0018682479858398438
Post-attention residual: 0.0006189346313476562
LN2: 0.0006923675537109375
MLP_h_4h: 0.07115983963012695
MLP_4h_h: 0.06960511207580566
Post-MLP residual: 0.0018515586853027344
Attention layer time: 0.2249743938446045
LN1: 0.0007114410400390625
QKV Transform: 0.052342891693115234
Flash: 0.008377790451049805
Attention linproj: 0.016659259796142578
Post-attention Dropout: 0.0018620491027832031
Post-attention residual: 0.0006194114685058594
LN2: 0.0006973743438720703
MLP_h_4h: 0.07162761688232422
MLP_4h_h: 0.06929206848144531
Post-MLP residual: 0.0018796920776367188
Attention layer time: 0.22493910789489746
LN1: 0.0007154941558837891
QKV Transform: 0.05277705192565918
Flash: 0.00812077522277832
Attention linproj: 0.0170137882232666
Post-attention Dropout: 0.0018813610076904297
Post-attention residual: 0.0006186962127685547
LN2: 0.0006947517395019531
MLP_h_4h: 0.07220625877380371
MLP_4h_h: 0.0697011947631836
Post-MLP residual: 0.0018591880798339844
Attention layer time: 0.22646689414978027
LN1: 0.0007147789001464844
QKV Transform: 0.05136847496032715
Flash: 0.008033990859985352
Attention linproj: 0.016703367233276367
Post-attention Dropout: 0.0018677711486816406
Post-attention residual: 0.0006213188171386719
LN2: 0.0007128715515136719
MLP_h_4h: 0.0713200569152832
MLP_4h_h: 0.06985664367675781
Post-MLP residual: 0.001857757568359375
Attention layer time: 0.22394323348999023
LN1: 0.0007166862487792969
QKV Transform: 0.05276823043823242
Flash: 0.007957696914672852
Attention linproj: 0.016632556915283203
Post-attention Dropout: 0.0018606185913085938
Post-attention residual: 0.0006191730499267578
LN2: 0.0006928443908691406
MLP_h_4h: 0.07144689559936523
MLP_4h_h: 0.07035589218139648
Post-MLP residual: 0.0018661022186279297
Attention layer time: 0.22577643394470215
LN1: 0.0007174015045166016
QKV Transform: 0.05254006385803223
Flash: 0.00821232795715332
Attention linproj: 0.016759157180786133
Post-attention Dropout: 0.0018527507781982422
Post-attention residual: 0.0006206035614013672
LN2: 0.0006983280181884766
MLP_h_4h: 0.07104253768920898
MLP_4h_h: 0.07027745246887207
Post-MLP residual: 0.0018572807312011719
Attention layer time: 0.2254471778869629
LN1: 0.0007154941558837891
QKV Transform: 0.05158877372741699
Flash: 0.008055925369262695
Attention linproj: 0.01660442352294922
Post-attention Dropout: 0.0018684864044189453
Post-attention residual: 0.0006198883056640625
LN2: 0.0006973743438720703
MLP_h_4h: 0.07362747192382812
MLP_4h_h: 0.07011675834655762
Post-MLP residual: 0.0018520355224609375
Attention layer time: 0.2266230583190918
LN1: 0.0007178783416748047
QKV Transform: 0.05282282829284668
Flash: 0.0078067779541015625
Attention linproj: 0.016793251037597656
Post-attention Dropout: 0.0018544197082519531
Post-attention residual: 0.0006237030029296875
LN2: 0.0006952285766601562
MLP_h_4h: 0.07189178466796875
MLP_4h_h: 0.06891345977783203
Post-MLP residual: 0.0018587112426757812
Attention layer time: 0.22484827041625977
LN1: 0.0007116794586181641
QKV Transform: 0.05246782302856445
Flash: 0.008370161056518555
Attention linproj: 0.016857385635375977
Post-attention Dropout: 0.001863241195678711
Post-attention residual: 0.0006194114685058594
LN2: 0.0006954669952392578
MLP_h_4h: 0.07187414169311523
MLP_4h_h: 0.0697782039642334
Post-MLP residual: 0.0018422603607177734
Attention layer time: 0.22599148750305176
LN1: 0.0007143020629882812
QKV Transform: 0.052102088928222656
Flash: 0.008635282516479492
Attention linproj: 0.016545772552490234
Post-attention Dropout: 0.001851797103881836
Post-attention residual: 0.0006203651428222656
LN2: 0.00069427490234375
MLP_h_4h: 0.07137775421142578
MLP_4h_h: 0.06866121292114258
Post-MLP residual: 0.0018529891967773438
Attention layer time: 0.22391891479492188
LN1: 0.0007140636444091797
QKV Transform: 0.05226540565490723
Flash: 0.008463621139526367
Attention linproj: 0.017089128494262695
Post-attention Dropout: 0.0018706321716308594
Post-attention residual: 0.0006196498870849609
LN2: 0.0006952285766601562
MLP_h_4h: 0.07232069969177246
MLP_4h_h: 0.06965017318725586
Post-MLP residual: 0.001833200454711914
Attention layer time: 0.2263932228088379
LN1: 0.0007140636444091797
QKV Transform: 0.05160641670227051
Flash: 0.008112907409667969
Attention linproj: 0.01673722267150879
Post-attention Dropout: 0.0018520355224609375
Post-attention residual: 0.0006215572357177734
LN2: 0.0006966590881347656
MLP_h_4h: 0.0706324577331543
MLP_4h_h: 0.0694584846496582
Post-MLP residual: 0.001855611801147461
Attention layer time: 0.22317266464233398
LN1: 0.0007116794586181641
QKV Transform: 0.05233025550842285
Flash: 0.008571863174438477
Attention linproj: 0.016733169555664062
Post-attention Dropout: 0.0018584728240966797
Post-attention residual: 0.0006208419799804688
LN2: 0.0006985664367675781
MLP_h_4h: 0.07172560691833496
MLP_4h_h: 0.0697946548461914
Post-MLP residual: 0.0018436908721923828
Attention layer time: 0.2257704734802246
LN1: 0.0007157325744628906
QKV Transform: 0.052785634994506836
Flash: 0.008143424987792969
Attention linproj: 0.017064571380615234
Post-attention Dropout: 0.00186920166015625
Post-attention residual: 0.0006201267242431641
LN2: 0.0006990432739257812
MLP_h_4h: 0.07231903076171875
MLP_4h_h: 0.0697946548461914
Post-MLP residual: 0.0018625259399414062
Attention layer time: 0.226759672164917
LN1: 0.0007126331329345703
QKV Transform: 0.05153059959411621
Flash: 0.008091211318969727
Attention linproj: 0.016730785369873047
Post-attention Dropout: 0.0018563270568847656
Post-attention residual: 0.000621795654296875
LN2: 0.000698089599609375
MLP_h_4h: 0.07096338272094727
MLP_4h_h: 0.06949996948242188
Post-MLP residual: 0.0018434524536132812
Attention layer time: 0.22341251373291016
LN1: 0.0007116794586181641
QKV Transform: 0.05195760726928711
Flash: 0.007789134979248047
Attention linproj: 0.01657581329345703
Post-attention Dropout: 0.0018506050109863281
Post-attention residual: 0.0006206035614013672
LN2: 0.0006940364837646484
MLP_h_4h: 0.07108664512634277
MLP_4h_h: 0.06944775581359863
Post-MLP residual: 0.0018508434295654297
Attention layer time: 0.22344303131103516
LN1: 0.0007183551788330078
QKV Transform: 0.05325889587402344
Flash: 0.00790858268737793
Attention linproj: 0.016800403594970703
Post-attention Dropout: 0.001859903335571289
Post-attention residual: 0.0006208419799804688
LN2: 0.0006973743438720703
MLP_h_4h: 0.07118535041809082
MLP_4h_h: 0.06945228576660156
Post-MLP residual: 0.0018668174743652344
Attention layer time: 0.22524213790893555
LN1: 0.000732421875
QKV Transform: 0.0523526668548584
Flash: 0.008173942565917969
Attention linproj: 0.016964435577392578
Post-attention Dropout: 0.0018584728240966797
Post-attention residual: 0.0006182193756103516
LN2: 0.0006966590881347656
MLP_h_4h: 0.07213759422302246
MLP_4h_h: 0.06973099708557129
Post-MLP residual: 0.0018534660339355469
Attention layer time: 0.22599005699157715
LN1: 0.0007109642028808594
QKV Transform: 0.05211997032165527
Flash: 0.00868368148803711
Attention linproj: 0.016565799713134766
Post-attention Dropout: 0.0018727779388427734
Post-attention residual: 0.0006227493286132812
LN2: 0.0006966590881347656
MLP_h_4h: 0.07095742225646973
MLP_4h_h: 0.06905889511108398
Post-MLP residual: 0.0018525123596191406
Attention layer time: 0.22400951385498047
LN1: 0.0007176399230957031
QKV Transform: 0.05280470848083496
Flash: 0.008005857467651367
Attention linproj: 0.016802549362182617
Post-attention Dropout: 0.0018568038940429688
Post-attention residual: 0.0006182193756103516
LN2: 0.0006976127624511719
MLP_h_4h: 0.07171988487243652
MLP_4h_h: 0.06882095336914062
Post-MLP residual: 0.0018520355224609375
Attention layer time: 0.22475576400756836
LN1: 0.0007114410400390625
QKV Transform: 0.05212140083312988
Flash: 0.00877070426940918
Attention linproj: 0.016869544982910156
Post-attention Dropout: 0.0018620491027832031
Post-attention residual: 0.0006196498870849609
LN2: 0.0006966590881347656
MLP_h_4h: 0.07140469551086426
MLP_4h_h: 0.0693352222442627
Post-MLP residual: 0.001855611801147461
Attention layer time: 0.22513699531555176
LN1: 0.0007162094116210938
QKV Transform: 0.0521693229675293
Flash: 0.008517265319824219
Attention linproj: 0.01657867431640625
Post-attention Dropout: 0.001851797103881836
Post-attention residual: 0.0006215572357177734
LN2: 0.0006990432739257812
MLP_h_4h: 0.07146644592285156
MLP_4h_h: 0.06959867477416992
Post-MLP residual: 0.0018489360809326172
Attention layer time: 0.22493338584899902
LN1: 0.0007157325744628906
QKV Transform: 0.05203104019165039
Flash: 0.00809168815612793
Attention linproj: 0.016797780990600586
Post-attention Dropout: 0.0018587112426757812
Post-attention residual: 0.0006194114685058594
LN2: 0.0006949901580810547
MLP_h_4h: 0.07151579856872559
MLP_4h_h: 0.06883502006530762
Post-MLP residual: 0.0018434524536132812
Attention layer time: 0.2238914966583252
LN1: 0.0007107257843017578
QKV Transform: 0.05152606964111328
Flash: 0.008147478103637695
Attention linproj: 0.016726970672607422
Post-attention Dropout: 0.001851797103881836
Post-attention residual: 0.0006177425384521484
LN2: 0.0006937980651855469
MLP_h_4h: 0.0712578296661377
MLP_4h_h: 0.06975841522216797
Post-MLP residual: 0.0020241737365722656
Attention layer time: 0.22428584098815918
LN1: 0.000766754150390625
QKV Transform: 0.05184197425842285
Flash: 0.008066415786743164
Attention linproj: 0.0166170597076416
Post-attention Dropout: 0.0018680095672607422
Post-attention residual: 0.0006232261657714844
LN2: 0.0006966590881347656
MLP_h_4h: 0.07143592834472656
MLP_4h_h: 0.06966233253479004
Post-MLP residual: 0.0018463134765625
Attention layer time: 0.2243802547454834
LN1: 0.0007164478302001953
QKV Transform: 0.05255436897277832
Flash: 0.008258581161499023
Attention linproj: 0.01693415641784668
Post-attention Dropout: 0.0018672943115234375
Post-attention residual: 0.0006186962127685547
LN2: 0.0006952285766601562
MLP_h_4h: 0.07245802879333496
MLP_4h_h: 0.06883835792541504
Post-MLP residual: 0.0018508434295654297
Attention layer time: 0.22566843032836914
LN1: 0.00072479248046875
QKV Transform: 0.05159807205200195
Flash: 0.008139371871948242
Attention linproj: 0.016749143600463867
Post-attention Dropout: 0.001855611801147461
Post-attention residual: 0.0006220340728759766
LN2: 0.0006930828094482422
MLP_h_4h: 0.07098913192749023
MLP_4h_h: 0.06998205184936523
Post-MLP residual: 0.0018496513366699219
Attention layer time: 0.22406959533691406
LN1: 0.0007121562957763672
QKV Transform: 0.05206012725830078
Flash: 0.0087738037109375
Attention linproj: 0.01662421226501465
Post-attention Dropout: 0.001856088638305664
Post-attention residual: 0.0006196498870849609
LN2: 0.0006959438323974609
MLP_h_4h: 0.07071781158447266
MLP_4h_h: 0.06940221786499023
Post-MLP residual: 0.0018558502197265625
Attention layer time: 0.22420787811279297
LN1: 0.0007197856903076172
QKV Transform: 0.0529172420501709
Flash: 0.008619546890258789
Attention linproj: 0.016809701919555664
Post-attention Dropout: 0.0018625259399414062
Post-attention residual: 0.0006206035614013672
LN2: 0.0006940364837646484
MLP_h_4h: 0.07211184501647949
MLP_4h_h: 0.06929183006286621
Post-MLP residual: 0.0018544197082519531
Attention layer time: 0.2263658046722412
LN1: 0.0007197856903076172
QKV Transform: 0.05249428749084473
Flash: 0.008311033248901367
Attention linproj: 0.016857624053955078
Post-attention Dropout: 0.0018584728240966797
Post-attention residual: 0.0006234645843505859
LN2: 0.0006966590881347656
MLP_h_4h: 0.07065677642822266
MLP_4h_h: 0.06965994834899902
Post-MLP residual: 0.0018568038940429688
Attention layer time: 0.22464418411254883
LN1: 0.0007159709930419922
QKV Transform: 0.05215954780578613
Flash: 0.008736848831176758
Attention linproj: 0.016608238220214844
Post-attention Dropout: 0.0018537044525146484
Post-attention residual: 0.0006203651428222656
LN2: 0.0006937980651855469
MLP_h_4h: 0.07092118263244629
MLP_4h_h: 0.0691072940826416
Post-MLP residual: 0.0018477439880371094
Attention layer time: 0.22416067123413086
LN1: 0.0007176399230957031
QKV Transform: 0.05257272720336914
Flash: 0.008147478103637695
Attention linproj: 0.01680302619934082
Post-attention Dropout: 0.0018780231475830078
Post-attention residual: 0.0006206035614013672
LN2: 0.0006959438323974609
MLP_h_4h: 0.07154369354248047
MLP_4h_h: 0.06905889511108398
Post-MLP residual: 0.0018558502197265625
Attention layer time: 0.2247772216796875
LN1: 0.0007126331329345703
QKV Transform: 0.052257537841796875
Flash: 0.00864100456237793
Attention linproj: 0.01691913604736328
Post-attention Dropout: 0.0018622875213623047
Post-attention residual: 0.0006225109100341797
LN2: 0.0006966590881347656
MLP_h_4h: 0.0713801383972168
MLP_4h_h: 0.06935667991638184
Post-MLP residual: 0.0018463134765625
Attention layer time: 0.225175142288208
Transformer duration (in seconds): 0.2294
Transformer throughput (in TFLOP/s): 234.866
========================================================================================================================

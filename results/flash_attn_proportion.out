num_attention_heads: 20, hidden_size: 2560, train_micro_batch_size_per_gpu: 4, tensor_mp_size: 1, pipeline_mp_size: 1, dp_size: 1

MLP duration (in seconds): 0.0040
MLP throughput (in TFLOP/s): 212.697
LN1: 0.004076957702636719
QKV Transform: 0.0016138553619384766
Flash: 0.0022056102752685547
Attention linproj: 0.000537872314453125
Post-attention Dropout: 0.06640791893005371
Post-attention residual: 0.004055500030517578
LN2: 0.00018358230590820312
MLP_h_4h: 0.002364635467529297
MLP_4h_h: 0.0016968250274658203
Post-MLP residual: 0.0020263195037841797
Attention layer time: 0.08559989929199219
LN1: 0.00013256072998046875
QKV Transform: 0.0027561187744140625
Flash: 0.006319761276245117
Attention linproj: 0.0005259513854980469
Post-attention Dropout: 0.0003478527069091797
Post-attention residual: 0.00011515617370605469
LN2: 0.00011682510375976562
MLP_h_4h: 0.0029191970825195312
MLP_4h_h: 0.0017063617706298828
Post-MLP residual: 0.00033164024353027344
Attention layer time: 0.015591144561767578
LN1: 0.0001354217529296875
QKV Transform: 0.002033233642578125
Flash: 0.007412910461425781
Attention linproj: 0.0005230903625488281
Post-attention Dropout: 0.0003440380096435547
Post-attention residual: 0.00011444091796875
LN2: 0.00011754035949707031
MLP_h_4h: 0.003586292266845703
MLP_4h_h: 0.0017185211181640625
Post-MLP residual: 0.00033664703369140625
Attention layer time: 0.01663661003112793
LN1: 0.00013375282287597656
QKV Transform: 0.0026051998138427734
Flash: 0.00742650032043457
Attention linproj: 0.0005223751068115234
Post-attention Dropout: 0.000335693359375
Post-attention residual: 0.00011324882507324219
LN2: 0.00011539459228515625
MLP_h_4h: 0.0036079883575439453
MLP_4h_h: 0.0017113685607910156
Post-MLP residual: 0.0003407001495361328
Attention layer time: 0.01720142364501953
LN1: 0.00013184547424316406
QKV Transform: 0.002663135528564453
Flash: 0.008554220199584961
Attention linproj: 0.0005135536193847656
Post-attention Dropout: 0.0003383159637451172
Post-attention residual: 0.00011324882507324219
LN2: 0.00011587142944335938
MLP_h_4h: 0.0034999847412109375
MLP_4h_h: 0.0017132759094238281
Post-MLP residual: 0.00033974647521972656
Attention layer time: 0.0182955265045166
LN1: 0.00013136863708496094
QKV Transform: 0.0025413036346435547
Flash: 0.007406949996948242
Attention linproj: 0.0005199909210205078
Post-attention Dropout: 0.0003352165222167969
Post-attention residual: 0.00011277198791503906
LN2: 0.00011539459228515625
MLP_h_4h: 0.003621339797973633
MLP_4h_h: 0.0017216205596923828
Post-MLP residual: 0.0003387928009033203
Attention layer time: 0.017144441604614258
LN1: 0.0001323223114013672
QKV Transform: 0.0025320053100585938
Flash: 0.007413625717163086
Attention linproj: 0.0005252361297607422
Post-attention Dropout: 0.00034737586975097656
Post-attention residual: 0.00011396408081054688
LN2: 0.0001163482666015625
MLP_h_4h: 0.003582000732421875
MLP_4h_h: 0.0017137527465820312
Post-MLP residual: 0.0003342628479003906
Attention layer time: 0.01711583137512207
LN1: 0.00014257431030273438
QKV Transform: 0.002551555633544922
Flash: 0.007411003112792969
Attention linproj: 0.0005211830139160156
Post-attention Dropout: 0.0003445148468017578
Post-attention residual: 0.00011277198791503906
LN2: 0.00011706352233886719
MLP_h_4h: 0.003596067428588867
MLP_4h_h: 0.0017139911651611328
Post-MLP residual: 0.0003368854522705078
Attention layer time: 0.0171663761138916
LN1: 0.00013303756713867188
QKV Transform: 0.0026030540466308594
Flash: 0.007436037063598633
Attention linproj: 0.00051116943359375
Post-attention Dropout: 0.0003349781036376953
Post-attention residual: 0.00011205673217773438
LN2: 0.00011396408081054688
MLP_h_4h: 0.010118722915649414
MLP_4h_h: 0.0016980171203613281
Post-MLP residual: 0.0003376007080078125
Attention layer time: 0.023689746856689453
LN1: 0.0001323223114013672
QKV Transform: 0.0022585391998291016
Flash: 0.007416248321533203
Attention linproj: 0.0005235671997070312
Post-attention Dropout: 0.00034427642822265625
Post-attention residual: 0.00011301040649414062
LN2: 0.000133514404296875
MLP_h_4h: 0.003567934036254883
MLP_4h_h: 0.001712799072265625
Post-MLP residual: 0.00033593177795410156
Attention layer time: 0.016841888427734375
LN1: 0.000133514404296875
QKV Transform: 0.0025751590728759766
Flash: 0.007425785064697266
Attention linproj: 0.0005195140838623047
Post-attention Dropout: 0.0003342628479003906
Post-attention residual: 0.00011348724365234375
LN2: 0.00011515617370605469
MLP_h_4h: 0.0035932064056396484
MLP_4h_h: 0.0017082691192626953
Post-MLP residual: 0.000339508056640625
Attention layer time: 0.017147302627563477
LN1: 0.0001304149627685547
QKV Transform: 0.0025348663330078125
Flash: 0.0074329376220703125
Attention linproj: 0.0005214214324951172
Post-attention Dropout: 0.00033664703369140625
Post-attention residual: 0.00011277198791503906
LN2: 0.00011491775512695312
MLP_h_4h: 0.003604412078857422
MLP_4h_h: 0.0017104148864746094
Post-MLP residual: 0.0003368854522705078
Attention layer time: 0.017127275466918945
LN1: 0.00013065338134765625
QKV Transform: 0.002564668655395508
Flash: 0.007422447204589844
Attention linproj: 0.0005414485931396484
Post-attention Dropout: 0.00033855438232421875
Post-attention residual: 0.00011301040649414062
LN2: 0.0001163482666015625
MLP_h_4h: 0.003571033477783203
MLP_4h_h: 0.0017123222351074219
Post-MLP residual: 0.00033545494079589844
Attention layer time: 0.017145872116088867
LN1: 0.00013113021850585938
QKV Transform: 0.0025322437286376953
Flash: 0.0074269771575927734
Attention linproj: 0.0005211830139160156
Post-attention Dropout: 0.000347137451171875
Post-attention residual: 0.00011444091796875
LN2: 0.0001163482666015625
MLP_h_4h: 0.0035791397094726562
MLP_4h_h: 0.0017130374908447266
Post-MLP residual: 0.0003380775451660156
Attention layer time: 0.017121553421020508
LN1: 0.000133514404296875
QKV Transform: 0.002515077590942383
Flash: 0.00743412971496582
Attention linproj: 0.0005199909210205078
Post-attention Dropout: 0.00033283233642578125
Post-attention residual: 0.00011277198791503906
LN2: 0.00011515617370605469
MLP_h_4h: 0.003607511520385742
MLP_4h_h: 0.0017099380493164062
Post-MLP residual: 0.00033783912658691406
Attention layer time: 0.017107725143432617
LN1: 0.00013303756713867188
QKV Transform: 0.002299070358276367
Flash: 0.0074291229248046875
Attention linproj: 0.0005204677581787109
Post-attention Dropout: 0.00033593177795410156
Post-attention residual: 0.00011444091796875
LN2: 0.00011587142944335938
MLP_h_4h: 0.0035991668701171875
MLP_4h_h: 0.0017108917236328125
Post-MLP residual: 0.0003383159637451172
Attention layer time: 0.016889572143554688
LN1: 0.00013065338134765625
QKV Transform: 0.0026144981384277344
Flash: 0.007416486740112305
Attention linproj: 0.0005242824554443359
Post-attention Dropout: 0.0003383159637451172
Post-attention residual: 0.00011157989501953125
LN2: 0.00011515617370605469
MLP_h_4h: 0.003602266311645508
MLP_4h_h: 0.0017092227935791016
Post-MLP residual: 0.00033783912658691406
Attention layer time: 0.01719498634338379
LN1: 0.00013136863708496094
QKV Transform: 0.002560138702392578
Flash: 0.007429838180541992
Attention linproj: 0.0005230903625488281
Post-attention Dropout: 0.0003447532653808594
Post-attention residual: 0.00011491775512695312
LN2: 0.00011706352233886719
MLP_h_4h: 0.0035789012908935547
MLP_4h_h: 0.0017137527465820312
Post-MLP residual: 0.0003361701965332031
Attention layer time: 0.017151594161987305
LN1: 0.0001323223114013672
QKV Transform: 0.0025587081909179688
Flash: 0.007426023483276367
Attention linproj: 0.0005209445953369141
Post-attention Dropout: 0.0003345012664794922
Post-attention residual: 0.00011301040649414062
LN2: 0.00011444091796875
MLP_h_4h: 0.0036139488220214844
MLP_4h_h: 0.001708984375
Post-MLP residual: 0.0003497600555419922
Attention layer time: 0.017160654067993164
LN1: 0.0001308917999267578
QKV Transform: 0.0025517940521240234
Flash: 0.00743412971496582
Attention linproj: 0.0005202293395996094
Post-attention Dropout: 0.0003349781036376953
Post-attention residual: 0.00011277198791503906
LN2: 0.00011396408081054688
MLP_h_4h: 0.003612518310546875
MLP_4h_h: 0.0017087459564208984
Post-MLP residual: 0.0003371238708496094
Attention layer time: 0.01714801788330078
LN1: 0.00013256072998046875
QKV Transform: 0.002493143081665039
Flash: 0.007415294647216797
Attention linproj: 0.0005145072937011719
Post-attention Dropout: 0.00033736228942871094
Post-attention residual: 0.00011324882507324219
LN2: 0.00011610984802246094
MLP_h_4h: 0.003598451614379883
MLP_4h_h: 0.0017120838165283203
Post-MLP residual: 0.0003352165222167969
Attention layer time: 0.017078638076782227
LN1: 0.00013113021850585938
QKV Transform: 0.002537250518798828
Flash: 0.007415771484375
Attention linproj: 0.0005204677581787109
Post-attention Dropout: 0.0003457069396972656
Post-attention residual: 0.00011396408081054688
LN2: 0.00011682510375976562
MLP_h_4h: 0.003574371337890625
MLP_4h_h: 0.0017139911651611328
Post-MLP residual: 0.0003380775451660156
Attention layer time: 0.017122745513916016
LN1: 0.0001323223114013672
QKV Transform: 0.0025305747985839844
Flash: 0.007435798645019531
Attention linproj: 0.0005190372467041016
Post-attention Dropout: 0.0003349781036376953
Post-attention residual: 0.00011301040649414062
LN2: 0.00011515617370605469
MLP_h_4h: 0.0036077499389648438
MLP_4h_h: 0.001708984375
Post-MLP residual: 0.000339508056640625
Attention layer time: 0.01712942123413086
LN1: 0.00013065338134765625
QKV Transform: 0.002566814422607422
Flash: 0.007443904876708984
Attention linproj: 0.0005192756652832031
Post-attention Dropout: 0.00033783912658691406
Post-attention residual: 0.00011301040649414062
LN2: 0.00011444091796875
MLP_h_4h: 0.003590106964111328
MLP_4h_h: 0.0017094612121582031
Post-MLP residual: 0.000339508056640625
Attention layer time: 0.017155885696411133
LN1: 0.00013065338134765625
QKV Transform: 0.0025234222412109375
Flash: 0.00742030143737793
Attention linproj: 0.0005304813385009766
Post-attention Dropout: 0.0003483295440673828
Post-attention residual: 0.00011301040649414062
LN2: 0.00011491775512695312
MLP_h_4h: 0.0035772323608398438
MLP_4h_h: 0.0017120838165283203
Post-MLP residual: 0.0003361701965332031
Attention layer time: 0.01710367202758789
LN1: 0.00013256072998046875
QKV Transform: 0.0025496482849121094
Flash: 0.007450580596923828
Attention linproj: 0.0005209445953369141
Post-attention Dropout: 0.0003447532653808594
Post-attention residual: 0.00011539459228515625
LN2: 0.0001163482666015625
MLP_h_4h: 0.0035660266876220703
MLP_4h_h: 0.0017116069793701172
Post-MLP residual: 0.0003390312194824219
Attention layer time: 0.017145872116088867
LN1: 0.000133514404296875
QKV Transform: 0.002612590789794922
Flash: 0.0074121952056884766
Attention linproj: 0.0005216598510742188
Post-attention Dropout: 0.0003376007080078125
Post-attention residual: 0.00011444091796875
LN2: 0.00011610984802246094
MLP_h_4h: 0.0036017894744873047
MLP_4h_h: 0.0017139911651611328
Post-MLP residual: 0.0003387928009033203
Attention layer time: 0.017197370529174805
LN1: 0.00013303756713867188
QKV Transform: 0.0024156570434570312
Flash: 0.007414817810058594
Attention linproj: 0.0005233287811279297
Post-attention Dropout: 0.00033664703369140625
Post-attention residual: 0.00011444091796875
LN2: 0.00011587142944335938
MLP_h_4h: 0.003592252731323242
MLP_4h_h: 0.0017125606536865234
Post-MLP residual: 0.0003407001495361328
Attention layer time: 0.017014265060424805
LN1: 0.00014901161193847656
QKV Transform: 0.002351999282836914
Flash: 0.007428169250488281
Attention linproj: 0.0005247592926025391
Post-attention Dropout: 0.0003533363342285156
Post-attention residual: 0.00011277198791503906
LN2: 0.00011801719665527344
MLP_h_4h: 0.0035715103149414062
MLP_4h_h: 0.0017120838165283203
Post-MLP residual: 0.00033593177795410156
Attention layer time: 0.016963720321655273
LN1: 0.0001327991485595703
QKV Transform: 0.0025272369384765625
Flash: 0.0073931217193603516
Attention linproj: 0.0005242824554443359
Post-attention Dropout: 0.0003459453582763672
Post-attention residual: 0.00011372566223144531
LN2: 0.00011658668518066406
MLP_h_4h: 0.004661083221435547
MLP_4h_h: 0.0017118453979492188
Post-MLP residual: 0.00033354759216308594
Attention layer time: 0.018161773681640625
LN1: 0.00013327598571777344
QKV Transform: 0.0024378299713134766
Flash: 0.007428884506225586
Attention linproj: 0.0005214214324951172
Post-attention Dropout: 0.00034332275390625
Post-attention residual: 0.00011301040649414062
LN2: 0.0001163482666015625
MLP_h_4h: 0.0035741329193115234
MLP_4h_h: 0.0017070770263671875
Post-MLP residual: 0.0003361701965332031
Attention layer time: 0.01701807975769043
LN1: 0.00013303756713867188
QKV Transform: 0.0026488304138183594
Flash: 0.007433652877807617
Attention linproj: 0.0005178451538085938
Post-attention Dropout: 0.00033354759216308594
Post-attention residual: 0.00011348724365234375
LN2: 0.00011420249938964844
MLP_h_4h: 0.0035958290100097656
MLP_4h_h: 0.0017101764678955078
Post-MLP residual: 0.0003399848937988281
Attention layer time: 0.01723003387451172
LN1: 0.0001316070556640625
QKV Transform: 0.002328634262084961
Flash: 0.007437944412231445
Attention linproj: 0.0005216598510742188
Post-attention Dropout: 0.0003349781036376953
Post-attention residual: 0.0001125335693359375
LN2: 0.00011563301086425781
MLP_h_4h: 0.0035915374755859375
MLP_4h_h: 0.0017104148864746094
Post-MLP residual: 0.00033855438232421875
Attention layer time: 0.016913890838623047
LN1: 0.00013184547424316406
QKV Transform: 0.002529621124267578
Flash: 0.007422447204589844
Attention linproj: 0.0005238056182861328
Post-attention Dropout: 0.0003521442413330078
Post-attention residual: 0.00011396408081054688
LN2: 0.00011610984802246094
MLP_h_4h: 0.0035622119903564453
MLP_4h_h: 0.0017125606536865234
Post-MLP residual: 0.0003352165222167969
Attention layer time: 0.017111539840698242
LN1: 0.00013256072998046875
QKV Transform: 0.0025053024291992188
Flash: 0.007401704788208008
Attention linproj: 0.0005214214324951172
Post-attention Dropout: 0.00034356117248535156
Post-attention residual: 0.00011324882507324219
LN2: 0.00011610984802246094
MLP_h_4h: 0.0036025047302246094
MLP_4h_h: 0.0017130374908447266
Post-MLP residual: 0.00033593177795410156
Attention layer time: 0.017084360122680664
LN1: 0.00013303756713867188
QKV Transform: 0.0024983882904052734
Flash: 0.007425069808959961
Attention linproj: 0.0005202293395996094
Post-attention Dropout: 0.000335693359375
Post-attention residual: 0.00011277198791503906
LN2: 0.00011444091796875
MLP_h_4h: 0.003601551055908203
MLP_4h_h: 0.0017120838165283203
Post-MLP residual: 0.00033974647521972656
Attention layer time: 0.017081737518310547
LN1: 0.00012993812561035156
QKV Transform: 0.0026116371154785156
Flash: 0.008490800857543945
Attention linproj: 0.0005195140838623047
Post-attention Dropout: 0.0003345012664794922
Post-attention residual: 0.0001125335693359375
LN2: 0.00011467933654785156
MLP_h_4h: 0.003587007522583008
MLP_4h_h: 0.0017094612121582031
Post-MLP residual: 0.00033855438232421875
Attention layer time: 0.018245458602905273
LN1: 0.00012969970703125
QKV Transform: 0.002517223358154297
Flash: 0.007425069808959961
Attention linproj: 0.0005228519439697266
Post-attention Dropout: 0.0003337860107421875
Post-attention residual: 0.00011229515075683594
LN2: 0.00011467933654785156
MLP_h_4h: 0.00360870361328125
MLP_4h_h: 0.0017092227935791016
Post-MLP residual: 0.0003390312194824219
Attention layer time: 0.017102479934692383
LN1: 0.00013017654418945312
QKV Transform: 0.002523183822631836
Flash: 0.007421016693115234
Attention linproj: 0.0005242824554443359
Post-attention Dropout: 0.0003521442413330078
Post-attention residual: 0.00011348724365234375
LN2: 0.00011706352233886719
MLP_h_4h: 0.003541231155395508
MLP_4h_h: 0.0017125606536865234
Post-MLP residual: 0.00033473968505859375
Attention layer time: 0.017101764678955078
LN1: 0.0001327991485595703
QKV Transform: 0.0025475025177001953
Flash: 0.008473873138427734
Attention linproj: 0.0006172657012939453
Post-attention Dropout: 0.00036787986755371094
Post-attention residual: 0.00011515617370605469
LN2: 0.00015282630920410156
MLP_h_4h: 0.003381967544555664
MLP_4h_h: 0.0017132759094238281
Post-MLP residual: 0.0003407001495361328
Attention layer time: 0.018192768096923828
LN1: 0.0001327991485595703
QKV Transform: 0.0024132728576660156
Flash: 0.007372379302978516
Attention linproj: 0.0005209445953369141
Post-attention Dropout: 0.0003426074981689453
Post-attention residual: 0.00011301040649414062
LN2: 0.00011682510375976562
MLP_h_4h: 0.003596782684326172
MLP_4h_h: 0.0017125606536865234
Post-MLP residual: 0.00033664703369140625
Attention layer time: 0.017011404037475586
LN1: 0.00013327598571777344
QKV Transform: 0.0025513172149658203
Flash: 0.007429599761962891
Attention linproj: 0.0005209445953369141
Post-attention Dropout: 0.00033402442932128906
Post-attention residual: 0.0001125335693359375
LN2: 0.00011420249938964844
MLP_h_4h: 0.003597259521484375
MLP_4h_h: 0.0017116069793701172
Post-MLP residual: 0.00033974647521972656
Attention layer time: 0.017134666442871094
LN1: 0.0001308917999267578
QKV Transform: 0.0026717185974121094
Flash: 0.0074405670166015625
Attention linproj: 0.0005240440368652344
Post-attention Dropout: 0.000335693359375
Post-attention residual: 0.0001125335693359375
LN2: 0.00011539459228515625
MLP_h_4h: 0.003594636917114258
MLP_4h_h: 0.001711130142211914
Post-MLP residual: 0.00033974647521972656
Attention layer time: 0.017268896102905273
LN1: 0.0001308917999267578
QKV Transform: 0.0025413036346435547
Flash: 0.007411479949951172
Attention linproj: 0.0005254745483398438
Post-attention Dropout: 0.0003619194030761719
Post-attention residual: 0.00011324882507324219
LN2: 0.00011539459228515625
MLP_h_4h: 0.0035715103149414062
MLP_4h_h: 0.0017123222351074219
Post-MLP residual: 0.0003368854522705078
Attention layer time: 0.017121076583862305
LN1: 0.0001327991485595703
QKV Transform: 0.0024607181549072266
Flash: 0.00740361213684082
Attention linproj: 0.0005218982696533203
Post-attention Dropout: 0.00034308433532714844
Post-attention residual: 0.00011277198791503906
LN2: 0.00011706352233886719
MLP_h_4h: 0.0035932064056396484
MLP_4h_h: 0.0017139911651611328
Post-MLP residual: 0.0003361701965332031
Attention layer time: 0.01703667640686035
LN1: 0.00013303756713867188
QKV Transform: 0.00250244140625
Flash: 0.0074138641357421875
Attention linproj: 0.0005204677581787109
Post-attention Dropout: 0.0003364086151123047
Post-attention residual: 0.0001125335693359375
LN2: 0.00011515617370605469
MLP_h_4h: 0.0036067962646484375
MLP_4h_h: 0.0017101764678955078
Post-MLP residual: 0.000339508056640625
Attention layer time: 0.01708531379699707
LN1: 0.0001308917999267578
QKV Transform: 0.0026361942291259766
Flash: 0.007425069808959961
Attention linproj: 0.0005230903625488281
Post-attention Dropout: 0.0003349781036376953
Post-attention residual: 0.00011229515075683594
LN2: 0.00011610984802246094
MLP_h_4h: 0.003595113754272461
MLP_4h_h: 0.0017092227935791016
Post-MLP residual: 0.0003387928009033203
Attention layer time: 0.017218351364135742
LN1: 0.0001304149627685547
QKV Transform: 0.0026061534881591797
Flash: 0.007420539855957031
Attention linproj: 0.0005245208740234375
Post-attention Dropout: 0.0003561973571777344
Post-attention residual: 0.00011301040649414062
LN2: 0.00011539459228515625
MLP_h_4h: 0.003568887710571289
MLP_4h_h: 0.0017120838165283203
Post-MLP residual: 0.0003333091735839844
Attention layer time: 0.017182350158691406
LN1: 0.0001327991485595703
QKV Transform: 0.0024824142456054688
Flash: 0.007414102554321289
Attention linproj: 0.0005218982696533203
Post-attention Dropout: 0.0003457069396972656
Post-attention residual: 0.00011324882507324219
LN2: 0.00011658668518066406
MLP_h_4h: 0.003583669662475586
MLP_4h_h: 0.0017132759094238281
Post-MLP residual: 0.0003364086151123047
Attention layer time: 0.01707291603088379
LN1: 0.00013256072998046875
QKV Transform: 0.002582550048828125
Flash: 0.007448434829711914
Attention linproj: 0.0005192756652832031
Post-attention Dropout: 0.00033593177795410156
Post-attention residual: 0.00011301040649414062
LN2: 0.00011420249938964844
MLP_h_4h: 0.0035886764526367188
MLP_4h_h: 0.0017092227935791016
Post-MLP residual: 0.0003399848937988281
Attention layer time: 0.017172574996948242
LN1: 0.0001304149627685547
QKV Transform: 0.002652883529663086
Flash: 0.007408857345581055
Attention linproj: 0.0005235671997070312
Post-attention Dropout: 0.0003349781036376953
Post-attention residual: 0.00011205673217773438
LN2: 0.00011420249938964844
MLP_h_4h: 0.0036077499389648438
MLP_4h_h: 0.0017192363739013672
Post-MLP residual: 0.00033664703369140625
Attention layer time: 0.01723504066467285
LN1: 0.00013136863708496094
QKV Transform: 0.0025293827056884766
Flash: 0.007416963577270508
Attention linproj: 0.0005249977111816406
Post-attention Dropout: 0.00034356117248535156
Post-attention residual: 0.00011301040649414062
LN2: 0.00011610984802246094
MLP_h_4h: 0.003587484359741211
MLP_4h_h: 0.0017232894897460938
Post-MLP residual: 0.00033664703369140625
Attention layer time: 0.01712512969970703
LN1: 0.00013256072998046875
QKV Transform: 0.0023992061614990234
Flash: 0.007418632507324219
Attention linproj: 0.0005218982696533203
Post-attention Dropout: 0.00034356117248535156
Post-attention residual: 0.00011324882507324219
LN2: 0.00011563301086425781
MLP_h_4h: 0.003588438034057617
MLP_4h_h: 0.001714944839477539
Post-MLP residual: 0.0003466606140136719
Attention layer time: 0.017000913619995117
LN1: 0.0001323223114013672
QKV Transform: 0.00249481201171875
Flash: 0.007444620132446289
Attention linproj: 0.0005207061767578125
Post-attention Dropout: 0.00033402442932128906
Post-attention residual: 0.0001125335693359375
LN2: 0.00011467933654785156
MLP_h_4h: 0.0035927295684814453
MLP_4h_h: 0.0017104148864746094
Post-MLP residual: 0.00033855438232421875
Attention layer time: 0.017081022262573242
LN1: 0.00013136863708496094
QKV Transform: 0.0023360252380371094
Flash: 0.007427215576171875
Attention linproj: 0.0005235671997070312
Post-attention Dropout: 0.0003349781036376953
Post-attention residual: 0.00011324882507324219
LN2: 0.0001163482666015625
MLP_h_4h: 0.003578662872314453
MLP_4h_h: 0.001711130142211914
Post-MLP residual: 0.0003533363342285156
Attention layer time: 0.016922712326049805
LN1: 0.00013136863708496094
QKV Transform: 0.0026030540466308594
Flash: 0.00742793083190918
Attention linproj: 0.0005252361297607422
Post-attention Dropout: 0.0003457069396972656
Post-attention residual: 0.00011348724365234375
LN2: 0.00011515617370605469
MLP_h_4h: 0.003574848175048828
MLP_4h_h: 0.0017137527465820312
Post-MLP residual: 0.00033354759216308594
Attention layer time: 0.017184734344482422
LN1: 0.00013136863708496094
QKV Transform: 0.00247955322265625
Flash: 0.007421255111694336
Attention linproj: 0.0005309581756591797
Post-attention Dropout: 0.00034499168395996094
Post-attention residual: 0.00011372566223144531
LN2: 0.00011610984802246094
MLP_h_4h: 0.0035943984985351562
MLP_4h_h: 0.0017120838165283203
Post-MLP residual: 0.00034999847412109375
Attention layer time: 0.01709151268005371
LN1: 0.0001323223114013672
QKV Transform: 0.002524137496948242
Flash: 0.007424354553222656
Attention linproj: 0.0005216598510742188
Post-attention Dropout: 0.0003345012664794922
Post-attention residual: 0.00011301040649414062
LN2: 0.00011610984802246094
MLP_h_4h: 0.0036139488220214844
MLP_4h_h: 0.0017101764678955078
Post-MLP residual: 0.0003383159637451172
Attention layer time: 0.017117738723754883
LN1: 0.00013136863708496094
QKV Transform: 0.002406597137451172
Flash: 0.007418155670166016
Attention linproj: 0.0005233287811279297
Post-attention Dropout: 0.0003364086151123047
Post-attention residual: 0.00011277198791503906
LN2: 0.00011467933654785156
MLP_h_4h: 0.003595590591430664
MLP_4h_h: 0.001707315444946289
Post-MLP residual: 0.000354766845703125
Attention layer time: 0.017033100128173828
LN1: 0.00013256072998046875
QKV Transform: 0.002336263656616211
Flash: 0.007422924041748047
Attention linproj: 0.0005252361297607422
Post-attention Dropout: 0.00034356117248535156
Post-attention residual: 0.00011372566223144531
LN2: 0.0001163482666015625
MLP_h_4h: 0.003584623336791992
MLP_4h_h: 0.0017130374908447266
Post-MLP residual: 0.0003342628479003906
Attention layer time: 0.016934633255004883
LN1: 0.0001323223114013672
QKV Transform: 0.002454519271850586
Flash: 0.007425546646118164
Attention linproj: 0.0005211830139160156
Post-attention Dropout: 0.00036144256591796875
Post-attention residual: 0.00011348724365234375
LN2: 0.00011610984802246094
MLP_h_4h: 0.003578662872314453
MLP_4h_h: 0.0017130374908447266
Post-MLP residual: 0.0003387928009033203
Attention layer time: 0.017045974731445312
LN1: 0.00013256072998046875
QKV Transform: 0.0026280879974365234
Flash: 0.007416248321533203
Attention linproj: 0.000522613525390625
Post-attention Dropout: 0.0003371238708496094
Post-attention residual: 0.00011348724365234375
LN2: 0.00011539459228515625
MLP_h_4h: 0.0036096572875976562
MLP_4h_h: 0.0017104148864746094
Post-MLP residual: 0.00033926963806152344
Attention layer time: 0.01721954345703125
LN1: 0.0001304149627685547
QKV Transform: 0.0025529861450195312
Flash: 0.0074100494384765625
Attention linproj: 0.000522613525390625
Post-attention Dropout: 0.00034546852111816406
Post-attention residual: 0.00011277198791503906
LN2: 0.00011491775512695312
MLP_h_4h: 0.0036115646362304688
MLP_4h_h: 0.001708984375
Post-MLP residual: 0.00034332275390625
Attention layer time: 0.017150402069091797
LN1: 0.00013113021850585938
QKV Transform: 0.0025451183319091797
Flash: 0.0074062347412109375
Attention linproj: 0.0005254745483398438
Post-attention Dropout: 0.0003437995910644531
Post-attention residual: 0.00011229515075683594
LN2: 0.00011491775512695312
MLP_h_4h: 0.003587961196899414
MLP_4h_h: 0.0017154216766357422
Post-MLP residual: 0.00033473968505859375
Attention layer time: 0.017131805419921875
LN1: 0.00013303756713867188
QKV Transform: 0.002499818801879883
Flash: 0.007431745529174805
Attention linproj: 0.0005185604095458984
Post-attention Dropout: 0.0003571510314941406
Post-attention residual: 0.00011396408081054688
LN2: 0.00011658668518066406
MLP_h_4h: 0.0035614967346191406
MLP_4h_h: 0.0017135143280029297
Post-MLP residual: 0.00033783912658691406
Attention layer time: 0.017084121704101562
LN1: 0.0001323223114013672
QKV Transform: 0.002607583999633789
Flash: 0.007424116134643555
Attention linproj: 0.0005204677581787109
Post-attention Dropout: 0.0003342628479003906
Post-attention residual: 0.00011301040649414062
LN2: 0.00011515617370605469
MLP_h_4h: 0.003603696823120117
MLP_4h_h: 0.0017077922821044922
Post-MLP residual: 0.00034046173095703125
Attention layer time: 0.01719188690185547
LN1: 0.0001316070556640625
QKV Transform: 0.0026521682739257812
Flash: 0.0074346065521240234
Attention linproj: 0.0005202293395996094
Post-attention Dropout: 0.00033473968505859375
Post-attention residual: 0.00011372566223144531
LN2: 0.00011467933654785156
MLP_h_4h: 0.0036063194274902344
MLP_4h_h: 0.0017085075378417969
Post-MLP residual: 0.0003445148468017578
Attention layer time: 0.017253398895263672
LN1: 0.00013136863708496094
QKV Transform: 0.002365589141845703
Flash: 0.007398843765258789
Attention linproj: 0.0005245208740234375
Post-attention Dropout: 0.00034427642822265625
Post-attention residual: 0.00011277198791503906
LN2: 0.00011467933654785156
MLP_h_4h: 0.0035936832427978516
MLP_4h_h: 0.0017132759094238281
Post-MLP residual: 0.0003345012664794922
Attention layer time: 0.016945838928222656
LN1: 0.00013256072998046875
QKV Transform: 0.002490520477294922
Flash: 0.007430553436279297
Attention linproj: 0.0005199909210205078
Post-attention Dropout: 0.0003426074981689453
Post-attention residual: 0.00011348724365234375
LN2: 0.00011563301086425781
MLP_h_4h: 0.0035970211029052734
MLP_4h_h: 0.0017116069793701172
Post-MLP residual: 0.0003364086151123047
Attention layer time: 0.01707935333251953
LN1: 0.0001480579376220703
QKV Transform: 0.0026199817657470703
Flash: 0.0074176788330078125
Attention linproj: 0.0005197525024414062
Post-attention Dropout: 0.0003368854522705078
Post-attention residual: 0.00011396408081054688
LN2: 0.00011515617370605469
MLP_h_4h: 0.0036132335662841797
MLP_4h_h: 0.001718282699584961
Post-MLP residual: 0.00033926963806152344
Attention layer time: 0.017235994338989258
LN1: 0.00013017654418945312
QKV Transform: 0.002544403076171875
Flash: 0.007409572601318359
Attention linproj: 0.0005233287811279297
Post-attention Dropout: 0.0003364086151123047
Post-attention residual: 0.00011301040649414062
LN2: 0.00011420249938964844
MLP_h_4h: 0.0036115646362304688
MLP_4h_h: 0.0017099380493164062
Post-MLP residual: 0.0003349781036376953
Attention layer time: 0.017122983932495117
LN1: 0.0001308917999267578
QKV Transform: 0.002535581588745117
Flash: 0.007416486740112305
Attention linproj: 0.0005257129669189453
Post-attention Dropout: 0.0003457069396972656
Post-attention residual: 0.00011277198791503906
LN2: 0.00011491775512695312
MLP_h_4h: 0.003590106964111328
MLP_4h_h: 0.001712799072265625
Post-MLP residual: 0.00033283233642578125
Attention layer time: 0.01711726188659668
LN1: 0.0001316070556640625
QKV Transform: 0.0027959346771240234
Flash: 0.007416725158691406
Attention linproj: 0.0005238056182861328
Post-attention Dropout: 0.0003440380096435547
Post-attention residual: 0.00011396408081054688
LN2: 0.00011563301086425781
MLP_h_4h: 0.0035762786865234375
MLP_4h_h: 0.001714468002319336
Post-MLP residual: 0.00033402442932128906
Attention layer time: 0.017383337020874023
LN1: 0.00013399124145507812
QKV Transform: 0.0023152828216552734
Flash: 0.007420539855957031
Attention linproj: 0.0005204677581787109
Post-attention Dropout: 0.0003447532653808594
Post-attention residual: 0.00011277198791503906
LN2: 0.00011539459228515625
MLP_h_4h: 0.003600597381591797
MLP_4h_h: 0.0017154216766357422
Post-MLP residual: 0.0003402233123779297
Attention layer time: 0.016910552978515625
LN1: 0.0001494884490966797
QKV Transform: 0.002619028091430664
Flash: 0.007420539855957031
Attention linproj: 0.0005202293395996094
Post-attention Dropout: 0.0003349781036376953
Post-attention residual: 0.00011348724365234375
LN2: 0.00011563301086425781
MLP_h_4h: 0.003604888916015625
MLP_4h_h: 0.0017213821411132812
Post-MLP residual: 0.0003414154052734375
Attention layer time: 0.017233610153198242
LN1: 0.00013017654418945312
QKV Transform: 0.0026051998138427734
Flash: 0.007412433624267578
Attention linproj: 0.0005233287811279297
Post-attention Dropout: 0.000339508056640625
Post-attention residual: 0.00011229515075683594
LN2: 0.00011467933654785156
MLP_h_4h: 0.003604888916015625
MLP_4h_h: 0.0016982555389404297
Post-MLP residual: 0.0003361701965332031
Attention layer time: 0.017169952392578125
LN1: 0.0001304149627685547
QKV Transform: 0.0024869441986083984
Flash: 0.00741887092590332
Attention linproj: 0.0005257129669189453
Post-attention Dropout: 0.0003445148468017578
Post-attention residual: 0.00011277198791503906
LN2: 0.00011491775512695312
MLP_h_4h: 0.003596782684326172
MLP_4h_h: 0.0017123222351074219
Post-MLP residual: 0.0003352165222167969
Attention layer time: 0.017076492309570312
LN1: 0.00014352798461914062
QKV Transform: 0.002412557601928711
Flash: 0.007424831390380859
Attention linproj: 0.0005202293395996094
Post-attention Dropout: 0.0003333091735839844
Post-attention residual: 0.00011539459228515625
LN2: 0.00011610984802246094
MLP_h_4h: 0.0036160945892333984
MLP_4h_h: 0.001712799072265625
Post-MLP residual: 0.000339508056640625
Attention layer time: 0.017023324966430664
LN1: 0.0001404285430908203
QKV Transform: 0.0026383399963378906
Flash: 0.0074310302734375
Attention linproj: 0.0005207061767578125
Post-attention Dropout: 0.00033473968505859375
Post-attention residual: 0.00011277198791503906
LN2: 0.00011444091796875
MLP_h_4h: 0.0036096572875976562
MLP_4h_h: 0.0017080307006835938
Post-MLP residual: 0.00035452842712402344
Attention layer time: 0.01725459098815918
LN1: 0.00013113021850585938
QKV Transform: 0.002638578414916992
Flash: 0.0074079036712646484
Attention linproj: 0.0005214214324951172
Post-attention Dropout: 0.00033473968505859375
Post-attention residual: 0.00011229515075683594
LN2: 0.00011587142944335938
MLP_h_4h: 0.0036153793334960938
MLP_4h_h: 0.001707315444946289
Post-MLP residual: 0.0003345012664794922
Attention layer time: 0.01723456382751465
LN1: 0.00013399124145507812
QKV Transform: 0.0024602413177490234
Flash: 0.007411479949951172
Attention linproj: 0.00054168701171875
Post-attention Dropout: 0.0003552436828613281
Post-attention residual: 0.00011372566223144531
LN2: 0.00011587142944335938
MLP_h_4h: 0.0035657882690429688
MLP_4h_h: 0.0017125606536865234
Post-MLP residual: 0.00033473968505859375
Attention layer time: 0.01704859733581543
LN1: 0.00013327598571777344
QKV Transform: 0.0025179386138916016
Flash: 0.007425785064697266
Attention linproj: 0.0005209445953369141
Post-attention Dropout: 0.0003349781036376953
Post-attention residual: 0.00011444091796875
LN2: 0.00011682510375976562
MLP_h_4h: 0.0036029815673828125
MLP_4h_h: 0.0017054080963134766
Post-MLP residual: 0.00033783912658691406
Attention layer time: 0.01710033416748047
LN1: 0.00013184547424316406
QKV Transform: 0.002664327621459961
Flash: 0.007426261901855469
Attention linproj: 0.0005197525024414062
Post-attention Dropout: 0.00033402442932128906
Post-attention residual: 0.00011324882507324219
LN2: 0.00011539459228515625
MLP_h_4h: 0.0036220550537109375
MLP_4h_h: 0.0017082691192626953
Post-MLP residual: 0.00035309791564941406
Attention layer time: 0.017281770706176758
LN1: 0.00013136863708496094
QKV Transform: 0.0024013519287109375
Flash: 0.008465766906738281
Attention linproj: 0.0005221366882324219
Post-attention Dropout: 0.0003364086151123047
Post-attention residual: 0.00011301040649414062
LN2: 0.00011491775512695312
MLP_h_4h: 0.0035924911499023438
MLP_4h_h: 0.001707315444946289
Post-MLP residual: 0.0003516674041748047
Attention layer time: 0.018032312393188477
LN1: 0.0001304149627685547
QKV Transform: 0.0025789737701416016
Flash: 0.008288383483886719
Attention linproj: 0.0005486011505126953
Post-attention Dropout: 0.00037217140197753906
Post-attention residual: 0.00011563301086425781
LN2: 0.00013017654418945312
MLP_h_4h: 0.003522157669067383
MLP_4h_h: 0.0017101764678955078
Post-MLP residual: 0.00034236907958984375
Attention layer time: 0.0181884765625
LN1: 0.0001304149627685547
QKV Transform: 0.0025119781494140625
Flash: 0.0074307918548583984
Attention linproj: 0.000522613525390625
Post-attention Dropout: 0.000339508056640625
Post-attention residual: 0.00011181831359863281
LN2: 0.00011420249938964844
MLP_h_4h: 0.0035943984985351562
MLP_4h_h: 0.0017101764678955078
Post-MLP residual: 0.000335693359375
Attention layer time: 0.017100095748901367
LN1: 0.00013184547424316406
QKV Transform: 0.002585887908935547
Flash: 0.007427215576171875
Attention linproj: 0.0005249977111816406
Post-attention Dropout: 0.00034546852111816406
Post-attention residual: 0.00011277198791503906
LN2: 0.00011539459228515625
MLP_h_4h: 0.0035762786865234375
MLP_4h_h: 0.001714944839477539
Post-MLP residual: 0.0003337860107421875
Attention layer time: 0.01716923713684082
LN1: 0.00013327598571777344
QKV Transform: 0.0024573802947998047
Flash: 0.0074269771575927734
Attention linproj: 0.0005197525024414062
Post-attention Dropout: 0.0003349781036376953
Post-attention residual: 0.00011396408081054688
LN2: 0.00011658668518066406
MLP_h_4h: 0.0036067962646484375
MLP_4h_h: 0.0017139911651611328
Post-MLP residual: 0.00033855438232421875
Attention layer time: 0.01705026626586914
LN1: 0.00013065338134765625
QKV Transform: 0.00267791748046875
Flash: 0.007418632507324219
Attention linproj: 0.0005197525024414062
Post-attention Dropout: 0.0003337860107421875
Post-attention residual: 0.0001125335693359375
LN2: 0.00011539459228515625
MLP_h_4h: 0.003614664077758789
MLP_4h_h: 0.0017125606536865234
Post-MLP residual: 0.0003533363342285156
Attention layer time: 0.017287015914916992
LN1: 0.00012993812561035156
QKV Transform: 0.0026111602783203125
Flash: 0.007424354553222656
Attention linproj: 0.0005223751068115234
Post-attention Dropout: 0.0003383159637451172
Post-attention residual: 0.00011205673217773438
LN2: 0.00011491775512695312
MLP_h_4h: 0.0035924911499023438
MLP_4h_h: 0.0017096996307373047
Post-MLP residual: 0.0003361701965332031
Attention layer time: 0.017187118530273438
LN1: 0.00013136863708496094
QKV Transform: 0.0024797916412353516
Flash: 0.007412433624267578
Attention linproj: 0.0005433559417724609
Post-attention Dropout: 0.0003540515899658203
Post-attention residual: 0.00011229515075683594
LN2: 0.00011444091796875
MLP_h_4h: 0.0035674571990966797
MLP_4h_h: 0.0017158985137939453
Post-MLP residual: 0.0003345012664794922
Attention layer time: 0.01706528663635254
LN1: 0.00013208389282226562
QKV Transform: 0.002524852752685547
Flash: 0.0074307918548583984
Attention linproj: 0.0005207061767578125
Post-attention Dropout: 0.00033473968505859375
Post-attention residual: 0.00011372566223144531
LN2: 0.00011730194091796875
MLP_h_4h: 0.0035986900329589844
MLP_4h_h: 0.0017049312591552734
Post-MLP residual: 0.0003371238708496094
Attention layer time: 0.017108440399169922
LN1: 0.00013375282287597656
QKV Transform: 0.002521514892578125
Flash: 0.0074198246002197266
Attention linproj: 0.0005202293395996094
Post-attention Dropout: 0.00033473968505859375
Post-attention residual: 0.00011348724365234375
LN2: 0.00011444091796875
MLP_h_4h: 0.003631114959716797
MLP_4h_h: 0.0017104148864746094
Post-MLP residual: 0.0003535747528076172
Attention layer time: 0.017158985137939453
LN1: 0.00013208389282226562
QKV Transform: 0.0024695396423339844
Flash: 0.007425546646118164
Attention linproj: 0.0005238056182861328
Post-attention Dropout: 0.0003387928009033203
Post-attention residual: 0.00011730194091796875
LN2: 0.00011515617370605469
MLP_h_4h: 0.0035920143127441406
MLP_4h_h: 0.0017104148864746094
Post-MLP residual: 0.0003345012664794922
Attention layer time: 0.01705765724182129
LN1: 0.0001316070556640625
QKV Transform: 0.0025703907012939453
Flash: 0.00742340087890625
Attention linproj: 0.0005247592926025391
Post-attention Dropout: 0.0003628730773925781
Post-attention residual: 0.00011372566223144531
LN2: 0.00011467933654785156
MLP_h_4h: 0.0035674571990966797
MLP_4h_h: 0.001714944839477539
Post-MLP residual: 0.0003368854522705078
Attention layer time: 0.017157554626464844
LN1: 0.0001327991485595703
QKV Transform: 0.0024580955505371094
Flash: 0.007422685623168945
Attention linproj: 0.0005199909210205078
Post-attention Dropout: 0.0003349781036376953
Post-attention residual: 0.00011324882507324219
LN2: 0.00011754035949707031
MLP_h_4h: 0.003615140914916992
MLP_4h_h: 0.0017046928405761719
Post-MLP residual: 0.0003361701965332031
Attention layer time: 0.017049312591552734
LN1: 0.00013113021850585938
QKV Transform: 0.002614736557006836
Flash: 0.007418155670166016
Attention linproj: 0.0005247592926025391
Post-attention Dropout: 0.00033473968505859375
Post-attention residual: 0.00011301040649414062
LN2: 0.00011444091796875
MLP_h_4h: 0.0036284923553466797
MLP_4h_h: 0.001710653305053711
Post-MLP residual: 0.0003383159637451172
Attention layer time: 0.017218589782714844
LN1: 0.00013113021850585938
QKV Transform: 0.0026175975799560547
Flash: 0.007421731948852539
Attention linproj: 0.0005235671997070312
Post-attention Dropout: 0.000339508056640625
Post-attention residual: 0.00011205673217773438
LN2: 0.00011467933654785156
MLP_h_4h: 0.0036013126373291016
MLP_4h_h: 0.0017082691192626953
Post-MLP residual: 0.00033473968505859375
Attention layer time: 0.017199993133544922
LN1: 0.00013065338134765625
QKV Transform: 0.0025949478149414062
Flash: 0.007420063018798828
Attention linproj: 0.0005249977111816406
Post-attention Dropout: 0.0003631114959716797
Post-attention residual: 0.00011348724365234375
LN2: 0.0001163482666015625
MLP_h_4h: 0.0035712718963623047
MLP_4h_h: 0.0017142295837402344
Post-MLP residual: 0.00033664703369140625
Attention layer time: 0.01718449592590332
LN1: 0.00014400482177734375
QKV Transform: 0.002276182174682617
Flash: 0.007424592971801758
Attention linproj: 0.0005197525024414062
Post-attention Dropout: 0.00033593177795410156
Post-attention residual: 0.00011587142944335938
LN2: 0.00011920928955078125
MLP_h_4h: 0.003574848175048828
MLP_4h_h: 0.0017173290252685547
Post-MLP residual: 0.0003364086151123047
Attention layer time: 0.016882896423339844
LN1: 0.00013113021850585938
QKV Transform: 0.002565622329711914
Flash: 0.007435321807861328
Attention linproj: 0.0005197525024414062
Post-attention Dropout: 0.0003330707550048828
Post-attention residual: 0.00011301040649414062
LN2: 0.00011324882507324219
MLP_h_4h: 0.003609895706176758
MLP_4h_h: 0.001708984375
Post-MLP residual: 0.0003387928009033203
Attention layer time: 0.01716017723083496
LN1: 0.00013113021850585938
QKV Transform: 0.0026149749755859375
Flash: 0.0074160099029541016
Attention linproj: 0.0005304813385009766
Post-attention Dropout: 0.0003342628479003906
Post-attention residual: 0.00011301040649414062
LN2: 0.00011444091796875
MLP_h_4h: 0.0035965442657470703
MLP_4h_h: 0.0017218589782714844
Post-MLP residual: 0.00033736228942871094
Attention layer time: 0.017205238342285156
LN1: 0.0001323223114013672
QKV Transform: 0.0025322437286376953
Flash: 0.007430553436279297
Attention linproj: 0.0005240440368652344
Post-attention Dropout: 0.00034356117248535156
Post-attention residual: 0.00011491775512695312
LN2: 0.00011706352233886719
MLP_h_4h: 0.0035772323608398438
MLP_4h_h: 0.001714944839477539
Post-MLP residual: 0.0003342628479003906
Attention layer time: 0.017124652862548828
LN1: 0.00013399124145507812
QKV Transform: 0.00455784797668457
Flash: 0.007428646087646484
Attention linproj: 0.0005400180816650391
Post-attention Dropout: 0.0003380775451660156
Post-attention residual: 0.00011229515075683594
LN2: 0.00011515617370605469
MLP_h_4h: 0.003580331802368164
MLP_4h_h: 0.0017099380493164062
Post-MLP residual: 0.0003342628479003906
Attention layer time: 0.019148826599121094
LN1: 0.0001323223114013672
QKV Transform: 0.0025606155395507812
Flash: 0.007422924041748047
Attention linproj: 0.0005259513854980469
Post-attention Dropout: 0.00034332275390625
Post-attention residual: 0.00011348724365234375
LN2: 0.0001163482666015625
MLP_h_4h: 0.0035657882690429688
MLP_4h_h: 0.001718759536743164
Post-MLP residual: 0.0003352165222167969
Attention layer time: 0.017154216766357422
LN1: 0.00013113021850585938
QKV Transform: 0.002559185028076172
Flash: 0.0074193477630615234
Attention linproj: 0.0005204677581787109
Post-attention Dropout: 0.0003337860107421875
Post-attention residual: 0.0001125335693359375
LN2: 0.00011491775512695312
MLP_h_4h: 0.0036084651947021484
MLP_4h_h: 0.0017099380493164062
Post-MLP residual: 0.0003345012664794922
Attention layer time: 0.017139196395874023
LN1: 0.00013208389282226562
QKV Transform: 0.0025146007537841797
Flash: 0.007413148880004883
Attention linproj: 0.0005152225494384766
Post-attention Dropout: 0.00034332275390625
Post-attention residual: 0.0001125335693359375
LN2: 0.00011658668518066406
MLP_h_4h: 0.0036017894744873047
MLP_4h_h: 0.001714944839477539
Post-MLP residual: 0.0003337860107421875
Attention layer time: 0.017102718353271484
LN1: 0.00013375282287597656
QKV Transform: 0.002511739730834961
Flash: 0.0074160099029541016
Attention linproj: 0.0005214214324951172
Post-attention Dropout: 0.0003333091735839844
Post-attention residual: 0.00011444091796875
LN2: 0.00012230873107910156
MLP_h_4h: 0.0036132335662841797
MLP_4h_h: 0.0017135143280029297
Post-MLP residual: 0.0003368854522705078
Attention layer time: 0.017108678817749023
LN1: 0.00013947486877441406
QKV Transform: 0.002642393112182617
Flash: 0.007427692413330078
Attention linproj: 0.0005195140838623047
Post-attention Dropout: 0.00033164024353027344
Post-attention residual: 0.00011372566223144531
LN2: 0.00011467933654785156
MLP_h_4h: 0.0036034584045410156
MLP_4h_h: 0.0017094612121582031
Post-MLP residual: 0.0003514289855957031
Attention layer time: 0.017245054244995117
LN1: 0.00013208389282226562
QKV Transform: 0.0024442672729492188
Flash: 0.007429599761962891
Attention linproj: 0.0005216598510742188
Post-attention Dropout: 0.00033664703369140625
Post-attention residual: 0.00011277198791503906
LN2: 0.00011444091796875
MLP_h_4h: 0.002534627914428711
MLP_4h_h: 0.0017137527465820312
Post-MLP residual: 0.00033664703369140625
Attention layer time: 0.015982627868652344
LN1: 0.00013256072998046875
QKV Transform: 0.002517223358154297
Flash: 0.007421255111694336
Attention linproj: 0.0005245208740234375
Post-attention Dropout: 0.0003345012664794922
Post-attention residual: 0.00011467933654785156
LN2: 0.00011706352233886719
MLP_h_4h: 0.003613710403442383
MLP_4h_h: 0.001705169677734375
Post-MLP residual: 0.00033473968505859375
Attention layer time: 0.01710653305053711
LN1: 0.00013208389282226562
QKV Transform: 0.0026340484619140625
Flash: 0.007436037063598633
Attention linproj: 0.0005209445953369141
Post-attention Dropout: 0.00033545494079589844
Post-attention residual: 0.00011181831359863281
LN2: 0.00011539459228515625
MLP_h_4h: 0.0036215782165527344
MLP_4h_h: 0.001708984375
Post-MLP residual: 0.00033783912658691406
Attention layer time: 0.017261505126953125
LN1: 0.0001304149627685547
QKV Transform: 0.0024919509887695312
Flash: 0.007421731948852539
Attention linproj: 0.0005221366882324219
Post-attention Dropout: 0.00033736228942871094
Post-attention residual: 0.00011348724365234375
LN2: 0.00011372566223144531
MLP_h_4h: 0.0036072731018066406
MLP_4h_h: 0.0017116069793701172
Post-MLP residual: 0.0003361701965332031
Attention layer time: 0.017078638076782227
LN1: 0.00013136863708496094
QKV Transform: 0.002460002899169922
Flash: 0.0074236392974853516
Attention linproj: 0.0005245208740234375
Post-attention Dropout: 0.0003609657287597656
Post-attention residual: 0.00011372566223144531
LN2: 0.00011563301086425781
MLP_h_4h: 0.0035653114318847656
MLP_4h_h: 0.001714468002319336
Post-MLP residual: 0.00033402442932128906
Attention layer time: 0.017045259475708008
LN1: 0.0001342296600341797
QKV Transform: 0.0022428035736083984
Flash: 0.007417917251586914
Attention linproj: 0.0005195140838623047
Post-attention Dropout: 0.00033545494079589844
Post-attention residual: 0.00011420249938964844
LN2: 0.00011682510375976562
MLP_h_4h: 0.003618001937866211
MLP_4h_h: 0.001718282699584961
Post-MLP residual: 0.00033593177795410156
Attention layer time: 0.016841650009155273
LN1: 0.00013065338134765625
QKV Transform: 0.0026655197143554688
Flash: 0.007444620132446289
Attention linproj: 0.0005204677581787109
Post-attention Dropout: 0.0003352165222167969
Post-attention residual: 0.00011301040649414062
LN2: 0.00011420249938964844
MLP_h_4h: 0.003593921661376953
MLP_4h_h: 0.0017113685607910156
Post-MLP residual: 0.0003383159637451172
Attention layer time: 0.01725912094116211
LN1: 0.0001304149627685547
QKV Transform: 0.0025501251220703125
Flash: 0.0074138641357421875
Attention linproj: 0.0005316734313964844
Post-attention Dropout: 0.0003361701965332031
Post-attention residual: 0.00011205673217773438
LN2: 0.00011444091796875
MLP_h_4h: 0.0036025047302246094
MLP_4h_h: 0.0017004013061523438
Post-MLP residual: 0.0003407001495361328
Attention layer time: 0.017123937606811523
LN1: 0.0001316070556640625
QKV Transform: 0.002490520477294922
Flash: 0.00740814208984375
Attention linproj: 0.0005238056182861328
Post-attention Dropout: 0.0003459453582763672
Post-attention residual: 0.00011444091796875
LN2: 0.00012922286987304688
MLP_h_4h: 0.003580808639526367
MLP_4h_h: 0.0017142295837402344
Post-MLP residual: 0.0003333091735839844
Attention layer time: 0.017073631286621094
LN1: 0.00013256072998046875
QKV Transform: 0.0024209022521972656
Flash: 0.007429599761962891
Attention linproj: 0.0005178451538085938
Post-attention Dropout: 0.00033736228942871094
Post-attention residual: 0.00011396408081054688
LN2: 0.00011730194091796875
MLP_h_4h: 0.003605365753173828
MLP_4h_h: 0.0017247200012207031
Post-MLP residual: 0.00033974647521972656
Attention layer time: 0.01702880859375
LN1: 0.00013113021850585938
QKV Transform: 0.0026526451110839844
Flash: 0.007422208786010742
Attention linproj: 0.0005228519439697266
Post-attention Dropout: 0.0003383159637451172
Post-attention residual: 0.00011229515075683594
LN2: 0.00011610984802246094
MLP_h_4h: 0.0036001205444335938
MLP_4h_h: 0.0017099380493164062
Post-MLP residual: 0.0003409385681152344
Attention layer time: 0.01725912094116211
LN1: 0.00013113021850585938
QKV Transform: 0.0025911331176757812
Flash: 0.007435321807861328
Attention linproj: 0.0005328655242919922
Post-attention Dropout: 0.0003371238708496094
Post-attention residual: 0.00011372566223144531
LN2: 0.00011563301086425781
MLP_h_4h: 0.0035855770111083984
MLP_4h_h: 0.001712799072265625
Post-MLP residual: 0.0003345012664794922
Attention layer time: 0.017200946807861328
LN1: 0.00013136863708496094
QKV Transform: 0.0024890899658203125
Flash: 0.007437705993652344
Attention linproj: 0.0005235671997070312
Post-attention Dropout: 0.00034165382385253906
Post-attention residual: 0.00011515617370605469
LN2: 0.0001163482666015625
MLP_h_4h: 0.003574848175048828
MLP_4h_h: 0.0017132759094238281
Post-MLP residual: 0.00033545494079589844
Attention layer time: 0.017078161239624023
LN1: 0.00013518333435058594
QKV Transform: 0.0025191307067871094
Flash: 0.007424831390380859
Attention linproj: 0.0005214214324951172
Post-attention Dropout: 0.00033783912658691406
Post-attention residual: 0.00011324882507324219
LN2: 0.00011801719665527344
MLP_h_4h: 0.0036039352416992188
MLP_4h_h: 0.0017180442810058594
Post-MLP residual: 0.00033736228942871094
Attention layer time: 0.017120361328125
LN1: 0.0001308917999267578
QKV Transform: 0.002641439437866211
Flash: 0.007420539855957031
Attention linproj: 0.0005202293395996094
Post-attention Dropout: 0.0003333091735839844
Post-attention residual: 0.00011301040649414062
LN2: 0.00011515617370605469
MLP_h_4h: 0.0036020278930664062
MLP_4h_h: 0.0017113685607910156
Post-MLP residual: 0.00034117698669433594
Attention layer time: 0.017221450805664062
LN1: 0.0001304149627685547
QKV Transform: 0.0026397705078125
Flash: 0.0074269771575927734
Attention linproj: 0.0005147457122802734
Post-attention Dropout: 0.00034809112548828125
Post-attention residual: 0.00011277198791503906
LN2: 0.00011491775512695312
MLP_h_4h: 0.0036001205444335938
MLP_4h_h: 0.0017032623291015625
Post-MLP residual: 0.00033545494079589844
Attention layer time: 0.017230749130249023
LN1: 0.0001430511474609375
QKV Transform: 0.0024199485778808594
Flash: 0.007401227951049805
Attention linproj: 0.0005245208740234375
Post-attention Dropout: 0.00034427642822265625
Post-attention residual: 0.00011372566223144531
LN2: 0.00011682510375976562
MLP_h_4h: 0.0035898685455322266
MLP_4h_h: 0.00171661376953125
Post-MLP residual: 0.000335693359375
Attention layer time: 0.017024517059326172
LN1: 0.00013375282287597656
QKV Transform: 0.002439737319946289
Flash: 0.007437944412231445
Attention linproj: 0.0005202293395996094
Post-attention Dropout: 0.00034928321838378906
Post-attention residual: 0.00011372566223144531
LN2: 0.00011682510375976562
MLP_h_4h: 0.0035827159881591797
MLP_4h_h: 0.0017108917236328125
Post-MLP residual: 0.0003390312194824219
Attention layer time: 0.017037391662597656
LN1: 0.00013017654418945312
QKV Transform: 0.0026280879974365234
Flash: 0.007425785064697266
Attention linproj: 0.0005221366882324219
Post-attention Dropout: 0.000335693359375
Post-attention residual: 0.00011229515075683594
LN2: 0.00011491775512695312
MLP_h_4h: 0.0036046504974365234
MLP_4h_h: 0.0017108917236328125
Post-MLP residual: 0.000339508056640625
Attention layer time: 0.01721358299255371
LN1: 0.0001308917999267578
QKV Transform: 0.002622842788696289
Flash: 0.007408618927001953
Attention linproj: 0.0005242824554443359
Post-attention Dropout: 0.0003554821014404297
Post-attention residual: 0.00011301040649414062
LN2: 0.00011515617370605469
MLP_h_4h: 0.0035867691040039062
MLP_4h_h: 0.0017206668853759766
Post-MLP residual: 0.00033473968505859375
Attention layer time: 0.017215251922607422
LN1: 0.00013375282287597656
QKV Transform: 0.002431154251098633
Flash: 0.007433891296386719
Attention linproj: 0.0005235671997070312
Post-attention Dropout: 0.00034165382385253906
Post-attention residual: 0.00011491775512695312
LN2: 0.00011730194091796875
MLP_h_4h: 0.003578662872314453
MLP_4h_h: 0.0017156600952148438
Post-MLP residual: 0.0003345012664794922
Attention layer time: 0.017040252685546875
LN1: 0.0001323223114013672
QKV Transform: 0.002577543258666992
Flash: 0.007444143295288086
Attention linproj: 0.0005142688751220703
Post-attention Dropout: 0.00034356117248535156
Post-attention residual: 0.00011372566223144531
LN2: 0.0001285076141357422
MLP_h_4h: 0.003558635711669922
MLP_4h_h: 0.001714468002319336
Post-MLP residual: 0.0003376007080078125
Attention layer time: 0.017169952392578125
LN1: 0.00014853477478027344
QKV Transform: 0.0025463104248046875
Flash: 0.007424116134643555
Attention linproj: 0.0005195140838623047
Post-attention Dropout: 0.00033545494079589844
Post-attention residual: 0.00011444091796875
LN2: 0.00011682510375976562
MLP_h_4h: 0.0035963058471679688
MLP_4h_h: 0.001708984375
Post-MLP residual: 0.0003380775451660156
Attention layer time: 0.017156124114990234
LN1: 0.0001308917999267578
QKV Transform: 0.0026209354400634766
Flash: 0.007436513900756836
Attention linproj: 0.0005202293395996094
Post-attention Dropout: 0.0003349781036376953
Post-attention residual: 0.00011229515075683594
LN2: 0.00011539459228515625
MLP_h_4h: 0.003591775894165039
MLP_4h_h: 0.0017096996307373047
Post-MLP residual: 0.0003387928009033203
Attention layer time: 0.017200946807861328
LN1: 0.0001308917999267578
QKV Transform: 0.0021910667419433594
Flash: 0.007405757904052734
Attention linproj: 0.0005247592926025391
Post-attention Dropout: 0.0003376007080078125
Post-attention residual: 0.0001125335693359375
LN2: 0.00011587142944335938
MLP_h_4h: 0.003607511520385742
MLP_4h_h: 0.001711130142211914
Post-MLP residual: 0.00033402442932128906
Attention layer time: 0.016766071319580078
LN1: 0.00013065338134765625
QKV Transform: 0.002418041229248047
Flash: 0.0074193477630615234
Attention linproj: 0.0005247592926025391
Post-attention Dropout: 0.00034236907958984375
Post-attention residual: 0.00011348724365234375
LN2: 0.00011754035949707031
MLP_h_4h: 0.003580808639526367
MLP_4h_h: 0.0017147064208984375
Post-MLP residual: 0.00033473968505859375
Attention layer time: 0.0170133113861084
LN1: 0.00013399124145507812
QKV Transform: 0.0025818347930908203
Flash: 0.007416963577270508
Attention linproj: 0.0005202293395996094
Post-attention Dropout: 0.00033402442932128906
Post-attention residual: 0.00011372566223144531
LN2: 0.00011754035949707031
MLP_h_4h: 0.0035948753356933594
MLP_4h_h: 0.0017096996307373047
Post-MLP residual: 0.0003409385681152344
Attention layer time: 0.01716470718383789
LN1: 0.00013113021850585938
QKV Transform: 0.0025544166564941406
Flash: 0.0074310302734375
Attention linproj: 0.0005204677581787109
Post-attention Dropout: 0.0003349781036376953
Post-attention residual: 0.00011277198791503906
LN2: 0.00011467933654785156
MLP_h_4h: 0.003607511520385742
MLP_4h_h: 0.0017142295837402344
Post-MLP residual: 0.00033736228942871094
Attention layer time: 0.017147541046142578
LN1: 0.00014352798461914062
QKV Transform: 0.0023102760314941406
Flash: 0.007428884506225586
Attention linproj: 0.0005211830139160156
Post-attention Dropout: 0.0003349781036376953
Post-attention residual: 0.00011444091796875
LN2: 0.0001163482666015625
MLP_h_4h: 0.003605365753173828
MLP_4h_h: 0.0017178058624267578
Post-MLP residual: 0.00033593177795410156
Attention layer time: 0.016917943954467773
LN1: 0.00013017654418945312
QKV Transform: 0.002593994140625
Flash: 0.0074384212493896484
Attention linproj: 0.0005235671997070312
Post-attention Dropout: 0.0003337860107421875
Post-attention residual: 0.00011301040649414062
LN2: 0.00011444091796875
MLP_h_4h: 0.0036063194274902344
MLP_4h_h: 0.0017120838165283203
Post-MLP residual: 0.0003383159637451172
Attention layer time: 0.017192363739013672
LN1: 0.0001308917999267578
QKV Transform: 0.002603769302368164
Flash: 0.0074310302734375
Attention linproj: 0.0005133152008056641
Post-attention Dropout: 0.0003361701965332031
Post-attention residual: 0.00011205673217773438
LN2: 0.00011467933654785156
MLP_h_4h: 0.0036094188690185547
MLP_4h_h: 0.0017096996307373047
Post-MLP residual: 0.0003337860107421875
Attention layer time: 0.01719522476196289
LN1: 0.00013303756713867188
QKV Transform: 0.002517223358154297
Flash: 0.007422447204589844
Attention linproj: 0.0005249977111816406
Post-attention Dropout: 0.0003421306610107422
Post-attention residual: 0.00011467933654785156
LN2: 0.00011706352233886719
MLP_h_4h: 0.003563404083251953
MLP_4h_h: 0.0017147064208984375
Post-MLP residual: 0.0003342628479003906
Attention layer time: 0.017111778259277344
LN1: 0.00014925003051757812
QKV Transform: 0.0025565624237060547
Flash: 0.007422685623168945
Attention linproj: 0.0005209445953369141
Post-attention Dropout: 0.00033545494079589844
Post-attention residual: 0.0001308917999267578
LN2: 0.00011706352233886719
MLP_h_4h: 0.0035958290100097656
MLP_4h_h: 0.0017087459564208984
Post-MLP residual: 0.0003368854522705078
Attention layer time: 0.01716446876525879
LN1: 0.00013065338134765625
QKV Transform: 0.002603769302368164
Flash: 0.007420539855957031
Attention linproj: 0.0005204677581787109
Post-attention Dropout: 0.0003342628479003906
Post-attention residual: 0.00011348724365234375
LN2: 0.00011444091796875
MLP_h_4h: 0.003615140914916992
MLP_4h_h: 0.0017113685607910156
Post-MLP residual: 0.0003387928009033203
Attention layer time: 0.01719069480895996
LN1: 0.00013065338134765625
QKV Transform: 0.002521038055419922
Flash: 0.007422208786010742
Attention linproj: 0.0005135536193847656
Post-attention Dropout: 0.00034046173095703125
Post-attention residual: 0.00011324882507324219
LN2: 0.00011324882507324219
MLP_h_4h: 0.0036058425903320312
MLP_4h_h: 0.0017116069793701172
Post-MLP residual: 0.0003361701965332031
Attention layer time: 0.0171051025390625
LN1: 0.00013184547424316406
QKV Transform: 0.002538919448852539
Flash: 0.007427215576171875
Attention linproj: 0.0005235671997070312
Post-attention Dropout: 0.0003426074981689453
Post-attention residual: 0.00011396408081054688
LN2: 0.00011730194091796875
MLP_h_4h: 0.0035703182220458984
MLP_4h_h: 0.001714944839477539
Post-MLP residual: 0.00033354759216308594
Attention layer time: 0.01713275909423828
LN1: 0.0001327991485595703
QKV Transform: 0.002601146697998047
Flash: 0.0074269771575927734
Attention linproj: 0.0005218982696533203
Post-attention Dropout: 0.0003368854522705078
Post-attention residual: 0.00011301040649414062
LN2: 0.000118255615234375
MLP_h_4h: 0.0036249160766601562
MLP_4h_h: 0.0017096996307373047
Post-MLP residual: 0.0003383159637451172
Attention layer time: 0.01721501350402832
LN1: 0.00013208389282226562
QKV Transform: 0.0025641918182373047
Flash: 0.007417440414428711
Attention linproj: 0.0005216598510742188
Post-attention Dropout: 0.0003361701965332031
Post-attention residual: 0.00011277198791503906
LN2: 0.00011563301086425781
MLP_h_4h: 0.003612995147705078
MLP_4h_h: 0.0017096996307373047
Post-MLP residual: 0.00033855438232421875
Attention layer time: 0.01715087890625
LN1: 0.00013065338134765625
QKV Transform: 0.002609729766845703
Flash: 0.0074160099029541016
Attention linproj: 0.0005261898040771484
Post-attention Dropout: 0.00033473968505859375
Post-attention residual: 0.00012350082397460938
LN2: 0.00011467933654785156
MLP_h_4h: 0.003584623336791992
MLP_4h_h: 0.0017108917236328125
Post-MLP residual: 0.00033545494079589844
Attention layer time: 0.017180442810058594
LN1: 0.00013184547424316406
QKV Transform: 0.0025398731231689453
Flash: 0.007418632507324219
Attention linproj: 0.0005252361297607422
Post-attention Dropout: 0.00034332275390625
Post-attention residual: 0.00011563301086425781
LN2: 0.00011754035949707031
MLP_h_4h: 0.0035707950592041016
MLP_4h_h: 0.0017151832580566406
Post-MLP residual: 0.0003342628479003906
Attention layer time: 0.01714181900024414
LN1: 0.0001323223114013672
QKV Transform: 0.0024497509002685547
Flash: 0.007419586181640625
Attention linproj: 0.0005197525024414062
Post-attention Dropout: 0.00033354759216308594
Post-attention residual: 0.00012135505676269531
LN2: 0.00011730194091796875
MLP_h_4h: 0.003592967987060547
MLP_4h_h: 0.0017104148864746094
Post-MLP residual: 0.00033736228942871094
Attention layer time: 0.017026662826538086
Transformer duration (in seconds): 0.0190
Transformer throughput (in TFLOP/s): 76.816
========================================================================================================================

ERROR: Unable to locate a modulefile for 'cuda/11.7'
1.13.1 

[2023-11-20 18:58:19,102] [INFO] [distributed.py:36:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...
[2023-11-20 18:58:19,559] [INFO] [distributed.py:83:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=26.0.144.205, master_port=6000
[2023-11-20 18:58:19,559] [INFO] [distributed.py:46:init_distributed] Initializing torch distributed with backend: nccl
[2023-11-20 18:58:20,789] [INFO] [checkpointing.py:223:model_parallel_cuda_manual_seed] > initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234
num_attention_heads: 128, hidden_size: 16384, train_micro_batch_size_per_gpu: 4, tensor_mp_size: 1, pipeline_mp_size: 1, dp_size: 1


Actual
------
QKV Transform: 1.1164593696594238
Flash: 0.015961170196533203
Attention linproj: 0.016992807388305664
QKV Transform: 0.05202078819274902
Flash: 0.017765045166015625
Attention linproj: 0.016673803329467773
QKV Transform: 0.05205130577087402
Flash: 0.017855405807495117
Attention linproj: 0.016497135162353516
QKV Transform: 0.05112314224243164
Flash: 0.017136335372924805
Attention linproj: 0.016657590866088867
QKV Transform: 0.051312923431396484
Flash: 0.018382787704467773
Attention linproj: 0.016235828399658203
QKV Transform: 0.05044102668762207
Flash: 0.030177831649780273
Attention linproj: 0.016155481338500977
QKV Transform: 0.050950050354003906
Flash: 0.017455101013183594
Attention linproj: 0.016472578048706055
QKV Transform: 0.05104494094848633
Flash: 0.017466306686401367
Attention linproj: 0.016309738159179688
QKV Transform: 0.051808834075927734
Flash: 0.0171658992767334
Attention linproj: 0.01648235321044922
QKV Transform: 0.05073118209838867
Flash: 0.01820850372314453
Attention linproj: 0.016526222229003906
QKV Transform: 0.05126619338989258
Flash: 0.017325639724731445
Attention linproj: 0.016713857650756836
QKV Transform: 0.051758766174316406
Flash: 0.018064498901367188
Attention linproj: 0.01656365394592285
QKV Transform: 0.05103254318237305
Flash: 0.01732921600341797
Attention linproj: 0.01628255844116211
QKV Transform: 0.05070209503173828
Flash: 0.018244028091430664
Attention linproj: 0.016295671463012695
QKV Transform: 0.050798654556274414
Flash: 0.018402576446533203
Attention linproj: 0.016660451889038086
QKV Transform: 0.051450490951538086
Flash: 0.018184661865234375
Attention linproj: 0.016283512115478516
QKV Transform: 0.05058598518371582
Flash: 0.017583608627319336
Attention linproj: 0.016664743423461914
QKV Transform: 0.05143332481384277
Flash: 0.01925373077392578
Attention linproj: 0.01628732681274414
QKV Transform: 0.050601959228515625
Flash: 0.01855635643005371
Attention linproj: 0.016648054122924805
QKV Transform: 0.051077842712402344
Flash: 0.018369674682617188
Attention linproj: 0.016309261322021484
QKV Transform: 0.050791263580322266
Flash: 0.0172116756439209
Attention linproj: 0.0165865421295166
QKV Transform: 0.06297540664672852
Flash: 0.01823902130126953
Attention linproj: 0.016869544982910156
QKV Transform: 0.05123496055603027
Flash: 0.01814556121826172
Attention linproj: 0.01629185676574707
QKV Transform: 0.0505373477935791
Flash: 0.018469810485839844
Attention linproj: 0.01676154136657715
QKV Transform: 0.05127763748168945
Flash: 0.018201589584350586
Attention linproj: 0.016288042068481445
QKV Transform: 0.05084109306335449
Flash: 0.018426895141601562
Attention linproj: 0.016755342483520508
QKV Transform: 0.05124831199645996
Flash: 0.017237186431884766
Attention linproj: 0.01630115509033203
QKV Transform: 0.050780296325683594
Flash: 0.018392562866210938
Attention linproj: 0.01670360565185547
QKV Transform: 0.0508427619934082
Flash: 0.01730203628540039
Attention linproj: 0.016304492950439453
QKV Transform: 0.05152082443237305
Flash: 0.018370628356933594
Attention linproj: 0.016726016998291016
QKV Transform: 0.05113720893859863
Flash: 0.01710987091064453
Attention linproj: 0.016339778900146484
QKV Transform: 0.0513153076171875
Flash: 0.017273902893066406
Attention linproj: 0.016710758209228516
QKV Transform: 0.0516660213470459
Flash: 0.01811838150024414
Attention linproj: 0.016330957412719727
QKV Transform: 0.05107426643371582
Flash: 0.02122330665588379
Attention linproj: 0.016659975051879883
QKV Transform: 0.051659345626831055
Flash: 0.01928877830505371
Attention linproj: 0.016311168670654297
QKV Transform: 0.0510251522064209
Flash: 0.018309831619262695
Attention linproj: 0.016730785369873047
QKV Transform: 0.05147600173950195
Flash: 0.01824212074279785
Attention linproj: 0.016358613967895508
QKV Transform: 0.050810813903808594
Flash: 0.018350601196289062
Attention linproj: 0.016690969467163086
QKV Transform: 0.05140280723571777
Flash: 0.018213272094726562
Attention linproj: 0.016357898712158203
QKV Transform: 0.05089282989501953
Flash: 0.019331693649291992
Attention linproj: 0.0167233943939209
QKV Transform: 0.05158853530883789
Flash: 0.017984390258789062
Attention linproj: 0.016332149505615234
QKV Transform: 0.05072164535522461
Flash: 0.018360376358032227
Attention linproj: 0.016741514205932617
QKV Transform: 0.0509800910949707
Flash: 0.017132043838500977
Attention linproj: 0.016347646713256836
QKV Transform: 0.05132174491882324
Flash: 0.019275903701782227
Attention linproj: 0.016759157180786133
QKV Transform: 0.051140785217285156
Flash: 0.018083810806274414
Attention linproj: 0.01634836196899414
QKV Transform: 0.05072784423828125
Flash: 0.01723504066467285
Attention linproj: 0.01674365997314453
QKV Transform: 0.05147957801818848
Flash: 0.017032623291015625
Attention linproj: 0.016373157501220703
QKV Transform: 0.05084514617919922
Flash: 0.01924300193786621
Attention linproj: 0.01674652099609375
QKV Transform: 0.05145597457885742
Flash: 0.018151283264160156
Attention linproj: 0.016369104385375977
QKV Transform: 0.05087757110595703
Flash: 0.01715683937072754
Attention linproj: 0.016719341278076172
QKV Transform: 0.0514225959777832
Flash: 0.016982555389404297
Attention linproj: 0.016390323638916016
QKV Transform: 0.05178570747375488
Flash: 0.0169525146484375
Attention linproj: 0.016780614852905273
QKV Transform: 0.051553964614868164
Flash: 0.016965389251708984
Attention linproj: 0.016394615173339844
QKV Transform: 0.05150723457336426
Flash: 0.017874717712402344
Attention linproj: 0.016735315322875977
QKV Transform: 0.05195021629333496
Flash: 0.017933368682861328
Attention linproj: 0.016397714614868164
QKV Transform: 0.0510866641998291
Flash: 0.016973495483398438
Attention linproj: 0.01686549186706543
QKV Transform: 0.05121350288391113
Flash: 0.017916202545166016
Attention linproj: 0.016347169876098633
QKV Transform: 0.0516057014465332
Flash: 0.018094539642333984
Attention linproj: 0.01671290397644043
QKV Transform: 0.051123857498168945
Flash: 0.020273208618164062
Attention linproj: 0.016338348388671875
QKV Transform: 0.0513455867767334
Flash: 0.01726222038269043
Attention linproj: 0.01678776741027832
QKV Transform: 0.051245689392089844
Flash: 0.01798272132873535
Attention linproj: 0.016365528106689453
QKV Transform: 0.051575422286987305
Flash: 0.018192529678344727
Attention linproj: 0.016785860061645508
QKV Transform: 0.051070213317871094
Flash: 0.016946077346801758
Attention linproj: 0.016935110092163086
QKV Transform: 0.05104684829711914
Flash: 0.018229007720947266
Attention linproj: 0.016687393188476562
QKV Transform: 0.051522016525268555
Flash: 0.016930580139160156
Attention linproj: 0.016492366790771484
QKV Transform: 0.05120253562927246
Flash: 0.01814889907836914
Attention linproj: 0.016810894012451172
QKV Transform: 0.05163979530334473
Flash: 0.016948223114013672
Attention linproj: 0.016383886337280273
QKV Transform: 0.051244497299194336
Flash: 0.017299175262451172
Attention linproj: 0.016797542572021484
QKV Transform: 0.05083298683166504
Flash: 0.017115116119384766
Attention linproj: 0.016358613967895508
QKV Transform: 0.052080392837524414
Flash: 0.01712942123413086
Attention linproj: 0.01676344871520996
QKV Transform: 0.05130791664123535
Flash: 0.018164873123168945
Attention linproj: 0.01635289192199707
QKV Transform: 0.050904273986816406
Flash: 0.019217252731323242
Attention linproj: 0.01675868034362793
QKV Transform: 0.05151867866516113
Flash: 0.018137454986572266
Attention linproj: 0.016384601593017578
QKV Transform: 0.05169081687927246
Flash: 0.017204999923706055
Attention linproj: 0.016701698303222656
QKV Transform: 0.05117535591125488
Flash: 0.019147396087646484
Attention linproj: 0.016334056854248047
QKV Transform: 0.05141878128051758
Flash: 0.01829075813293457
Attention linproj: 0.016782283782958984
QKV Transform: 0.05114865303039551
Flash: 0.017295122146606445
Attention linproj: 0.016329288482666016
QKV Transform: 0.05160117149353027
Flash: 0.01719212532043457
Attention linproj: 0.016724109649658203
QKV Transform: 0.05115699768066406
Flash: 0.01811051368713379
Attention linproj: 0.016382217407226562
QKV Transform: 0.05067038536071777
Flash: 0.017374753952026367
Attention linproj: 0.016787290573120117
QKV Transform: 0.05123329162597656
Flash: 0.0169527530670166
Attention linproj: 0.016376018524169922
QKV Transform: 0.05149722099304199
Flash: 0.01873183250427246
Attention linproj: 0.016741514205932617
QKV Transform: 0.05186796188354492
Flash: 0.017988204956054688
Attention linproj: 0.016374826431274414
QKV Transform: 0.0510554313659668
Flash: 0.018054723739624023
Attention linproj: 0.016644001007080078
QKV Transform: 0.0517578125
Flash: 0.018052339553833008
Attention linproj: 0.01637554168701172
QKV Transform: 0.05173993110656738
Flash: 0.018216848373413086
Attention linproj: 0.016724824905395508
QKV Transform: 0.05146479606628418
Flash: 0.019182443618774414
Attention linproj: 0.016326189041137695
QKV Transform: 0.05112743377685547
Flash: 0.019169092178344727
Attention linproj: 0.01683640480041504
QKV Transform: 0.051287174224853516
Flash: 0.018146753311157227
Attention linproj: 0.0163571834564209
QKV Transform: 0.050795793533325195
Flash: 0.018273591995239258
Attention linproj: 0.016769886016845703
QKV Transform: 0.05115962028503418
Flash: 0.018204927444458008
Attention linproj: 0.016317367553710938
QKV Transform: 0.05173182487487793
Flash: 0.018377065658569336
Attention linproj: 0.01675891876220703
QKV Transform: 0.05123472213745117
Flash: 0.018033266067504883
Attention linproj: 0.01637887954711914
QKV Transform: 0.050737857818603516
Flash: 0.017200469970703125
Attention linproj: 0.016841650009155273
QKV Transform: 0.05124664306640625
Flash: 0.018129587173461914
Attention linproj: 0.016336917877197266
QKV Transform: 0.05103421211242676
Flash: 0.019191980361938477
Attention linproj: 0.0167691707611084
QKV Transform: 0.05175518989562988
Flash: 0.017835617065429688
Attention linproj: 0.016526460647583008
QKV Transform: 0.05193734169006348
Flash: 0.01688838005065918
Attention linproj: 0.016808748245239258
QKV Transform: 0.05120706558227539
Flash: 0.01695847511291504
Attention linproj: 0.016359806060791016
QKV Transform: 0.051909446716308594
Flash: 0.018117189407348633
Attention linproj: 0.016794919967651367
QKV Transform: 0.05134987831115723
Flash: 0.016936779022216797
Attention linproj: 0.01636791229248047
QKV Transform: 0.05125594139099121
Flash: 0.017007827758789062
Attention linproj: 0.01673412322998047
QKV Transform: 0.05112719535827637
Flash: 0.017970561981201172
Attention linproj: 0.01715087890625
QKV Transform: 0.052230119705200195
Flash: 0.018496036529541016
Attention linproj: 0.016696929931640625
QKV Transform: 0.05102419853210449
Flash: 0.017078876495361328
Attention linproj: 0.01638317108154297
QKV Transform: 0.05079293251037598
Flash: 0.01732039451599121
Attention linproj: 0.016782283782958984
QKV Transform: 0.05085873603820801
Flash: 0.01715087890625
Attention linproj: 0.016391754150390625
QKV Transform: 0.05165266990661621
Flash: 0.016957998275756836
Attention linproj: 0.01672983169555664
QKV Transform: 0.05159640312194824
Flash: 0.01688385009765625
Attention linproj: 0.016531705856323242
QKV Transform: 0.051831960678100586
Flash: 0.016750335693359375
Attention linproj: 0.016656875610351562
QKV Transform: 0.05122566223144531
Flash: 0.017047405242919922
Attention linproj: 0.016463518142700195
QKV Transform: 0.05158591270446777
Flash: 0.017080307006835938
Attention linproj: 0.016622304916381836
QKV Transform: 0.0517125129699707
Flash: 0.01780557632446289
Attention linproj: 0.016489267349243164
QKV Transform: 0.051560401916503906
Flash: 0.017767667770385742
Attention linproj: 0.01661205291748047
QKV Transform: 0.05173444747924805
Flash: 0.017068147659301758
Attention linproj: 0.016394376754760742
QKV Transform: 0.051867008209228516
Flash: 0.01804947853088379
Attention linproj: 0.016612529754638672
QKV Transform: 0.05180072784423828
Flash: 0.0180966854095459
Attention linproj: 0.01641106605529785
QKV Transform: 0.05192232131958008
Flash: 0.018010854721069336
Attention linproj: 0.01660776138305664
QKV Transform: 0.051770687103271484
Flash: 0.017141342163085938
Attention linproj: 0.016392946243286133
QKV Transform: 0.05192732810974121
Flash: 0.01788926124572754
Attention linproj: 0.016618728637695312
QKV Transform: 0.0517270565032959
Flash: 0.01922917366027832
Attention linproj: 0.01636981964111328
QKV Transform: 0.05202031135559082
Flash: 0.017910480499267578
Attention linproj: 0.016750097274780273
QKV Transform: 0.05137372016906738
Flash: 0.017956018447875977
Attention linproj: 0.016396045684814453
QKV Transform: 0.05185437202453613
Flash: 0.017862558364868164
Attention linproj: 0.016821861267089844
QKV Transform: 0.05145764350891113
Flash: 0.01889348030090332
Attention linproj: 0.01640152931213379
QKV Transform: 0.05146360397338867
Flash: 0.019113779067993164
Attention linproj: 0.01685619354248047
QKV Transform: 0.05142784118652344
Flash: 0.018112659454345703
Attention linproj: 0.016384601593017578
QKV Transform: 0.05173993110656738
Flash: 0.018151283264160156
Attention linproj: 0.01674199104309082
QKV Transform: 0.0511324405670166
Flash: 0.017993688583374023
Attention linproj: 0.016416549682617188
QKV Transform: 0.05121660232543945
Flash: 0.018007516860961914
Attention linproj: 0.016757726669311523
QKV Transform: 0.05196571350097656
Flash: 0.017749547958374023
Attention linproj: 0.01648712158203125
QKV Transform: 0.05188417434692383
Flash: 0.0180971622467041
Attention linproj: 0.016707658767700195
QKV Transform: 0.05213522911071777
Flash: 0.01744842529296875
Attention linproj: 0.016475915908813477
QKV Transform: 0.05179715156555176
Flash: 0.01924586296081543
Attention linproj: 0.01638627052307129
QKV Transform: 0.051878929138183594
Flash: 0.01793050765991211
Attention linproj: 0.016482114791870117
QKV Transform: 0.05086803436279297
Flash: 0.01816248893737793
Attention linproj: 0.01667618751525879
QKV Transform: 0.0516972541809082
Flash: 0.017735958099365234
Attention linproj: 0.01648855209350586
QKV Transform: 0.05182671546936035
Flash: 0.018112897872924805
Attention linproj: 0.016592741012573242
QKV Transform: 0.051633358001708984
Flash: 0.01772594451904297
Attention linproj: 0.016507625579833984
QKV Transform: 0.0513303279876709
Flash: 0.018189430236816406
Attention linproj: 0.016521692276000977
QKV Transform: 0.051578521728515625
Flash: 0.017728567123413086
Attention linproj: 0.016577959060668945
QKV Transform: 0.0518033504486084
Flash: 0.01821756362915039
Attention linproj: 0.01636672019958496
QKV Transform: 0.0515444278717041
Flash: 0.019114971160888672
Attention linproj: 0.016473054885864258
QKV Transform: 0.05097818374633789
Flash: 0.018122196197509766
Attention linproj: 0.016379594802856445
QKV Transform: 0.05096626281738281
Flash: 0.016863346099853516
Attention linproj: 0.016481876373291016
QKV Transform: 0.05169939994812012
Flash: 0.018136978149414062
Attention linproj: 0.016440629959106445
QKV Transform: 0.05171942710876465
Flash: 0.01791214942932129
Attention linproj: 0.01647806167602539
QKV Transform: 0.05267214775085449
Flash: 0.01821160316467285
Attention linproj: 0.01633930206298828
QKV Transform: 0.05190467834472656
Flash: 0.0189974308013916
Attention linproj: 0.016629695892333984
QKV Transform: 0.05151963233947754
Flash: 0.018896102905273438
Attention linproj: 0.016408920288085938
Attention duration (in seconds): 0.0912
Attention throughput (in TFLOP/s): 204.970
MLP_h_4h: 0.18663835525512695
MLP_4h_h: 0.0688483715057373
MLP_h_4h: 0.07165765762329102
MLP_4h_h: 0.06801962852478027
MLP_h_4h: 0.07021951675415039
MLP_4h_h: 0.06830334663391113
MLP_h_4h: 0.07027506828308105
MLP_4h_h: 0.06839394569396973
MLP_h_4h: 0.07067751884460449
MLP_4h_h: 0.07094097137451172
MLP_h_4h: 0.07181596755981445
MLP_4h_h: 0.06851983070373535
MLP_h_4h: 0.07028961181640625
MLP_4h_h: 0.06913995742797852
MLP_h_4h: 0.07326483726501465
MLP_4h_h: 0.06938576698303223
MLP_h_4h: 0.07007551193237305
MLP_4h_h: 0.06831717491149902
MLP_h_4h: 0.07071685791015625
MLP_4h_h: 0.06982779502868652
MLP_h_4h: 0.07262253761291504
MLP_4h_h: 0.06869673728942871
MLP_h_4h: 0.07095003128051758
MLP_4h_h: 0.07074499130249023
MLP_h_4h: 0.07209253311157227
MLP_4h_h: 0.06888723373413086
MLP_h_4h: 0.07213306427001953
MLP_4h_h: 0.06927037239074707
MLP_h_4h: 0.07210803031921387
MLP_4h_h: 0.06942391395568848
MLP_h_4h: 0.0726315975189209
MLP_4h_h: 0.06860899925231934
MLP_h_4h: 0.07027983665466309
MLP_4h_h: 0.07310700416564941
MLP_h_4h: 0.07137107849121094
MLP_4h_h: 0.06859636306762695
MLP_h_4h: 0.07029032707214355
MLP_4h_h: 0.06888461112976074
MLP_h_4h: 0.07199954986572266
MLP_4h_h: 0.06810188293457031
MLP_h_4h: 0.0710608959197998
MLP_4h_h: 0.07014870643615723
MLP_h_4h: 0.07213449478149414
MLP_4h_h: 0.06782841682434082
MLP_h_4h: 0.07021808624267578
MLP_4h_h: 0.0684967041015625
MLP_h_4h: 0.07052469253540039
MLP_4h_h: 0.06825780868530273
MLP_h_4h: 0.0694272518157959
MLP_4h_h: 0.06831479072570801
MLP_h_4h: 0.0706789493560791
MLP_4h_h: 0.06852054595947266
MLP_h_4h: 0.07027888298034668
MLP_4h_h: 0.06932926177978516
MLP_h_4h: 0.07218742370605469
MLP_4h_h: 0.06984543800354004
MLP_h_4h: 0.07206487655639648
MLP_4h_h: 0.06904077529907227
MLP_h_4h: 0.07204580307006836
MLP_4h_h: 0.06752824783325195
MLP_h_4h: 0.07027745246887207
MLP_4h_h: 0.06870198249816895
MLP_h_4h: 0.07201981544494629
MLP_4h_h: 0.06804084777832031
MLP_h_4h: 0.07099676132202148
MLP_4h_h: 0.0683438777923584
MLP_h_4h: 0.07106590270996094
MLP_4h_h: 0.07032489776611328
MLP_h_4h: 0.07221579551696777
MLP_4h_h: 0.06796479225158691
MLP_h_4h: 0.06943321228027344
MLP_4h_h: 0.06836628913879395
MLP_h_4h: 0.07052087783813477
MLP_4h_h: 0.06870484352111816
MLP_h_4h: 0.07050681114196777
MLP_4h_h: 0.06926679611206055
MLP_h_4h: 0.07176089286804199
MLP_4h_h: 0.06926298141479492
MLP_h_4h: 0.07008051872253418
MLP_4h_h: 0.06837821006774902
MLP_h_4h: 0.07165980339050293
MLP_4h_h: 0.06909537315368652
MLP_h_4h: 0.07239437103271484
MLP_4h_h: 0.06815433502197266
MLP_h_4h: 0.07102203369140625
MLP_4h_h: 0.06823015213012695
MLP_h_4h: 0.07103991508483887
MLP_4h_h: 0.06819605827331543
MLP_h_4h: 0.07102108001708984
MLP_4h_h: 0.06851339340209961
MLP_h_4h: 0.0710148811340332
MLP_4h_h: 0.0692591667175293
MLP_h_4h: 0.07177424430847168
MLP_4h_h: 0.06917595863342285
MLP_h_4h: 0.07001686096191406
MLP_4h_h: 0.06796383857727051
MLP_h_4h: 0.07028770446777344
MLP_4h_h: 0.06873106956481934
MLP_h_4h: 0.07135319709777832
MLP_4h_h: 0.06817412376403809
MLP_h_4h: 0.0707101821899414
MLP_4h_h: 0.06775856018066406
MLP_h_4h: 0.06942558288574219
MLP_4h_h: 0.06866645812988281
MLP_h_4h: 0.07341599464416504
MLP_4h_h: 0.068603515625
MLP_h_4h: 0.07129859924316406
MLP_4h_h: 0.06821513175964355
MLP_h_4h: 0.07051563262939453
MLP_4h_h: 0.06847715377807617
MLP_h_4h: 0.07050967216491699
MLP_4h_h: 0.0683450698852539
MLP_h_4h: 0.07016897201538086
MLP_4h_h: 0.06846141815185547
MLP_h_4h: 0.07027387619018555
MLP_4h_h: 0.06873273849487305
MLP_h_4h: 0.07140231132507324
MLP_4h_h: 0.06828117370605469
MLP_h_4h: 0.07097411155700684
MLP_4h_h: 0.0709078311920166
MLP_h_4h: 0.0725562572479248
MLP_4h_h: 0.06861472129821777
MLP_h_4h: 0.07094836235046387
MLP_4h_h: 0.07058310508728027
MLP_h_4h: 0.0721886157989502
MLP_4h_h: 0.06829690933227539
MLP_h_4h: 0.07100248336791992
MLP_4h_h: 0.06833553314208984
MLP_h_4h: 0.07104182243347168
MLP_4h_h: 0.06810235977172852
MLP_h_4h: 0.07092666625976562
MLP_4h_h: 0.06850671768188477
MLP_h_4h: 0.0710606575012207
MLP_4h_h: 0.06852197647094727
MLP_h_4h: 0.07027435302734375
MLP_4h_h: 0.06839346885681152
MLP_h_4h: 0.07051753997802734
MLP_4h_h: 0.0686330795288086
MLP_h_4h: 0.07071042060852051
MLP_4h_h: 0.06829357147216797
MLP_h_4h: 0.07094407081604004
MLP_4h_h: 0.0682525634765625
MLP_h_4h: 0.07100391387939453
MLP_4h_h: 0.06823444366455078
MLP_h_4h: 0.07107043266296387
MLP_4h_h: 0.07007932662963867
MLP_h_4h: 0.07243919372558594
MLP_4h_h: 0.06822490692138672
MLP_h_4h: 0.07099485397338867
MLP_4h_h: 0.06788945198059082
MLP_h_4h: 0.06942057609558105
MLP_4h_h: 0.06796860694885254
MLP_h_4h: 0.07045364379882812
MLP_4h_h: 0.07158041000366211
MLP_h_4h: 0.07180404663085938
MLP_4h_h: 0.06841206550598145
MLP_h_4h: 0.07066893577575684
MLP_4h_h: 0.06851577758789062
MLP_h_4h: 0.07029390335083008
MLP_4h_h: 0.06840229034423828
MLP_h_4h: 0.07142996788024902
MLP_4h_h: 0.06830668449401855
MLP_h_4h: 0.07098269462585449
MLP_4h_h: 0.06837320327758789
MLP_h_4h: 0.07172346115112305
MLP_4h_h: 0.07157301902770996
MLP_h_4h: 0.07193303108215332
MLP_4h_h: 0.06843233108520508
MLP_h_4h: 0.07180643081665039
MLP_4h_h: 0.06826066970825195
MLP_h_4h: 0.07105469703674316
MLP_4h_h: 0.0699319839477539
MLP_h_4h: 0.07232356071472168
MLP_4h_h: 0.06871223449707031
MLP_h_4h: 0.07075643539428711
MLP_4h_h: 0.0710458755493164
MLP_h_4h: 0.07222461700439453
MLP_4h_h: 0.06812119483947754
MLP_h_4h: 0.07046699523925781
MLP_4h_h: 0.06850957870483398
MLP_h_4h: 0.07055854797363281
MLP_4h_h: 0.06866335868835449
MLP_h_4h: 0.07053780555725098
MLP_4h_h: 0.06887960433959961
MLP_h_4h: 0.07067990303039551
MLP_4h_h: 0.0686492919921875
MLP_h_4h: 0.07029128074645996
MLP_4h_h: 0.06848382949829102
MLP_h_4h: 0.07097148895263672
MLP_4h_h: 0.06842947006225586
MLP_h_4h: 0.07180070877075195
MLP_4h_h: 0.06823086738586426
MLP_h_4h: 0.07113122940063477
MLP_4h_h: 0.06809043884277344
MLP_h_4h: 0.07085251808166504
MLP_4h_h: 0.07088565826416016
MLP_h_4h: 0.07254815101623535
MLP_4h_h: 0.06870412826538086
MLP_h_4h: 0.07028079032897949
MLP_4h_h: 0.06847023963928223
MLP_h_4h: 0.07049155235290527
MLP_4h_h: 0.06929659843444824
MLP_h_4h: 0.07170534133911133
MLP_4h_h: 0.0692589282989502
MLP_h_4h: 0.07003521919250488
MLP_4h_h: 0.06819725036621094
MLP_h_4h: 0.07097816467285156
MLP_4h_h: 0.06989312171936035
MLP_h_4h: 0.07068943977355957
MLP_4h_h: 0.06835103034973145
MLP_h_4h: 0.07145524024963379
MLP_4h_h: 0.06828856468200684
MLP_h_4h: 0.07101750373840332
MLP_4h_h: 0.0695502758026123
MLP_h_4h: 0.07222843170166016
MLP_4h_h: 0.06859612464904785
MLP_h_4h: 0.07180619239807129
MLP_4h_h: 0.06824779510498047
MLP_h_4h: 0.07096672058105469
MLP_4h_h: 0.06880688667297363
MLP_h_4h: 0.07128143310546875
MLP_4h_h: 0.06862497329711914
MLP_h_4h: 0.0710608959197998
MLP_4h_h: 0.06860566139221191
MLP_h_4h: 0.07033085823059082
MLP_4h_h: 0.06832337379455566
MLP_h_4h: 0.070526123046875
MLP_4h_h: 0.07450175285339355
MLP_h_4h: 0.0703284740447998
MLP_4h_h: 0.0687553882598877
MLP_h_4h: 0.07027769088745117
MLP_4h_h: 0.0682826042175293
MLP_h_4h: 0.0702810287475586
MLP_4h_h: 0.06803202629089355
MLP_h_4h: 0.07027959823608398
MLP_4h_h: 0.06868195533752441
MLP_h_4h: 0.07224535942077637
MLP_4h_h: 0.06824088096618652
MLP_h_4h: 0.07102131843566895
MLP_4h_h: 0.07007002830505371
MLP_h_4h: 0.07224059104919434
MLP_4h_h: 0.06879520416259766
MLP_h_4h: 0.07127547264099121
MLP_4h_h: 0.06875443458557129
MLP_h_4h: 0.07188677787780762
MLP_4h_h: 0.06813740730285645
MLP_h_4h: 0.07045602798461914
MLP_4h_h: 0.06839346885681152
MLP_h_4h: 0.07056021690368652
MLP_4h_h: 0.06867027282714844
MLP_h_4h: 0.07028436660766602
MLP_4h_h: 0.0687863826751709
MLP_h_4h: 0.07067275047302246
MLP_4h_h: 0.06879043579101562
MLP_h_4h: 0.07201290130615234
MLP_4h_h: 0.06883955001831055
MLP_h_4h: 0.07029938697814941
MLP_4h_h: 0.06887936592102051
MLP_h_4h: 0.07245492935180664
MLP_4h_h: 0.0681300163269043
MLP_h_4h: 0.07046627998352051
MLP_4h_h: 0.06862068176269531
MLP_h_4h: 0.07179474830627441
MLP_4h_h: 0.06779718399047852
MLP_h_4h: 0.06943154335021973
MLP_4h_h: 0.06822991371154785
MLP_h_4h: 0.07051730155944824
MLP_4h_h: 0.06857585906982422
MLP_h_4h: 0.07052373886108398
MLP_4h_h: 0.06900691986083984
MLP_h_4h: 0.07068037986755371
MLP_4h_h: 0.06853747367858887
MLP_h_4h: 0.07028675079345703
MLP_4h_h: 0.06857538223266602
MLP_h_4h: 0.07168769836425781
MLP_4h_h: 0.06834268569946289
MLP_h_4h: 0.07164692878723145
MLP_4h_h: 0.06817126274108887
MLP_h_4h: 0.07176923751831055
MLP_4h_h: 0.06836247444152832
MLP_h_4h: 0.07101821899414062
MLP_4h_h: 0.06829977035522461
MLP_h_4h: 0.07103705406188965
MLP_4h_h: 0.0682675838470459
MLP_h_4h: 0.0702657699584961
MLP_4h_h: 0.06812286376953125
MLP_h_4h: 0.07010555267333984
MLP_4h_h: 0.0685112476348877
MLP_h_4h: 0.07072186470031738
MLP_4h_h: 0.06836581230163574
MLP_h_4h: 0.07095146179199219
MLP_4h_h: 0.06806325912475586
MLP_h_4h: 0.07073044776916504
MLP_4h_h: 0.06848716735839844
MLP_h_4h: 0.07179570198059082
MLP_4h_h: 0.06818413734436035
MLP_h_4h: 0.07105731964111328
MLP_4h_h: 0.06832551956176758
MLP_h_4h: 0.07051420211791992
MLP_4h_h: 0.06876873970031738
MLP duration (in seconds): 0.1395
MLP throughput (in TFLOP/s): 252.273
LN1: 0.0008985996246337891
QKV Transform: 0.051587581634521484
Flash: 0.014302492141723633
Attention linproj: 0.016538619995117188
Post-attention Dropout: 0.04186058044433594
Post-attention residual: 0.0006575584411621094
LN2: 0.0006897449493408203
MLP_h_4h: 0.06825518608093262
MLP_4h_h: 0.06908631324768066
Post-MLP residual: 0.003466367721557617
Attention layer time: 0.26836609840393066
LN1: 0.0007171630859375
QKV Transform: 0.05159473419189453
Flash: 0.016736268997192383
Attention linproj: 0.01636528968811035
Post-attention Dropout: 0.0018148422241210938
Post-attention residual: 0.0006079673767089844
LN2: 0.0006756782531738281
MLP_h_4h: 0.07060813903808594
MLP_4h_h: 0.06989479064941406
Post-MLP residual: 0.0018453598022460938
Attention layer time: 0.2317202091217041
LN1: 0.0007145404815673828
QKV Transform: 0.05150461196899414
Flash: 0.01753544807434082
Attention linproj: 0.016402721405029297
Post-attention Dropout: 0.00186920166015625
Post-attention residual: 0.0006234645843505859
LN2: 0.0007066726684570312
MLP_h_4h: 0.07079672813415527
MLP_4h_h: 0.06874299049377441
Post-MLP residual: 0.0018510818481445312
Attention layer time: 0.23161554336547852
LN1: 0.000713348388671875
QKV Transform: 0.051482200622558594
Flash: 0.017618179321289062
Attention linproj: 0.01636338233947754
Post-attention Dropout: 0.0018486976623535156
Post-attention residual: 0.0006198883056640625
LN2: 0.0006954669952392578
MLP_h_4h: 0.07185626029968262
MLP_4h_h: 0.06906342506408691
Post-MLP residual: 0.0018470287322998047
Attention layer time: 0.23298168182373047
LN1: 0.0007205009460449219
QKV Transform: 0.05250716209411621
Flash: 0.017354488372802734
Attention linproj: 0.016510486602783203
Post-attention Dropout: 0.0018448829650878906
Post-attention residual: 0.0006227493286132812
LN2: 0.0006921291351318359
MLP_h_4h: 0.07216525077819824
MLP_4h_h: 0.06975722312927246
Post-MLP residual: 0.0018398761749267578
Attention layer time: 0.23488759994506836
LN1: 0.0007131099700927734
QKV Transform: 0.05178022384643555
Flash: 0.017436981201171875
Attention linproj: 0.0167849063873291
Post-attention Dropout: 0.0018532276153564453
Post-attention residual: 0.0006213188171386719
LN2: 0.0006947517395019531
MLP_h_4h: 0.07131767272949219
MLP_4h_h: 0.06919717788696289
Post-MLP residual: 0.0018329620361328125
Attention layer time: 0.2331221103668213
LN1: 0.000713348388671875
QKV Transform: 0.05246734619140625
Flash: 0.017369985580444336
Attention linproj: 0.016731739044189453
Post-attention Dropout: 0.0018393993377685547
Post-attention residual: 0.0006234645843505859
LN2: 0.0006918907165527344
MLP_h_4h: 0.07131528854370117
MLP_4h_h: 0.06877851486206055
Post-MLP residual: 0.0018453598022460938
Attention layer time: 0.23325657844543457
LN1: 0.0007305145263671875
QKV Transform: 0.05236530303955078
Flash: 0.017464399337768555
Attention linproj: 0.016624927520751953
Post-attention Dropout: 0.0018630027770996094
Post-attention residual: 0.0006206035614013672
LN2: 0.0006921291351318359
MLP_h_4h: 0.07148981094360352
MLP_4h_h: 0.06926679611206055
Post-MLP residual: 0.0018625259399414062
Attention layer time: 0.2338416576385498
LN1: 0.0007107257843017578
QKV Transform: 0.05102133750915527
Flash: 0.017930269241333008
Attention linproj: 0.016574859619140625
Post-attention Dropout: 0.0018393993377685547
Post-attention residual: 0.0006241798400878906
LN2: 0.0006923675537109375
MLP_h_4h: 0.07211470603942871
MLP_4h_h: 0.06939530372619629
Post-MLP residual: 0.0018427371978759766
Attention layer time: 0.23360395431518555
LN1: 0.0007076263427734375
QKV Transform: 0.05202794075012207
Flash: 0.016969680786132812
Attention linproj: 0.016448259353637695
Post-attention Dropout: 0.0018608570098876953
Post-attention residual: 0.0006213188171386719
LN2: 0.00069427490234375
MLP_h_4h: 0.07175946235656738
MLP_4h_h: 0.06984734535217285
Post-MLP residual: 0.0018420219421386719
Attention layer time: 0.2336595058441162
LN1: 0.0007126331329345703
QKV Transform: 0.0509335994720459
Flash: 0.017038345336914062
Attention linproj: 0.01636481285095215
Post-attention Dropout: 0.0018553733825683594
Post-attention residual: 0.0006239414215087891
LN2: 0.0006940364837646484
MLP_h_4h: 0.07160377502441406
MLP_4h_h: 0.0687718391418457
Post-MLP residual: 0.001837015151977539
Attention layer time: 0.23129701614379883
LN1: 0.0007128715515136719
QKV Transform: 0.05143332481384277
Flash: 0.01766490936279297
Attention linproj: 0.016376256942749023
Post-attention Dropout: 0.0018649101257324219
Post-attention residual: 0.0006220340728759766
LN2: 0.0006949901580810547
MLP_h_4h: 0.07218027114868164
MLP_4h_h: 0.06896281242370605
Post-MLP residual: 0.001842498779296875
Attention layer time: 0.23320460319519043
LN1: 0.0007154941558837891
QKV Transform: 0.05246686935424805
Flash: 0.018407344818115234
Attention linproj: 0.016381263732910156
Post-attention Dropout: 0.0018534660339355469
Post-attention residual: 0.000621795654296875
LN2: 0.0006911754608154297
MLP_h_4h: 0.07226085662841797
MLP_4h_h: 0.06926369667053223
Post-MLP residual: 0.0018436908721923828
Attention layer time: 0.2353661060333252
LN1: 0.0007123947143554688
QKV Transform: 0.05194497108459473
Flash: 0.01722884178161621
Attention linproj: 0.016517162322998047
Post-attention Dropout: 0.0018651485443115234
Post-attention residual: 0.0006191730499267578
LN2: 0.0006933212280273438
MLP_h_4h: 0.07200789451599121
MLP_4h_h: 0.06900143623352051
Post-MLP residual: 0.0018432140350341797
Attention layer time: 0.23331379890441895
LN1: 0.0007145404815673828
QKV Transform: 0.05209708213806152
Flash: 0.017719268798828125
Attention linproj: 0.016524314880371094
Post-attention Dropout: 0.0018506050109863281
Post-attention residual: 0.0006248950958251953
LN2: 0.00069427490234375
MLP_h_4h: 0.07206869125366211
MLP_4h_h: 0.06912922859191895
Post-MLP residual: 0.0018298625946044922
Attention layer time: 0.23412704467773438
LN1: 0.0007271766662597656
QKV Transform: 0.05269742012023926
Flash: 0.01709294319152832
Attention linproj: 0.01681971549987793
Post-attention Dropout: 0.0018458366394042969
Post-attention residual: 0.0006248950958251953
LN2: 0.0006916522979736328
MLP_h_4h: 0.07176709175109863
MLP_4h_h: 0.0691826343536377
Post-MLP residual: 0.001850128173828125
Attention layer time: 0.23418092727661133
LN1: 0.0007154941558837891
QKV Transform: 0.051577091217041016
Flash: 0.01871967315673828
Attention linproj: 0.016614198684692383
Post-attention Dropout: 0.001870870590209961
Post-attention residual: 0.0006220340728759766
LN2: 0.0006926059722900391
MLP_h_4h: 0.07199954986572266
MLP_4h_h: 0.0691070556640625
Post-MLP residual: 0.0018367767333984375
Attention layer time: 0.23462891578674316
LN1: 0.0007145404815673828
QKV Transform: 0.052269697189331055
Flash: 0.017247438430786133
Attention linproj: 0.0168609619140625
Post-attention Dropout: 0.0018482208251953125
Post-attention residual: 0.0006198883056640625
LN2: 0.0006966590881347656
MLP_h_4h: 0.0715632438659668
MLP_4h_h: 0.06942629814147949
Post-MLP residual: 0.0018491744995117188
Attention layer time: 0.23399782180786133
LN1: 0.0007143020629882812
QKV Transform: 0.05167794227600098
Flash: 0.017567873001098633
Attention linproj: 0.01668548583984375
Post-attention Dropout: 0.0018427371978759766
Post-attention residual: 0.0006229877471923828
LN2: 0.0006902217864990234
MLP_h_4h: 0.07169914245605469
MLP_4h_h: 0.06928801536560059
Post-MLP residual: 0.0018439292907714844
Attention layer time: 0.2335205078125
LN1: 0.0007116794586181641
QKV Transform: 0.0514073371887207
Flash: 0.017690181732177734
Attention linproj: 0.016723155975341797
Post-attention Dropout: 0.0018644332885742188
Post-attention residual: 0.0006382465362548828
LN2: 0.0006940364837646484
MLP_h_4h: 0.07148146629333496
MLP_4h_h: 0.06926441192626953
Post-MLP residual: 0.001842498779296875
Attention layer time: 0.2331855297088623
LN1: 0.0007078647613525391
QKV Transform: 0.05111837387084961
Flash: 0.016822099685668945
Attention linproj: 0.016449451446533203
Post-attention Dropout: 0.0018491744995117188
Post-attention residual: 0.000621795654296875
LN2: 0.0006928443908691406
MLP_h_4h: 0.07224559783935547
MLP_4h_h: 0.07017827033996582
Post-MLP residual: 0.001848459243774414
Attention layer time: 0.23342275619506836
LN1: 0.0007140636444091797
QKV Transform: 0.05094742774963379
Flash: 0.016963958740234375
Attention linproj: 0.01646709442138672
Post-attention Dropout: 0.0018453598022460938
Post-attention residual: 0.0006208419799804688
LN2: 0.0006906986236572266
MLP_h_4h: 0.07183575630187988
MLP_4h_h: 0.06906366348266602
Post-MLP residual: 0.0018448829650878906
Attention layer time: 0.23186421394348145
LN1: 0.0007112026214599609
QKV Transform: 0.05162334442138672
Flash: 0.017486095428466797
Attention linproj: 0.016470670700073242
Post-attention Dropout: 0.0018460750579833984
Post-attention residual: 0.0006186962127685547
LN2: 0.0006935596466064453
MLP_h_4h: 0.07207083702087402
MLP_4h_h: 0.06895589828491211
Post-MLP residual: 0.0018475055694580078
Attention layer time: 0.2331836223602295
LN1: 0.0007145404815673828
QKV Transform: 0.05225062370300293
Flash: 0.01764965057373047
Attention linproj: 0.016364574432373047
Post-attention Dropout: 0.0018415451049804688
Post-attention residual: 0.0010612010955810547
LN2: 0.0008647441864013672
MLP_h_4h: 0.07120084762573242
MLP_4h_h: 0.0688638687133789
Post-MLP residual: 0.0019059181213378906
Attention layer time: 0.23369526863098145
LN1: 0.0007233619689941406
QKV Transform: 0.05141139030456543
Flash: 0.018485307693481445
Attention linproj: 0.016344547271728516
Post-attention Dropout: 0.0018544197082519531
Post-attention residual: 0.0006258487701416016
LN2: 0.0006921291351318359
MLP_h_4h: 0.07219934463500977
MLP_4h_h: 0.06903886795043945
Post-MLP residual: 0.001844644546508789
Attention layer time: 0.23416948318481445
LN1: 0.0007154941558837891
QKV Transform: 0.05147743225097656
Flash: 0.01794123649597168
Attention linproj: 0.016411304473876953
Post-attention Dropout: 0.001855611801147461
Post-attention residual: 0.0006260871887207031
LN2: 0.00069427490234375
MLP_h_4h: 0.07190680503845215
MLP_4h_h: 0.06930875778198242
Post-MLP residual: 0.0018532276153564453
Attention layer time: 0.23365497589111328
LN1: 0.0007138252258300781
QKV Transform: 0.05232572555541992
Flash: 0.01753997802734375
Attention linproj: 0.016660213470458984
Post-attention Dropout: 0.0018434524536132812
Post-attention residual: 0.0006232261657714844
LN2: 0.0006911754608154297
MLP_h_4h: 0.07201242446899414
MLP_4h_h: 0.06925201416015625
Post-MLP residual: 0.0018434524536132812
Attention layer time: 0.23437952995300293
LN1: 0.0007150173187255859
QKV Transform: 0.052374839782714844
Flash: 0.017279624938964844
Attention linproj: 0.016759157180786133
Post-attention Dropout: 0.001840353012084961
Post-attention residual: 0.000621795654296875
LN2: 0.000698089599609375
MLP_h_4h: 0.07216167449951172
MLP_4h_h: 0.06927990913391113
Post-MLP residual: 0.0018434524536132812
Attention layer time: 0.23446297645568848
LN1: 0.0007112026214599609
QKV Transform: 0.051743507385253906
Flash: 0.01745462417602539
Attention linproj: 0.016899824142456055
Post-attention Dropout: 0.001863241195678711
Post-attention residual: 0.0006239414215087891
LN2: 0.0006926059722900391
MLP_h_4h: 0.07173943519592285
MLP_4h_h: 0.06939935684204102
Post-MLP residual: 0.0018279552459716797
Attention layer time: 0.23384380340576172
LN1: 0.0007126331329345703
QKV Transform: 0.05113935470581055
Flash: 0.017843961715698242
Attention linproj: 0.016368389129638672
Post-attention Dropout: 0.0018498897552490234
Post-attention residual: 0.0006246566772460938
LN2: 0.0006909370422363281
MLP_h_4h: 0.07239747047424316
MLP_4h_h: 0.06972122192382812
Post-MLP residual: 0.001848459243774414
Attention layer time: 0.23404526710510254
LN1: 0.0007073879241943359
QKV Transform: 0.05110311508178711
Flash: 0.017790555953979492
Attention linproj: 0.016475439071655273
Post-attention Dropout: 0.001842498779296875
Post-attention residual: 0.0006237030029296875
LN2: 0.0006959438323974609
MLP_h_4h: 0.07452535629272461
MLP_4h_h: 0.06928634643554688
Post-MLP residual: 0.0018436908721923828
Attention layer time: 0.23574614524841309
LN1: 0.0007312297821044922
QKV Transform: 0.05218672752380371
Flash: 0.017813444137573242
Attention linproj: 0.01658797264099121
Post-attention Dropout: 0.0018434524536132812
Post-attention residual: 0.0006213188171386719
LN2: 0.0006911754608154297
MLP_h_4h: 0.07192564010620117
MLP_4h_h: 0.06920146942138672
Post-MLP residual: 0.001850128173828125
Attention layer time: 0.2343130111694336
LN1: 0.0007128715515136719
QKV Transform: 0.052034616470336914
Flash: 0.017766237258911133
Attention linproj: 0.016387462615966797
Post-attention Dropout: 0.0018374919891357422
Post-attention residual: 0.0006346702575683594
LN2: 0.0006940364837646484
MLP_h_4h: 0.07236623764038086
MLP_4h_h: 0.0688943862915039
Post-MLP residual: 0.0018398761749267578
Attention layer time: 0.23401856422424316
LN1: 0.0007140636444091797
QKV Transform: 0.05138587951660156
Flash: 0.017641782760620117
Attention linproj: 0.016347885131835938
Post-attention Dropout: 0.001844644546508789
Post-attention residual: 0.0006237030029296875
LN2: 0.0006957054138183594
MLP_h_4h: 0.07194375991821289
MLP_4h_h: 0.06895232200622559
Post-MLP residual: 0.0018563270568847656
Attention layer time: 0.23285245895385742
LN1: 0.0007123947143554688
QKV Transform: 0.051837921142578125
Flash: 0.017250776290893555
Attention linproj: 0.016480445861816406
Post-attention Dropout: 0.0018510818481445312
Post-attention residual: 0.0006222724914550781
LN2: 0.0006947517395019531
MLP_h_4h: 0.07216405868530273
MLP_4h_h: 0.06863951683044434
Post-MLP residual: 0.0018315315246582031
Attention layer time: 0.23295092582702637
LN1: 0.0007159709930419922
QKV Transform: 0.051033735275268555
Flash: 0.019165515899658203
Attention linproj: 0.0163724422454834
Post-attention Dropout: 0.0018858909606933594
Post-attention residual: 0.0006251335144042969
LN2: 0.0006997585296630859
MLP_h_4h: 0.07215309143066406
MLP_4h_h: 0.06920409202575684
Post-MLP residual: 0.001847982406616211
Attention layer time: 0.23456954956054688
LN1: 0.0007164478302001953
QKV Transform: 0.05213284492492676
Flash: 0.017188310623168945
Attention linproj: 0.016462326049804688
Post-attention Dropout: 0.0018510818481445312
Post-attention residual: 0.0006203651428222656
LN2: 0.0006947517395019531
MLP_h_4h: 0.07225871086120605
MLP_4h_h: 0.06918883323669434
Post-MLP residual: 0.0018384456634521484
Attention layer time: 0.23384523391723633
LN1: 0.0007174015045166016
QKV Transform: 0.05268573760986328
Flash: 0.017999649047851562
Attention linproj: 0.01636338233947754
Post-attention Dropout: 0.0018439292907714844
Post-attention residual: 0.000621795654296875
LN2: 0.0007159709930419922
MLP_h_4h: 0.0722036361694336
MLP_4h_h: 0.06916522979736328
Post-MLP residual: 0.0018398761749267578
Attention layer time: 0.23502492904663086
LN1: 0.0007145404815673828
QKV Transform: 0.05199122428894043
Flash: 0.017841100692749023
Attention linproj: 0.01643657684326172
Post-attention Dropout: 0.0018551349639892578
Post-attention residual: 0.0006227493286132812
LN2: 0.0006928443908691406
MLP_h_4h: 0.07217669486999512
MLP_4h_h: 0.06928038597106934
Post-MLP residual: 0.0018496513366699219
Attention layer time: 0.23433208465576172
LN1: 0.0007150173187255859
QKV Transform: 0.05205059051513672
Flash: 0.01773667335510254
Attention linproj: 0.016632795333862305
Post-attention Dropout: 0.001836538314819336
Post-attention residual: 0.0006229877471923828
LN2: 0.0006914138793945312
MLP_h_4h: 0.07186746597290039
MLP_4h_h: 0.06903338432312012
Post-MLP residual: 0.0018432140350341797
Attention layer time: 0.23389554023742676
LN1: 0.0007128715515136719
QKV Transform: 0.051544189453125
Flash: 0.017470598220825195
Attention linproj: 0.01675248146057129
Post-attention Dropout: 0.001840829849243164
Post-attention residual: 0.0006208419799804688
LN2: 0.0006992816925048828
MLP_h_4h: 0.07186245918273926
MLP_4h_h: 0.06938576698303223
Post-MLP residual: 0.0018353462219238281
Attention layer time: 0.2335987091064453
LN1: 0.0007145404815673828
QKV Transform: 0.051614999771118164
Flash: 0.01851487159729004
Attention linproj: 0.01672220230102539
Post-attention Dropout: 0.0018541812896728516
Post-attention residual: 0.0006213188171386719
LN2: 0.0006911754608154297
MLP_h_4h: 0.07226777076721191
MLP_4h_h: 0.06994318962097168
Post-MLP residual: 0.001847982406616211
Attention layer time: 0.2357006072998047
LN1: 0.0007119178771972656
QKV Transform: 0.052289485931396484
Flash: 0.017450332641601562
Attention linproj: 0.01673269271850586
Post-attention Dropout: 0.0018472671508789062
Post-attention residual: 0.0006220340728759766
LN2: 0.0006918907165527344
MLP_h_4h: 0.07200241088867188
MLP_4h_h: 0.06934952735900879
Post-MLP residual: 0.001837015151977539
Attention layer time: 0.23441362380981445
LN1: 0.0007138252258300781
QKV Transform: 0.05121731758117676
Flash: 0.017714738845825195
Attention linproj: 0.016440153121948242
Post-attention Dropout: 0.001840353012084961
Post-attention residual: 0.0006253719329833984
LN2: 0.0006949901580810547
MLP_h_4h: 0.07198357582092285
MLP_4h_h: 0.06927084922790527
Post-MLP residual: 0.0018486976623535156
Attention layer time: 0.23321008682250977
LN1: 0.0007123947143554688
QKV Transform: 0.0508427619934082
Flash: 0.01699995994567871
Attention linproj: 0.016469955444335938
Post-attention Dropout: 0.0018455982208251953
Post-attention residual: 0.0006208419799804688
LN2: 0.0006928443908691406
MLP_h_4h: 0.07260680198669434
MLP_4h_h: 0.06984233856201172
Post-MLP residual: 0.001844167709350586
Attention layer time: 0.23333144187927246
LN1: 0.0007109642028808594
QKV Transform: 0.05128645896911621
Flash: 0.017660140991210938
Attention linproj: 0.016361236572265625
Post-attention Dropout: 0.0018420219421386719
Post-attention residual: 0.0006234645843505859
LN2: 0.0006945133209228516
MLP_h_4h: 0.07239079475402832
MLP_4h_h: 0.068817138671875
Post-MLP residual: 0.001859903335571289
Attention layer time: 0.23311352729797363
LN1: 0.0007109642028808594
QKV Transform: 0.05152249336242676
Flash: 0.017552852630615234
Attention linproj: 0.01639866828918457
Post-attention Dropout: 0.0018439292907714844
Post-attention residual: 0.0006234645843505859
LN2: 0.0006921291351318359
MLP_h_4h: 0.0722348690032959
MLP_4h_h: 0.06906247138977051
Post-MLP residual: 0.0018489360809326172
Attention layer time: 0.2333383560180664
LN1: 0.0007154941558837891
QKV Transform: 0.05249190330505371
Flash: 0.017368078231811523
Attention linproj: 0.0164029598236084
Post-attention Dropout: 0.0018510818481445312
Post-attention residual: 0.0006220340728759766
LN2: 0.0007026195526123047
MLP_h_4h: 0.0720527172088623
MLP_4h_h: 0.06919312477111816
Post-MLP residual: 0.0018610954284667969
Attention layer time: 0.23412251472473145
LN1: 0.0007154941558837891
QKV Transform: 0.05199718475341797
Flash: 0.017223596572875977
Attention linproj: 0.01650238037109375
Post-attention Dropout: 0.001852273941040039
Post-attention residual: 0.0006222724914550781
LN2: 0.0006949901580810547
MLP_h_4h: 0.07214665412902832
MLP_4h_h: 0.06891369819641113
Post-MLP residual: 0.0018463134765625
Attention layer time: 0.23337912559509277
LN1: 0.0007138252258300781
QKV Transform: 0.05154132843017578
Flash: 0.017531156539916992
Attention linproj: 0.016467809677124023
Post-attention Dropout: 0.0018470287322998047
Post-attention residual: 0.0006241798400878906
LN2: 0.0006978511810302734
MLP_h_4h: 0.07224154472351074
MLP_4h_h: 0.06895756721496582
Post-MLP residual: 0.0018448829650878906
Attention layer time: 0.23334360122680664
LN1: 0.0007128715515136719
QKV Transform: 0.051054954528808594
Flash: 0.019046783447265625
Attention linproj: 0.01659870147705078
Post-attention Dropout: 0.0018429756164550781
Post-attention residual: 0.0006265640258789062
LN2: 0.000690460205078125
MLP_h_4h: 0.07438874244689941
MLP_4h_h: 0.06920528411865234
Post-MLP residual: 0.0018413066864013672
Attention layer time: 0.23688721656799316
LN1: 0.0007174015045166016
QKV Transform: 0.0516810417175293
Flash: 0.017351388931274414
Attention linproj: 0.016501188278198242
Post-attention Dropout: 0.0018613338470458984
Post-attention residual: 0.0006237030029296875
LN2: 0.0006914138793945312
MLP_h_4h: 0.07219505310058594
MLP_4h_h: 0.06902647018432617
Post-MLP residual: 0.0018420219421386719
Attention layer time: 0.23336529731750488
LN1: 0.0007123947143554688
QKV Transform: 0.05270838737487793
Flash: 0.017251968383789062
Attention linproj: 0.016698122024536133
Post-attention Dropout: 0.0018701553344726562
Post-attention residual: 0.0006206035614013672
LN2: 0.0006937980651855469
MLP_h_4h: 0.07205033302307129
MLP_4h_h: 0.06935358047485352
Post-MLP residual: 0.001840829849243164
Attention layer time: 0.23468255996704102
LN1: 0.0007157325744628906
QKV Transform: 0.05176377296447754
Flash: 0.017211198806762695
Attention linproj: 0.01661539077758789
Post-attention Dropout: 0.0018506050109863281
Post-attention residual: 0.0006203651428222656
LN2: 0.0006906986236572266
MLP_h_4h: 0.07222509384155273
MLP_4h_h: 0.06968426704406738
Post-MLP residual: 0.0018405914306640625
Attention layer time: 0.23409414291381836
LN1: 0.000713348388671875
QKV Transform: 0.052800655364990234
Flash: 0.01714777946472168
Attention linproj: 0.016528606414794922
Post-attention Dropout: 0.0018563270568847656
Post-attention residual: 0.0006237030029296875
LN2: 0.0006937980651855469
MLP_h_4h: 0.0721578598022461
MLP_4h_h: 0.06915712356567383
Post-MLP residual: 0.0018417835235595703
Attention layer time: 0.2344050407409668
LN1: 0.0007185935974121094
QKV Transform: 0.05134916305541992
Flash: 0.01798415184020996
Attention linproj: 0.016541242599487305
Post-attention Dropout: 0.0018467903137207031
Post-attention residual: 0.0006184577941894531
LN2: 0.0006914138793945312
MLP_h_4h: 0.07203006744384766
MLP_4h_h: 0.06909656524658203
Post-MLP residual: 0.0018415451049804688
Attention layer time: 0.23359107971191406
LN1: 0.0007147789001464844
QKV Transform: 0.05267047882080078
Flash: 0.017359495162963867
Attention linproj: 0.01648116111755371
Post-attention Dropout: 0.0018472671508789062
Post-attention residual: 0.0006229877471923828
LN2: 0.0006918907165527344
MLP_h_4h: 0.07239103317260742
MLP_4h_h: 0.06975436210632324
Post-MLP residual: 0.0018432140350341797
Attention layer time: 0.23525571823120117
LN1: 0.0007121562957763672
QKV Transform: 0.05167722702026367
Flash: 0.01842331886291504
Attention linproj: 0.01644611358642578
Post-attention Dropout: 0.001844644546508789
Post-attention residual: 0.0006222724914550781
LN2: 0.0006918907165527344
MLP_h_4h: 0.07223224639892578
MLP_4h_h: 0.06903648376464844
Post-MLP residual: 0.001844167709350586
Attention layer time: 0.234405517578125
LN1: 0.0007157325744628906
QKV Transform: 0.05205059051513672
Flash: 0.01829051971435547
Attention linproj: 0.016536474227905273
Post-attention Dropout: 0.0018565654754638672
Post-attention residual: 0.0006229877471923828
LN2: 0.0006918907165527344
MLP_h_4h: 0.07211017608642578
MLP_4h_h: 0.06937146186828613
Post-MLP residual: 0.0018534660339355469
Attention layer time: 0.23500943183898926
LN1: 0.0007197856903076172
QKV Transform: 0.052004337310791016
Flash: 0.017198562622070312
Attention linproj: 0.016491174697875977
Post-attention Dropout: 0.0018515586853027344
Post-attention residual: 0.0006196498870849609
LN2: 0.0006918907165527344
MLP_h_4h: 0.0717477798461914
MLP_4h_h: 0.068634033203125
Post-MLP residual: 0.0018529891967773438
Attention layer time: 0.23269248008728027
LN1: 0.0007128715515136719
QKV Transform: 0.05194401741027832
Flash: 0.01841115951538086
Attention linproj: 0.016598939895629883
Post-attention Dropout: 0.0018496513366699219
Post-attention residual: 0.0006194114685058594
LN2: 0.0006954669952392578
MLP_h_4h: 0.07176065444946289
MLP_4h_h: 0.06932449340820312
Post-MLP residual: 0.0018417835235595703
Attention layer time: 0.234635591506958
LN1: 0.0007171630859375
QKV Transform: 0.052385568618774414
Flash: 0.017396926879882812
Attention linproj: 0.01654195785522461
Post-attention Dropout: 0.001861572265625
Post-attention residual: 0.0006225109100341797
LN2: 0.0006921291351318359
MLP_h_4h: 0.07211565971374512
MLP_4h_h: 0.06921958923339844
Post-MLP residual: 0.0018498897552490234
Attention layer time: 0.23428964614868164
LN1: 0.0007135868072509766
QKV Transform: 0.05196094512939453
Flash: 0.017493247985839844
Attention linproj: 0.016754150390625
Post-attention Dropout: 0.0018434524536132812
Post-attention residual: 0.0006227493286132812
LN2: 0.0006926059722900391
MLP_h_4h: 0.07217884063720703
MLP_4h_h: 0.06926274299621582
Post-MLP residual: 0.0018374919891357422
Attention layer time: 0.2342529296875
LN1: 0.000728607177734375
QKV Transform: 0.05217266082763672
Flash: 0.018117427825927734
Attention linproj: 0.016814708709716797
Post-attention Dropout: 0.001847982406616211
Post-attention residual: 0.0006222724914550781
LN2: 0.0006933212280273438
MLP_h_4h: 0.07170557975769043
MLP_4h_h: 0.06932497024536133
Post-MLP residual: 0.001848459243774414
Attention layer time: 0.2347850799560547
LN1: 0.0007140636444091797
QKV Transform: 0.05204606056213379
Flash: 0.01714920997619629
Attention linproj: 0.016861915588378906
Post-attention Dropout: 0.0018558502197265625
Post-attention residual: 0.0006210803985595703
LN2: 0.0006921291351318359
MLP_h_4h: 0.07160115242004395
MLP_4h_h: 0.06914687156677246
Post-MLP residual: 0.0018413066864013672
Attention layer time: 0.23341155052185059
LN1: 0.000713348388671875
QKV Transform: 0.051448822021484375
Flash: 0.01753067970275879
Attention linproj: 0.016653060913085938
Post-attention Dropout: 0.0018436908721923828
Post-attention residual: 0.0006229877471923828
LN2: 0.0006926059722900391
MLP_h_4h: 0.07193541526794434
MLP_4h_h: 0.06916284561157227
Post-MLP residual: 0.001848459243774414
Attention layer time: 0.23331999778747559
LN1: 0.0007083415985107422
QKV Transform: 0.05115151405334473
Flash: 0.017763614654541016
Attention linproj: 0.016451358795166016
Post-attention Dropout: 0.0018641948699951172
Post-attention residual: 0.0006227493286132812
LN2: 0.0006916522979736328
MLP_h_4h: 0.07225251197814941
MLP_4h_h: 0.0694737434387207
Post-MLP residual: 0.0018432140350341797
Attention layer time: 0.23367953300476074
LN1: 0.0007114410400390625
QKV Transform: 0.05097675323486328
Flash: 0.016990184783935547
Attention linproj: 0.016371488571166992
Post-attention Dropout: 0.0018498897552490234
Post-attention residual: 0.0006210803985595703
LN2: 0.0006926059722900391
MLP_h_4h: 0.07200098037719727
MLP_4h_h: 0.0688772201538086
Post-MLP residual: 0.0018503665924072266
Attention layer time: 0.23178911209106445
LN1: 0.0007114410400390625
QKV Transform: 0.051612138748168945
Flash: 0.01845526695251465
Attention linproj: 0.01636528968811035
Post-attention Dropout: 0.0018396377563476562
Post-attention residual: 0.0006210803985595703
LN2: 0.0006928443908691406
MLP_h_4h: 0.07230949401855469
MLP_4h_h: 0.06915855407714844
Post-MLP residual: 0.0018458366394042969
Attention layer time: 0.23446202278137207
LN1: 0.0007154941558837891
QKV Transform: 0.052724599838256836
Flash: 0.01719212532043457
Attention linproj: 0.016476154327392578
Post-attention Dropout: 0.001852273941040039
Post-attention residual: 0.0006203651428222656
LN2: 0.0006945133209228516
MLP_h_4h: 0.07247138023376465
MLP_4h_h: 0.06932878494262695
Post-MLP residual: 0.0018758773803710938
Attention layer time: 0.23480820655822754
LN1: 0.0007236003875732422
QKV Transform: 0.052489280700683594
Flash: 0.017312288284301758
Attention linproj: 0.01639080047607422
Post-attention Dropout: 0.0018496513366699219
Post-attention residual: 0.000621795654296875
LN2: 0.0006966590881347656
MLP_h_4h: 0.07244157791137695
MLP_4h_h: 0.06918740272521973
Post-MLP residual: 0.0018601417541503906
Attention layer time: 0.23444867134094238
LN1: 0.00072479248046875
QKV Transform: 0.05258965492248535
Flash: 0.017424821853637695
Attention linproj: 0.0163726806640625
Post-attention Dropout: 0.0018551349639892578
Post-attention residual: 0.0006220340728759766
LN2: 0.0006973743438720703
MLP_h_4h: 0.07238221168518066
MLP_4h_h: 0.06901907920837402
Post-MLP residual: 0.0018548965454101562
Attention layer time: 0.23439693450927734
LN1: 0.000713348388671875
QKV Transform: 0.05218982696533203
Flash: 0.01714468002319336
Attention linproj: 0.016497373580932617
Post-attention Dropout: 0.0018544197082519531
Post-attention residual: 0.0006198883056640625
LN2: 0.0006928443908691406
MLP_h_4h: 0.07224082946777344
MLP_4h_h: 0.06925225257873535
Post-MLP residual: 0.0018458366394042969
Attention layer time: 0.23394465446472168
LN1: 0.0007171630859375
QKV Transform: 0.05199170112609863
Flash: 0.0172269344329834
Attention linproj: 0.016520023345947266
Post-attention Dropout: 0.001865386962890625
Post-attention residual: 0.0006203651428222656
LN2: 0.0006926059722900391
MLP_h_4h: 0.07190227508544922
MLP_4h_h: 0.0691678524017334
Post-MLP residual: 0.0018372535705566406
Attention layer time: 0.23342180252075195
LN1: 0.0007154941558837891
QKV Transform: 0.05263876914978027
Flash: 0.017139434814453125
Attention linproj: 0.016690969467163086
Post-attention Dropout: 0.0018513202667236328
Post-attention residual: 0.00061798095703125
LN2: 0.0006923675537109375
MLP_h_4h: 0.07202768325805664
MLP_4h_h: 0.06934571266174316
Post-MLP residual: 0.0018384456634521484
Attention layer time: 0.23444080352783203
LN1: 0.0007166862487792969
QKV Transform: 0.05231285095214844
Flash: 0.017129182815551758
Attention linproj: 0.016706466674804688
Post-attention Dropout: 0.0018460750579833984
Post-attention residual: 0.0006246566772460938
LN2: 0.0006897449493408203
MLP_h_4h: 0.07191753387451172
MLP_4h_h: 0.0693204402923584
Post-MLP residual: 0.0018439292907714844
Attention layer time: 0.23399615287780762
LN1: 0.0007126331329345703
QKV Transform: 0.051647186279296875
Flash: 0.017330408096313477
Attention linproj: 0.016805171966552734
Post-attention Dropout: 0.0018477439880371094
Post-attention residual: 0.0006215572357177734
LN2: 0.0006926059722900391
MLP_h_4h: 0.07156944274902344
MLP_4h_h: 0.06924152374267578
Post-MLP residual: 0.0018544197082519531
Attention layer time: 0.2332005500793457
LN1: 0.0007100105285644531
QKV Transform: 0.05145621299743652
Flash: 0.01756882667541504
Attention linproj: 0.016594648361206055
Post-attention Dropout: 0.001859426498413086
Post-attention residual: 0.0006227493286132812
LN2: 0.0006930828094482422
MLP_h_4h: 0.07214760780334473
MLP_4h_h: 0.06971073150634766
Post-MLP residual: 0.0018467903137207031
Attention layer time: 0.2340836524963379
LN1: 0.00070953369140625
QKV Transform: 0.052489519119262695
Flash: 0.017542123794555664
Attention linproj: 0.016601085662841797
Post-attention Dropout: 0.0018489360809326172
Post-attention residual: 0.0006227493286132812
LN2: 0.0006918907165527344
MLP_h_4h: 0.07238316535949707
MLP_4h_h: 0.06928467750549316
Post-MLP residual: 0.0018434524536132812
Attention layer time: 0.2348802089691162
LN1: 0.0007121562957763672
QKV Transform: 0.05110311508178711
Flash: 0.017859458923339844
Attention linproj: 0.016442537307739258
Post-attention Dropout: 0.001861572265625
Post-attention residual: 0.0006229877471923828
LN2: 0.0006921291351318359
MLP_h_4h: 0.07218289375305176
MLP_4h_h: 0.069732666015625
Post-MLP residual: 0.0018401145935058594
Attention layer time: 0.2339024543762207
LN1: 0.0007245540618896484
QKV Transform: 0.05160856246948242
Flash: 0.017427921295166016
Attention linproj: 0.01648712158203125
Post-attention Dropout: 0.0018620491027832031
Post-attention residual: 0.0006237030029296875
LN2: 0.0006937980651855469
MLP_h_4h: 0.07256412506103516
MLP_4h_h: 0.07020163536071777
Post-MLP residual: 0.001844167709350586
Attention layer time: 0.2348928451538086
LN1: 0.0007140636444091797
QKV Transform: 0.05165863037109375
Flash: 0.017331600189208984
Attention linproj: 0.01650834083557129
Post-attention Dropout: 0.0018520355224609375
Post-attention residual: 0.000621795654296875
LN2: 0.0006906986236572266
MLP_h_4h: 0.07189774513244629
MLP_4h_h: 0.06901431083679199
Post-MLP residual: 0.0018470287322998047
Attention layer time: 0.2329864501953125
LN1: 0.000713348388671875
QKV Transform: 0.05158233642578125
Flash: 0.017429828643798828
Attention linproj: 0.016376972198486328
Post-attention Dropout: 0.0018498897552490234
Post-attention residual: 0.0006196498870849609
LN2: 0.0006909370422363281
MLP_h_4h: 0.07225275039672852
MLP_4h_h: 0.06902647018432617
Post-MLP residual: 0.0018544197082519531
Attention layer time: 0.2332606315612793
LN1: 0.0007154941558837891
QKV Transform: 0.051895856857299805
Flash: 0.0172269344329834
Attention linproj: 0.01675105094909668
Post-attention Dropout: 0.0018551349639892578
Post-attention residual: 0.0006206035614013672
LN2: 0.0006945133209228516
MLP_h_4h: 0.07179450988769531
MLP_4h_h: 0.06922388076782227
Post-MLP residual: 0.0018491744995117188
Attention layer time: 0.2335529327392578
LN1: 0.0007154941558837891
QKV Transform: 0.05154561996459961
Flash: 0.019918203353881836
Attention linproj: 0.01636052131652832
Post-attention Dropout: 0.0018405914306640625
Post-attention residual: 0.0006215572357177734
LN2: 0.0007083415985107422
MLP_h_4h: 0.0722663402557373
MLP_4h_h: 0.06923675537109375
Post-MLP residual: 0.0018432140350341797
Attention layer time: 0.2359309196472168
LN1: 0.0007150173187255859
QKV Transform: 0.05194401741027832
Flash: 0.017230987548828125
Attention linproj: 0.016463279724121094
Post-attention Dropout: 0.0018463134765625
Post-attention residual: 0.0006182193756103516
LN2: 0.0006930828094482422
MLP_h_4h: 0.07225441932678223
MLP_4h_h: 0.06903672218322754
Post-MLP residual: 0.0018520355224609375
Attention layer time: 0.2335350513458252
LN1: 0.0007131099700927734
QKV Transform: 0.052370548248291016
Flash: 0.018285751342773438
Attention linproj: 0.016579151153564453
Post-attention Dropout: 0.0018503665924072266
Post-attention residual: 0.0006232261657714844
LN2: 0.0006945133209228516
MLP_h_4h: 0.0717923641204834
MLP_4h_h: 0.06949305534362793
Post-MLP residual: 0.0018346309661865234
Attention layer time: 0.23513126373291016
LN1: 0.0007166862487792969
QKV Transform: 0.05181288719177246
Flash: 0.017362594604492188
Attention linproj: 0.016483306884765625
Post-attention Dropout: 0.0018463134765625
Post-attention residual: 0.0006198883056640625
LN2: 0.0006921291351318359
MLP_h_4h: 0.07219147682189941
MLP_4h_h: 0.06928634643554688
Post-MLP residual: 0.0018432140350341797
Attention layer time: 0.23372435569763184
LN1: 0.0007145404815673828
QKV Transform: 0.051969051361083984
Flash: 0.017493247985839844
Attention linproj: 0.016691207885742188
Post-attention Dropout: 0.0018582344055175781
Post-attention residual: 0.0006210803985595703
LN2: 0.0006928443908691406
MLP_h_4h: 0.07184052467346191
MLP_4h_h: 0.06943750381469727
Post-MLP residual: 0.0018417835235595703
Attention layer time: 0.2340254783630371
LN1: 0.0007169246673583984
QKV Transform: 0.0519716739654541
Flash: 0.01747274398803711
Attention linproj: 0.01671147346496582
Post-attention Dropout: 0.001844644546508789
Post-attention residual: 0.0006210803985595703
LN2: 0.00069427490234375
MLP_h_4h: 0.07382583618164062
MLP_4h_h: 0.06896281242370605
Post-MLP residual: 0.0018439292907714844
Attention layer time: 0.2355349063873291
LN1: 0.0007145404815673828
QKV Transform: 0.052408456802368164
Flash: 0.01716303825378418
Attention linproj: 0.016712188720703125
Post-attention Dropout: 0.001852273941040039
Post-attention residual: 0.0006227493286132812
LN2: 0.0006892681121826172
MLP_h_4h: 0.07213187217712402
MLP_4h_h: 0.06944537162780762
Post-MLP residual: 0.0018324851989746094
Attention layer time: 0.23444795608520508
LN1: 0.0007114410400390625
QKV Transform: 0.05250692367553711
Flash: 0.017535686492919922
Attention linproj: 0.016810894012451172
Post-attention Dropout: 0.0018453598022460938
Post-attention residual: 0.0006222724914550781
LN2: 0.0006940364837646484
MLP_h_4h: 0.07228684425354004
MLP_4h_h: 0.06928801536560059
Post-MLP residual: 0.0018477439880371094
Attention layer time: 0.23502779006958008
LN1: 0.0007112026214599609
QKV Transform: 0.051573991775512695
Flash: 0.017400741577148438
Attention linproj: 0.01660466194152832
Post-attention Dropout: 0.0018532276153564453
Post-attention residual: 0.0006220340728759766
LN2: 0.0006909370422363281
MLP_h_4h: 0.07239603996276855
MLP_4h_h: 0.07000422477722168
Post-MLP residual: 0.0018467903137207031
Attention layer time: 0.23457837104797363
LN1: 0.0007109642028808594
QKV Transform: 0.05119657516479492
Flash: 0.017734527587890625
Attention linproj: 0.01645064353942871
Post-attention Dropout: 0.0018396377563476562
Post-attention residual: 0.0006225109100341797
LN2: 0.0006906986236572266
MLP_h_4h: 0.07272505760192871
MLP_4h_h: 0.07004809379577637
Post-MLP residual: 0.0018506050109863281
Attention layer time: 0.2347266674041748
LN1: 0.0007107257843017578
QKV Transform: 0.05268406867980957
Flash: 0.017281532287597656
Attention linproj: 0.016613483428955078
Post-attention Dropout: 0.0018453598022460938
Post-attention residual: 0.0006215572357177734
LN2: 0.0006921291351318359
MLP_h_4h: 0.0726165771484375
MLP_4h_h: 0.06951093673706055
Post-MLP residual: 0.0018463134765625
Attention layer time: 0.23529481887817383
LN1: 0.0007143020629882812
QKV Transform: 0.0514531135559082
Flash: 0.017569780349731445
Attention linproj: 0.01648545265197754
Post-attention Dropout: 0.0018460750579833984
Post-attention residual: 0.0006225109100341797
LN2: 0.0006930828094482422
MLP_h_4h: 0.0724332332611084
MLP_4h_h: 0.06941056251525879
Post-MLP residual: 0.0018508434295654297
Attention layer time: 0.2339332103729248
LN1: 0.0007147789001464844
QKV Transform: 0.0518183708190918
Flash: 0.017926454544067383
Attention linproj: 0.016370296478271484
Post-attention Dropout: 0.0018434524536132812
Post-attention residual: 0.0006206035614013672
LN2: 0.0006923675537109375
MLP_h_4h: 0.07258033752441406
MLP_4h_h: 0.06930923461914062
Post-MLP residual: 0.0018472671508789062
Attention layer time: 0.2345867156982422
LN1: 0.0007114410400390625
QKV Transform: 0.05173754692077637
Flash: 0.01732921600341797
Attention linproj: 0.016472578048706055
Post-attention Dropout: 0.0018472671508789062
Post-attention residual: 0.0006203651428222656
LN2: 0.0007112026214599609
MLP_h_4h: 0.07218289375305176
MLP_4h_h: 0.06892037391662598
Post-MLP residual: 0.0018565654754638672
Attention layer time: 0.23324275016784668
LN1: 0.0007126331329345703
QKV Transform: 0.051950693130493164
Flash: 0.01720118522644043
Attention linproj: 0.016480684280395508
Post-attention Dropout: 0.0018537044525146484
Post-attention residual: 0.0006196498870849609
LN2: 0.00069427490234375
MLP_h_4h: 0.07222604751586914
MLP_4h_h: 0.06897997856140137
Post-MLP residual: 0.0018520355224609375
Attention layer time: 0.2334427833557129
LN1: 0.0007150173187255859
QKV Transform: 0.050914764404296875
Flash: 0.018133163452148438
Attention linproj: 0.016336679458618164
Post-attention Dropout: 0.001837015151977539
Post-attention residual: 0.0006213188171386719
LN2: 0.0006952285766601562
MLP_h_4h: 0.07351469993591309
MLP_4h_h: 0.06908726692199707
Post-MLP residual: 0.0018639564514160156
Attention layer time: 0.23458266258239746
LN1: 0.0007145404815673828
QKV Transform: 0.05211901664733887
Flash: 0.018028974533081055
Attention linproj: 0.016418933868408203
Post-attention Dropout: 0.0018491744995117188
Post-attention residual: 0.0006215572357177734
LN2: 0.0006947517395019531
MLP_h_4h: 0.07214832305908203
MLP_4h_h: 0.06926965713500977
Post-MLP residual: 0.0018420219421386719
Attention layer time: 0.234588623046875
LN1: 0.0007157325744628906
QKV Transform: 0.052474021911621094
Flash: 0.017311573028564453
Attention linproj: 0.016759872436523438
Post-attention Dropout: 0.0018477439880371094
Post-attention residual: 0.0006213188171386719
LN2: 0.0006911754608154297
MLP_h_4h: 0.07225251197814941
MLP_4h_h: 0.06925177574157715
Post-MLP residual: 0.0018532276153564453
Attention layer time: 0.23465943336486816
LN1: 0.0007147789001464844
QKV Transform: 0.05243396759033203
Flash: 0.017403602600097656
Attention linproj: 0.016505718231201172
Post-attention Dropout: 0.0018503665924072266
Post-attention residual: 0.0006227493286132812
LN2: 0.0006935596466064453
MLP_h_4h: 0.07210636138916016
MLP_4h_h: 0.06907105445861816
Post-MLP residual: 0.0018413066864013672
Attention layer time: 0.23412108421325684
LN1: 0.0007166862487792969
QKV Transform: 0.05266237258911133
Flash: 0.0172274112701416
Attention linproj: 0.016704320907592773
Post-attention Dropout: 0.0018453598022460938
Post-attention residual: 0.0006239414215087891
LN2: 0.0006911754608154297
MLP_h_4h: 0.07188200950622559
MLP_4h_h: 0.06927347183227539
Post-MLP residual: 0.0018453598022460938
Attention layer time: 0.23435354232788086
LN1: 0.0007140636444091797
QKV Transform: 0.05236244201660156
Flash: 0.017501354217529297
Attention linproj: 0.016739368438720703
Post-attention Dropout: 0.0018467903137207031
Post-attention residual: 0.0006227493286132812
LN2: 0.0006961822509765625
MLP_h_4h: 0.07207775115966797
MLP_4h_h: 0.06918454170227051
Post-MLP residual: 0.0018410682678222656
Attention layer time: 0.23449349403381348
LN1: 0.0007152557373046875
QKV Transform: 0.05281233787536621
Flash: 0.01804208755493164
Attention linproj: 0.0166778564453125
Post-attention Dropout: 0.0018630027770996094
Post-attention residual: 0.0006222724914550781
LN2: 0.0006940364837646484
MLP_h_4h: 0.07210612297058105
MLP_4h_h: 0.06908011436462402
Post-MLP residual: 0.0018420219421386719
Attention layer time: 0.2353367805480957
LN1: 0.0007112026214599609
QKV Transform: 0.051795244216918945
Flash: 0.01735544204711914
Attention linproj: 0.01716470718383789
Post-attention Dropout: 0.0018498897552490234
Post-attention residual: 0.0006237030029296875
LN2: 0.0006952285766601562
MLP_h_4h: 0.07244706153869629
MLP_4h_h: 0.06926155090332031
Post-MLP residual: 0.0018444061279296875
Attention layer time: 0.23463916778564453
LN1: 0.0007107257843017578
QKV Transform: 0.05132269859313965
Flash: 0.017666101455688477
Attention linproj: 0.01661372184753418
Post-attention Dropout: 0.0018389225006103516
Post-attention residual: 0.0006215572357177734
LN2: 0.0006921291351318359
MLP_h_4h: 0.07182025909423828
MLP_4h_h: 0.06936788558959961
Post-MLP residual: 0.0018453598022460938
Attention layer time: 0.23337674140930176
LN1: 0.0007112026214599609
QKV Transform: 0.051540374755859375
Flash: 0.01751565933227539
Attention linproj: 0.016476154327392578
Post-attention Dropout: 0.0018432140350341797
Post-attention residual: 0.0006213188171386719
LN2: 0.0006923675537109375
MLP_h_4h: 0.07246708869934082
MLP_4h_h: 0.07025384902954102
Post-MLP residual: 0.0018453598022460938
Attention layer time: 0.234818696975708
LN1: 0.0007159709930419922
QKV Transform: 0.050887346267700195
Flash: 0.017053604125976562
Attention linproj: 0.01638960838317871
Post-attention Dropout: 0.001842498779296875
Post-attention residual: 0.0006234645843505859
LN2: 0.00069427490234375
MLP_h_4h: 0.0720052719116211
MLP_4h_h: 0.06890201568603516
Post-MLP residual: 0.0018455982208251953
Attention layer time: 0.2318129539489746
LN1: 0.0007147789001464844
QKV Transform: 0.05172371864318848
Flash: 0.01733255386352539
Attention linproj: 0.01648426055908203
Post-attention Dropout: 0.0018508434295654297
Post-attention residual: 0.0006227493286132812
LN2: 0.0006933212280273438
MLP_h_4h: 0.07223176956176758
MLP_4h_h: 0.06913375854492188
Post-MLP residual: 0.0018427371978759766
Attention layer time: 0.2334890365600586
LN1: 0.0007123947143554688
QKV Transform: 0.05222749710083008
Flash: 0.017412185668945312
Attention linproj: 0.016373395919799805
Post-attention Dropout: 0.0018503665924072266
Post-attention residual: 0.0006208419799804688
LN2: 0.0006928443908691406
MLP_h_4h: 0.07157063484191895
MLP_4h_h: 0.06827545166015625
Post-MLP residual: 0.0018568038940429688
Attention layer time: 0.23244833946228027
LN1: 0.0007150173187255859
QKV Transform: 0.05238485336303711
Flash: 0.018451213836669922
Attention linproj: 0.016399383544921875
Post-attention Dropout: 0.0018537044525146484
Post-attention residual: 0.0006210803985595703
LN2: 0.0006945133209228516
MLP_h_4h: 0.07187581062316895
MLP_4h_h: 0.06920051574707031
Post-MLP residual: 0.0018458366394042969
Attention layer time: 0.23492693901062012
LN1: 0.0007164478302001953
QKV Transform: 0.05235767364501953
Flash: 0.01748204231262207
Attention linproj: 0.016475200653076172
Post-attention Dropout: 0.0018460750579833984
Post-attention residual: 0.0006234645843505859
LN2: 0.0006926059722900391
MLP_h_4h: 0.07162117958068848
MLP_4h_h: 0.0687718391418457
Post-MLP residual: 0.0018520355224609375
Attention layer time: 0.23329639434814453
LN1: 0.0007131099700927734
QKV Transform: 0.051371097564697266
Flash: 0.017626523971557617
Attention linproj: 0.016860485076904297
Post-attention Dropout: 0.0018429756164550781
Post-attention residual: 0.0006258487701416016
LN2: 0.0006909370422363281
MLP_h_4h: 0.0714871883392334
MLP_4h_h: 0.06923246383666992
Post-MLP residual: 0.0018310546875
Attention layer time: 0.23315048217773438
LN1: 0.0007097721099853516
QKV Transform: 0.052100419998168945
Flash: 0.016844511032104492
Attention linproj: 0.01660633087158203
Post-attention Dropout: 0.0018568038940429688
Post-attention residual: 0.0006227493286132812
LN2: 0.0006909370422363281
MLP_h_4h: 0.07149934768676758
MLP_4h_h: 0.06940031051635742
Post-MLP residual: 0.0018434524536132812
Attention layer time: 0.23302817344665527
LN1: 0.0007126331329345703
QKV Transform: 0.05250668525695801
Flash: 0.01743769645690918
Attention linproj: 0.016386032104492188
Post-attention Dropout: 0.001840829849243164
Post-attention residual: 0.0006244182586669922
LN2: 0.0006914138793945312
MLP_h_4h: 0.07196927070617676
MLP_4h_h: 0.0695500373840332
Post-MLP residual: 0.0018427371978759766
Attention layer time: 0.23441076278686523
LN1: 0.0007123947143554688
QKV Transform: 0.05128026008605957
Flash: 0.017833709716796875
Attention linproj: 0.01667475700378418
Post-attention Dropout: 0.0018579959869384766
Post-attention residual: 0.0006203651428222656
LN2: 0.0006940364837646484
MLP_h_4h: 0.07145547866821289
MLP_4h_h: 0.06875395774841309
Post-MLP residual: 0.0018553733825683594
Attention layer time: 0.23260498046875
LN1: 0.0007295608520507812
QKV Transform: 0.05182027816772461
Flash: 0.01739978790283203
Attention linproj: 0.01654839515686035
Post-attention Dropout: 0.0020093917846679688
Post-attention residual: 0.0006301403045654297
LN2: 0.0007741451263427734
MLP_h_4h: 0.07132196426391602
MLP_4h_h: 0.06864380836486816
Post-MLP residual: 0.0018625259399414062
Attention layer time: 0.23282241821289062
LN1: 0.0007233619689941406
QKV Transform: 0.051782846450805664
Flash: 0.017319202423095703
Attention linproj: 0.016512393951416016
Post-attention Dropout: 0.0018687248229980469
Post-attention residual: 0.0006213188171386719
LN2: 0.0006911754608154297
MLP_h_4h: 0.07147693634033203
MLP_4h_h: 0.06896138191223145
Post-MLP residual: 0.0018622875213623047
Attention layer time: 0.23276233673095703
LN1: 0.0007162094116210938
QKV Transform: 0.05262565612792969
Flash: 0.017149925231933594
Attention linproj: 0.016707181930541992
Post-attention Dropout: 0.0018570423126220703
Post-attention residual: 0.0006201267242431641
LN2: 0.0006914138793945312
MLP_h_4h: 0.07150864601135254
MLP_4h_h: 0.06882905960083008
Post-MLP residual: 0.0018360614776611328
Attention layer time: 0.2334156036376953
LN1: 0.0007126331329345703
QKV Transform: 0.05249381065368652
Flash: 0.018062829971313477
Attention linproj: 0.016507387161254883
Post-attention Dropout: 0.0018486976623535156
Post-attention residual: 0.0006229877471923828
LN2: 0.0006954669952392578
MLP_h_4h: 0.07192516326904297
MLP_4h_h: 0.06935477256774902
Post-MLP residual: 0.0018420219421386719
Attention layer time: 0.23493385314941406
LN1: 0.0007143020629882812
QKV Transform: 0.051239967346191406
Flash: 0.018768310546875
Attention linproj: 0.016707420349121094
Post-attention Dropout: 0.0018427371978759766
Post-attention residual: 0.0006210803985595703
LN2: 0.0006923675537109375
MLP_h_4h: 0.07146024703979492
MLP_4h_h: 0.06882119178771973
Post-MLP residual: 0.0018367767333984375
Attention layer time: 0.23357415199279785
LN1: 0.0007092952728271484
QKV Transform: 0.05105304718017578
Flash: 0.01787734031677246
Attention linproj: 0.01645660400390625
Post-attention Dropout: 0.0018618106842041016
Post-attention residual: 0.0006234645843505859
LN2: 0.0006926059722900391
MLP_h_4h: 0.07143163681030273
MLP_4h_h: 0.06878137588500977
Post-MLP residual: 0.0018496513366699219
Attention layer time: 0.23218512535095215
LN1: 0.0007112026214599609
QKV Transform: 0.05143332481384277
Flash: 0.01749706268310547
Attention linproj: 0.016359806060791016
Post-attention Dropout: 0.0018491744995117188
Post-attention residual: 0.0006234645843505859
LN2: 0.0006952285766601562
MLP_h_4h: 0.07187795639038086
MLP_4h_h: 0.06904363632202148
Post-MLP residual: 0.0018460750579833984
Attention layer time: 0.23279356956481934
LN1: 0.000713348388671875
QKV Transform: 0.05161595344543457
Flash: 0.017485618591308594
Attention linproj: 0.01677393913269043
Post-attention Dropout: 0.0018489360809326172
Post-attention residual: 0.0006215572357177734
LN2: 0.0006966590881347656
MLP_h_4h: 0.07157588005065918
MLP_4h_h: 0.0688323974609375
Post-MLP residual: 0.001850128173828125
Attention layer time: 0.23293495178222656
LN1: 0.0007143020629882812
QKV Transform: 0.05233573913574219
Flash: 0.017398834228515625
Attention linproj: 0.016378402709960938
Post-attention Dropout: 0.0018477439880371094
Post-attention residual: 0.0006322860717773438
LN2: 0.0006911754608154297
MLP_h_4h: 0.07208633422851562
MLP_4h_h: 0.06919741630554199
Post-MLP residual: 0.0018410682678222656
Attention layer time: 0.2340106964111328
LN1: 0.0007166862487792969
QKV Transform: 0.05245518684387207
Flash: 0.017378807067871094
Attention linproj: 0.016568422317504883
Post-attention Dropout: 0.0018534660339355469
Post-attention residual: 0.0006206035614013672
LN2: 0.0006923675537109375
MLP_h_4h: 0.0714418888092041
MLP_4h_h: 0.06893253326416016
Post-MLP residual: 0.0018460750579833984
Attention layer time: 0.23337602615356445
LN1: 0.0007138252258300781
QKV Transform: 0.05195355415344238
Flash: 0.017724037170410156
Attention linproj: 0.016672372817993164
Post-attention Dropout: 0.0018372535705566406
Post-attention residual: 0.0006198883056640625
LN2: 0.0006973743438720703
MLP_h_4h: 0.07172417640686035
MLP_4h_h: 0.06910085678100586
Post-MLP residual: 0.0018367767333984375
Attention layer time: 0.2337510585784912
LN1: 0.0007128715515136719
QKV Transform: 0.051589012145996094
Flash: 0.017371177673339844
Attention linproj: 0.0164186954498291
Post-attention Dropout: 0.0018372535705566406
Post-attention residual: 0.0006225109100341797
LN2: 0.0006928443908691406
MLP_h_4h: 0.07169008255004883
MLP_4h_h: 0.06920456886291504
Post-MLP residual: 0.0018472671508789062
Attention layer time: 0.2328352928161621
LN1: 0.0007119178771972656
QKV Transform: 0.0509488582611084
Flash: 0.017024993896484375
Attention linproj: 0.016489267349243164
Post-attention Dropout: 0.0018548965454101562
Post-attention residual: 0.0006196498870849609
LN2: 0.0006926059722900391
MLP_h_4h: 0.07218122482299805
MLP_4h_h: 0.06937718391418457
Post-MLP residual: 0.0018429756164550781
Attention layer time: 0.23260068893432617
LN1: 0.0007147789001464844
QKV Transform: 0.05213212966918945
Flash: 0.01770639419555664
Attention linproj: 0.016350269317626953
Post-attention Dropout: 0.0018544197082519531
Post-attention residual: 0.0006227493286132812
LN2: 0.0006930828094482422
MLP_h_4h: 0.07211065292358398
MLP_4h_h: 0.06925058364868164
Post-MLP residual: 0.0018432140350341797
Attention layer time: 0.23412203788757324
LN1: 0.0007190704345703125
QKV Transform: 0.05148935317993164
Flash: 0.01746368408203125
Attention linproj: 0.016360044479370117
Post-attention Dropout: 0.0018489360809326172
Post-attention residual: 0.0006213188171386719
LN2: 0.0006933212280273438
MLP_h_4h: 0.07205510139465332
MLP_4h_h: 0.06871533393859863
Post-MLP residual: 0.0018358230590820312
Attention layer time: 0.23267650604248047
LN1: 0.0007152557373046875
QKV Transform: 0.05272364616394043
Flash: 0.01742839813232422
Attention linproj: 0.016927242279052734
Post-attention Dropout: 0.0018572807312011719
Post-attention residual: 0.0006220340728759766
LN2: 0.0006911754608154297
MLP_h_4h: 0.071624755859375
MLP_4h_h: 0.06940484046936035
Post-MLP residual: 0.0019102096557617188
Attention layer time: 0.234879732131958
LN1: 0.0007350444793701172
QKV Transform: 0.05239748954772949
Flash: 0.01748180389404297
Attention linproj: 0.016408920288085938
Post-attention Dropout: 0.0018415451049804688
Post-attention residual: 0.0006251335144042969
LN2: 0.0006914138793945312
MLP_h_4h: 0.07181787490844727
MLP_4h_h: 0.0688169002532959
Post-MLP residual: 0.0018448829650878906
Attention layer time: 0.23356842994689941
LN1: 0.0007200241088867188
QKV Transform: 0.05143594741821289
Flash: 0.01756739616394043
Attention linproj: 0.016666173934936523
Post-attention Dropout: 0.001842498779296875
Post-attention residual: 0.0006227493286132812
LN2: 0.0006902217864990234
MLP_h_4h: 0.07179641723632812
MLP_4h_h: 0.0692133903503418
Post-MLP residual: 0.001863241195678711
Attention layer time: 0.2332911491394043
LN1: 0.0007135868072509766
QKV Transform: 0.0524289608001709
Flash: 0.01736927032470703
Attention linproj: 0.01672053337097168
Post-attention Dropout: 0.0018417835235595703
Post-attention residual: 0.0006239414215087891
LN2: 0.0006935596466064453
MLP_h_4h: 0.07151532173156738
MLP_4h_h: 0.06935977935791016
Post-MLP residual: 0.0018367767333984375
Attention layer time: 0.23398709297180176
LN1: 0.0007100105285644531
QKV Transform: 0.051137447357177734
Flash: 0.018889188766479492
Attention linproj: 0.016351938247680664
Post-attention Dropout: 0.0018460750579833984
Post-attention residual: 0.000621795654296875
LN2: 0.0006933212280273438
MLP_h_4h: 0.07170915603637695
MLP_4h_h: 0.06938362121582031
Post-MLP residual: 0.0018391609191894531
Attention layer time: 0.23402953147888184
LN1: 0.0007116794586181641
QKV Transform: 0.05087566375732422
Flash: 0.017059803009033203
Attention linproj: 0.016353368759155273
Post-attention Dropout: 0.0018467903137207031
Post-attention residual: 0.0006206035614013672
LN2: 0.0006933212280273438
MLP_h_4h: 0.07203865051269531
MLP_4h_h: 0.06920146942138672
Post-MLP residual: 0.001844644546508789
Attention layer time: 0.23209309577941895
LN1: 0.0007121562957763672
QKV Transform: 0.0515596866607666
Flash: 0.017541885375976562
Attention linproj: 0.016367435455322266
Post-attention Dropout: 0.0018489360809326172
Post-attention residual: 0.0006222724914550781
LN2: 0.0006978511810302734
MLP_h_4h: 0.07187795639038086
MLP_4h_h: 0.0687406063079834
Post-MLP residual: 0.0018420219421386719
Attention layer time: 0.23265838623046875
LN1: 0.0007131099700927734
QKV Transform: 0.0518345832824707
Flash: 0.017286062240600586
Attention linproj: 0.01642131805419922
Post-attention Dropout: 0.0018510818481445312
Post-attention residual: 0.0006246566772460938
LN2: 0.0006954669952392578
MLP_h_4h: 0.07230138778686523
MLP_4h_h: 0.06910443305969238
Post-MLP residual: 0.0018401145935058594
Attention layer time: 0.23356890678405762
LN1: 0.0007319450378417969
QKV Transform: 0.05173349380493164
Flash: 0.017425537109375
Attention linproj: 0.016803503036499023
Post-attention Dropout: 0.0018453598022460938
Post-attention residual: 0.0006222724914550781
LN2: 0.0006906986236572266
MLP_h_4h: 0.07182097434997559
MLP_4h_h: 0.06944012641906738
Post-MLP residual: 0.0018720626831054688
Attention layer time: 0.2338712215423584
LN1: 0.000713348388671875
QKV Transform: 0.052000999450683594
Flash: 0.017728805541992188
Attention linproj: 0.01652240753173828
Post-attention Dropout: 0.0018467903137207031
Post-attention residual: 0.000621795654296875
LN2: 0.0006926059722900391
MLP_h_4h: 0.07240128517150879
MLP_4h_h: 0.0698850154876709
Post-MLP residual: 0.0018320083618164062
Attention layer time: 0.23511481285095215
LN1: 0.0007128715515136719
QKV Transform: 0.052347421646118164
Flash: 0.017445802688598633
Attention linproj: 0.016817569732666016
Post-attention Dropout: 0.0018467903137207031
Post-attention residual: 0.0006201267242431641
LN2: 0.0006973743438720703
MLP_h_4h: 0.07147598266601562
MLP_4h_h: 0.06924939155578613
Post-MLP residual: 0.0018486976623535156
Attention layer time: 0.23394465446472168
LN1: 0.0007097721099853516
QKV Transform: 0.05151939392089844
Flash: 0.017495393753051758
Attention linproj: 0.016553163528442383
Post-attention Dropout: 0.0018362998962402344
Post-attention residual: 0.0006229877471923828
LN2: 0.0006909370422363281
MLP_h_4h: 0.07225823402404785
MLP_4h_h: 0.06952476501464844
Post-MLP residual: 0.0018391609191894531
Attention layer time: 0.2339153289794922
LN1: 0.0007195472717285156
QKV Transform: 0.05130171775817871
Flash: 0.017737388610839844
Attention linproj: 0.016416072845458984
Post-attention Dropout: 0.00183868408203125
Post-attention residual: 0.0006237030029296875
LN2: 0.0006930828094482422
MLP_h_4h: 0.07225441932678223
MLP_4h_h: 0.07009339332580566
Post-MLP residual: 0.0018541812896728516
Attention layer time: 0.23440003395080566
LN1: 0.0007166862487792969
QKV Transform: 0.05189871788024902
Flash: 0.017849206924438477
Attention linproj: 0.016478538513183594
Post-attention Dropout: 0.0018389225006103516
Post-attention residual: 0.0006227493286132812
LN2: 0.0006926059722900391
MLP_h_4h: 0.07195234298706055
MLP_4h_h: 0.06955838203430176
Post-MLP residual: 0.0018451213836669922
Attention layer time: 0.23433995246887207
LN1: 0.0007126331329345703
QKV Transform: 0.05106210708618164
Flash: 0.016969919204711914
Attention linproj: 0.016373872756958008
Post-attention Dropout: 0.001844644546508789
Post-attention residual: 0.0006198883056640625
LN2: 0.0006895065307617188
MLP_h_4h: 0.07202863693237305
MLP_4h_h: 0.06900787353515625
Post-MLP residual: 0.0018422603607177734
Attention layer time: 0.2319962978363037
LN1: 0.0007140636444091797
QKV Transform: 0.05176281929016113
Flash: 0.01725912094116211
Attention linproj: 0.01640939712524414
Post-attention Dropout: 0.0018508434295654297
Post-attention residual: 0.000621795654296875
LN2: 0.0006964206695556641
MLP_h_4h: 0.07222485542297363
MLP_4h_h: 0.06926774978637695
Post-MLP residual: 0.0018582344055175781
Attention layer time: 0.23351049423217773
LN1: 0.0007152557373046875
QKV Transform: 0.052860260009765625
Flash: 0.017168521881103516
Attention linproj: 0.0166168212890625
Post-attention Dropout: 0.0018703937530517578
Post-attention residual: 0.0006220340728759766
LN2: 0.0007004737854003906
MLP_h_4h: 0.07210636138916016
MLP_4h_h: 0.06896138191223145
Post-MLP residual: 0.0018508434295654297
Attention layer time: 0.23435521125793457
Transformer duration (in seconds): 0.2416
Transformer throughput (in TFLOP/s): 222.954
========================================================================================================================

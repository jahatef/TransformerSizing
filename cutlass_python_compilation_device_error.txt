Compilation error for the following kernel: 
#include "cutlass/cutlass.h"
#include "cutlass/numeric_types.h"
#include "cutlass/arch/arch.h"
#include "cutlass/arch/mma.h"
#include "cutlass/layout/matrix.h"
#include "cutlass/gemm/device/gemm.h"
#include "cutlass/gemm/device/gemm_universal_adapter.h"
#include "cutlass/gemm/kernel/default_gemm_universal.h"

// Gemm operator cutlass_sm80_tensorop_h16x8x16gemm_1x1x1_256x128_64x3_tt_align8
using cutlass_sm80_tensorop_h16x8x16gemm_1x1x1_256x128_64x3_tt_align8_base =
  typename cutlass::gemm::kernel::DefaultGemmUniversal<
    cutlass::half_t, cutlass::layout::RowMajor, cutlass::ComplexTransform::kNone, 8,
    cutlass::half_t, cutlass::layout::RowMajor, cutlass::ComplexTransform::kNone, 1,
    cutlass::half_t, cutlass::layout::RowMajor,
    cutlass::half_t,
    cutlass::arch::OpClassTensorOp,
    cutlass::arch::Sm80,
    cutlass::gemm::GemmShape<256, 128, 64>,
    cutlass::gemm::GemmShape<64, 64, 64>,
    cutlass::gemm::GemmShape<16, 8, 16>,
    cutlass::epilogue::thread::LinearCombination<cutlass::half_t, 1, cutlass::half_t, cutlass::half_t>,
    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<1>,
    3,
    cutlass::arch::OpMultiplyAdd
>::GemmKernel;

// Define named type
struct cutlass_sm80_tensorop_h16x8x16gemm_1x1x1_256x128_64x3_tt_align8_type : 
  public cutlass_sm80_tensorop_h16x8x16gemm_1x1x1_256x128_64x3_tt_align8_base { };

extern "C"
__global__ void
cutlass_sm80_tensorop_h16x8x16gemm_1x1x1_256x128_64x3_tt_align8(cutlass_sm80_tensorop_h16x8x16gemm_1x1x1_256x128_64x3_tt_align8_type::Params params) {

  // Dynamic shared memory base pointer
  extern __shared__ int SharedStorageBase[];

  // Declare pointer to dynamic shared memory.
  cutlass_sm80_tensorop_h16x8x16gemm_1x1x1_256x128_64x3_tt_align8_type::SharedStorage *shared_storage =
      reinterpret_cast<cutlass_sm80_tensorop_h16x8x16gemm_1x1x1_256x128_64x3_tt_align8_type::SharedStorage *>(SharedStorageBase);

  cutlass_sm80_tensorop_h16x8x16gemm_1x1x1_256x128_64x3_tt_align8_type::invoke(params, *shared_storage);
}
  
Error Message:
/fsx/quentin/jacob/gpt-neox-stuff/GEMMs_project/transformer_sizing/experiments/scripts/cutlass/python/cutlass/../..//include/cutlass/arch/memory_sm80.h(158): error: static assertion failed with "Size is not supported"
          detected during:
            instantiation of "cutlass::arch::cp_async_zfill<SizeInBytes, cutlass::arch::CacheOperation::Always>::cp_async_zfill(void *, const void *, __nv_bool) [with SizeInBytes=2]" 
/fsx/quentin/jacob/gpt-neox-stuff/GEMMs_project/transformer_sizing/experiments/scripts/cutlass/python/cutlass/../..//include/cutlass/gemm/threadblock/mma_multistage.h(422): here
            instantiation of "void cutlass::gemm::threadblock::MmaMultistage<Shape_, IteratorA_, SmemIteratorA_, CacheOpA, IteratorB_, SmemIteratorB_, CacheOpB, ElementC_, LayoutC_, Policy_, Stages, SharedMemoryClear, Enable>::prologue(cutlass::gemm::threadblock::MmaMultistage<Shape_, IteratorA_, SmemIteratorA_, CacheOpA, IteratorB_, SmemIteratorB_, CacheOpB, ElementC_, LayoutC_, Policy_, Stages, SharedMemoryClear, Enable>::IteratorA &, cutlass::gemm::threadblock::MmaMultistage<Shape_, IteratorA_, SmemIteratorA_, CacheOpA, IteratorB_, SmemIteratorB_, CacheOpB, ElementC_, LayoutC_, Policy_, Stages, SharedMemoryClear, Enable>::IteratorB &, int &) [with Shape_=cutlass::gemm::GemmShape<256, 128, 64>, IteratorA_=cutlass::transform::threadblock::PredicatedTileAccessIterator<cutlass::MatrixShape<256, 64>, cutlass::half_t, cutlass::layout::RowMajor, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<64, 256>, 256, cutlass::PitchLinearShape<8, 4>, 8>, cutlass::Array<cutlass::half_t, 8, false>, false, cutlass::layout::NoPermute>, SmemIteratorA_=cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<256, 64>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCrosswise<16, 64>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<64, 256>, 256, cutlass::PitchLinearShape<8, 4>, 8>, 16>, CacheOpA=cutlass::arch::CacheOperation::Global, IteratorB_=cutlass::transform::threadblock::PredicatedTileAccessIterator<cutlass::MatrixShape<64, 128>, cutlass::half_t, cutlass::layout::RowMajor, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<128, 64>, 256, cutlass::PitchLinearShape<8, 4>, 8>, cutlass::Array<cutlass::half_t, 1, false>, false, cutlass::layout::NoPermute>, SmemIteratorB_=cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 128>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<16, 64>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<128, 64>, 256, cutlass::PitchLinearShape<8, 4>, 8>, 16>, CacheOpB=cutlass::arch::CacheOperation::Always, ElementC_=cutlass::half_t, LayoutC_=cutlass::layout::RowMajor, Policy_=cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 64>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCrosswise<16, 64>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<16, 64>, cutlass::half_t, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 16>, 32, cutlass::half_t, cutlass::layout::RowMajor, cutlass::half_t, cutlass::layout::ColumnMajor, cutlass::half_t, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1>>, 1, false, __nv_bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, Stages=3, SharedMemoryClear=cutlass::gemm::SharedMemoryClearOption::kNone, Enable=__nv_bool]" 
/fsx/quentin/jacob/gpt-neox-stuff/GEMMs_project/transformer_sizing/experiments/scripts/cutlass/python/cutlass/../..//include/cutlass/gemm/threadblock/mma_multistage.h(721): here
            instantiation of "void cutlass::gemm::threadblock::MmaMultistage<Shape_, IteratorA_, SmemIteratorA_, CacheOpA, IteratorB_, SmemIteratorB_, CacheOpB, ElementC_, LayoutC_, Policy_, Stages, SharedMemoryClear, Enable>::operator()(int, cutlass::gemm::threadblock::MmaMultistage<Shape_, IteratorA_, SmemIteratorA_, CacheOpA, IteratorB_, SmemIteratorB_, CacheOpB, ElementC_, LayoutC_, Policy_, Stages, SharedMemoryClear, Enable>::FragmentC &, cutlass::gemm::threadblock::MmaMultistage<Shape_, IteratorA_, SmemIteratorA_, CacheOpA, IteratorB_, SmemIteratorB_, CacheOpB, ElementC_, LayoutC_, Policy_, Stages, SharedMemoryClear, Enable>::IteratorA, cutlass::gemm::threadblock::MmaMultistage<Shape_, IteratorA_, SmemIteratorA_, CacheOpA, IteratorB_, SmemIteratorB_, CacheOpB, ElementC_, LayoutC_, Policy_, Stages, SharedMemoryClear, Enable>::IteratorB, const cutlass::gemm::threadblock::MmaMultistage<Shape_, IteratorA_, SmemIteratorA_, CacheOpA, IteratorB_, SmemIteratorB_, CacheOpB, ElementC_, LayoutC_, Policy_, Stages, SharedMemoryClear, Enable>::FragmentC &) [with Shape_=cutlass::gemm::GemmShape<256, 128, 64>, IteratorA_=cutlass::transform::threadblock::PredicatedTileAccessIterator<cutlass::MatrixShape<256, 64>, cutlass::half_t, cutlass::layout::RowMajor, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<64, 256>, 256, cutlass::PitchLinearShape<8, 4>, 8>, cutlass::Array<cutlass::half_t, 8, false>, false, cutlass::layout::NoPermute>, SmemIteratorA_=cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<256, 64>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCrosswise<16, 64>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<64, 256>, 256, cutlass::PitchLinearShape<8, 4>, 8>, 16>, CacheOpA=cutlass::arch::CacheOperation::Global, IteratorB_=cutlass::transform::threadblock::PredicatedTileAccessIterator<cutlass::MatrixShape<64, 128>, cutlass::half_t, cutlass::layout::RowMajor, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<128, 64>, 256, cutlass::PitchLinearShape<8, 4>, 8>, cutlass::Array<cutlass::half_t, 1, false>, false, cutlass::layout::NoPermute>, SmemIteratorB_=cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 128>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<16, 64>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<128, 64>, 256, cutlass::PitchLinearShape<8, 4>, 8>, 16>, CacheOpB=cutlass::arch::CacheOperation::Always, ElementC_=cutlass::half_t, LayoutC_=cutlass::layout::RowMajor, Policy_=cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 64>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCrosswise<16, 64>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<16, 64>, cutlass::half_t, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 16>, 32, cutlass::half_t, cutlass::layout::RowMajor, cutlass::half_t, cutlass::layout::ColumnMajor, cutlass::half_t, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1>>, 1, false, __nv_bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, Stages=3, SharedMemoryClear=cutlass::gemm::SharedMemoryClearOption::kNone, Enable=__nv_bool]" 
/fsx/quentin/jacob/gpt-neox-stuff/GEMMs_project/transformer_sizing/experiments/scripts/cutlass/python/cutlass/../..//include/cutlass/gemm/kernel/gemm_universal.h(573): here
            instantiation of "void cutlass::gemm::kernel::GemmUniversal<Mma_, Epilogue_, ThreadblockSwizzle_, void, std::enable_if_t<<expression>, void>>::operator()(const cutlass::gemm::kernel::GemmUniversal<Mma_, Epilogue_, ThreadblockSwizzle_, void, std::enable_if_t<<expression>, void>>::Params &, cutlass::gemm::kernel::GemmUniversal<Mma_, Epilogue_, ThreadblockSwizzle_, void, std::enable_if_t<<expression>, void>>::SharedStorage &) [with Mma_=cutlass::gemm::threadblock::MmaMultistage<cutlass::gemm::GemmShape<256, 128, 64>, cutlass::transform::threadblock::PredicatedTileAccessIterator<cutlass::MatrixShape<256, 64>, cutlass::half_t, cutlass::layout::RowMajor, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<64, 256>, 256, cutlass::PitchLinearShape<8, 4>, 8>, cutlass::Array<cutlass::half_t, 8, false>, false, cutlass::layout::NoPermute>, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<256, 64>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCrosswise<16, 64>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<64, 256>, 256, cutlass::PitchLinearShape<8, 4>, 8>, 16>, cutlass::arch::CacheOperation::Global, cutlass::transform::threadblock::PredicatedTileAccessIterator<cutlass::MatrixShape<64, 128>, cutlass::half_t, cutlass::layout::RowMajor, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<128, 64>, 256, cutlass::PitchLinearShape<8, 4>, 8>, cutlass::Array<cutlass::half_t, 1, false>, false, cutlass::layout::NoPermute>, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 128>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<16, 64>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<128, 64>, 256, cutlass::PitchLinearShape<8, 4>, 8>, 16>, cutlass::arch::CacheOperation::Always, cutlass::half_t, cutlass::layout::RowMajor, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 64>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCrosswise<16, 64>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<16, 64>, cutlass::half_t, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 16>, 32, cutlass::half_t, cutlass::layout::RowMajor, cutlass::half_t, cutlass::layout::ColumnMajor, cutlass::half_t, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1>>, 1, false, __nv_bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 3, cutlass::gemm::SharedMemoryClearOption::kNone, __nv_bool>, Epilogue_=cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<256, 128, 64>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 64>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCrosswise<16, 64>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<16, 64>, cutlass::half_t, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 16>, 32, cutlass::half_t, cutlass::layout::RowMajor, cutlass::half_t, cutlass::layout::ColumnMajor, cutlass::half_t, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1>>, 1, false, __nv_bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<128, 8, 4, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 16>, cutlass::half_t, false, cutlass::layout::NoPermute, false>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 64>, cutlass::gemm::GemmShape<16, 8, 16>, cutlass::half_t, cutlass::Array<cutlass::half_t, 4, false>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 64>, cutlass::gemm::GemmShape<16, 8, 16>, cutlass::half_t, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<128, 8, 4, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 16>::CompactedThreadMap, cutlass::half_t, 2>, cutlass::epilogue::thread::LinearCombination<cutlass::half_t, 1, cutlass::half_t, cutlass::half_t, cutlass::epilogue::thread::ScaleType::Default, cutlass::FloatRoundStyle::round_to_nearest, cutlass::half_t>, cutlass::MatrixShape<0, 16>, 1, 1>, ThreadblockSwizzle_=cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<1>]" 
/fsx/quentin/jacob/gpt-neox-stuff/GEMMs_project/transformer_sizing/experiments/scripts/cutlass/python/cutlass/../..//include/cutlass/gemm/kernel/gemm_universal.h(462): here
            instantiation of "void cutlass::gemm::kernel::GemmUniversal<Mma_, Epilogue_, ThreadblockSwizzle_, void, std::enable_if_t<<expression>, void>>::invoke(const cutlass::gemm::kernel::GemmUniversal<Mma_, Epilogue_, ThreadblockSwizzle_, void, std::enable_if_t<<expression>, void>>::Params &, cutlass::gemm::kernel::GemmUniversal<Mma_, Epilogue_, ThreadblockSwizzle_, void, std::enable_if_t<<expression>, void>>::SharedStorage &) [with Mma_=cutlass::gemm::threadblock::MmaMultistage<cutlass::gemm::GemmShape<256, 128, 64>, cutlass::transform::threadblock::PredicatedTileAccessIterator<cutlass::MatrixShape<256, 64>, cutlass::half_t, cutlass::layout::RowMajor, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<64, 256>, 256, cutlass::PitchLinearShape<8, 4>, 8>, cutlass::Array<cutlass::half_t, 8, false>, false, cutlass::layout::NoPermute>, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<256, 64>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCrosswise<16, 64>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<64, 256>, 256, cutlass::PitchLinearShape<8, 4>, 8>, 16>, cutlass::arch::CacheOperation::Global, cutlass::transform::threadblock::PredicatedTileAccessIterator<cutlass::MatrixShape<64, 128>, cutlass::half_t, cutlass::layout::RowMajor, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<128, 64>, 256, cutlass::PitchLinearShape<8, 4>, 8>, cutlass::Array<cutlass::half_t, 1, false>, false, cutlass::layout::NoPermute>, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 128>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<16, 64>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<128, 64>, 256, cutlass::PitchLinearShape<8, 4>, 8>, 16>, cutlass::arch::CacheOperation::Always, cutlass::half_t, cutlass::layout::RowMajor, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 64>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCrosswise<16, 64>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<16, 64>, cutlass::half_t, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 16>, 32, cutlass::half_t, cutlass::layout::RowMajor, cutlass::half_t, cutlass::layout::ColumnMajor, cutlass::half_t, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1>>, 1, false, __nv_bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 3, cutlass::gemm::SharedMemoryClearOption::kNone, __nv_bool>, Epilogue_=cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<256, 128, 64>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 64>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCrosswise<16, 64>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<16, 64>, cutlass::half_t, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 16>, 32, cutlass::half_t, cutlass::layout::RowMajor, cutlass::half_t, cutlass::layout::ColumnMajor, cutlass::half_t, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1>>, 1, false, __nv_bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<128, 8, 4, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 16>, cutlass::half_t, false, cutlass::layout::NoPermute, false>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 64>, cutlass::gemm::GemmShape<16, 8, 16>, cutlass::half_t, cutlass::Array<cutlass::half_t, 4, false>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 64>, cutlass::gemm::GemmShape<16, 8, 16>, cutlass::half_t, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<128, 8, 4, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 16>::CompactedThreadMap, cutlass::half_t, 2>, cutlass::epilogue::thread::LinearCombination<cutlass::half_t, 1, cutlass::half_t, cutlass::half_t, cutlass::epilogue::thread::ScaleType::Default, cutlass::FloatRoundStyle::round_to_nearest, cutlass::half_t>, cutlass::MatrixShape<0, 16>, 1, 1>, ThreadblockSwizzle_=cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<1>]" 
/fsx/quentin/jacob/gpt-neox-stuff/GEMMs_project/transformer_sizing/experiments/scripts/kernel3_0lrcn6.cu(43): here

/fsx/quentin/jacob/gpt-neox-stuff/GEMMs_project/transformer_sizing/experiments/scripts/cutlass/python/cutlass/../..//include/cutlass/arch/memory_sm80.h(119): error: static assertion failed with "Size is not supported"
          detected during:
            instantiation of "cutlass::arch::cp_async<SizeInBytes, cutlass::arch::CacheOperation::Always>::cp_async(void *, const void *, __nv_bool) [with SizeInBytes=2]" 
/fsx/quentin/jacob/gpt-neox-stuff/GEMMs_project/transformer_sizing/experiments/scripts/cutlass/python/cutlass/../..//include/cutlass/gemm/threadblock/mma_multistage.h(350): here
            instantiation of "void cutlass::gemm::threadblock::MmaMultistage<Shape_, IteratorA_, SmemIteratorA_, CacheOpA, IteratorB_, SmemIteratorB_, CacheOpB, ElementC_, LayoutC_, Policy_, Stages, SharedMemoryClear, Enable>::copy_tiles_and_advance(cutlass::gemm::threadblock::MmaMultistage<Shape_, IteratorA_, SmemIteratorA_, CacheOpA, IteratorB_, SmemIteratorB_, CacheOpB, ElementC_, LayoutC_, Policy_, Stages, SharedMemoryClear, Enable>::IteratorA &, cutlass::gemm::threadblock::MmaMultistage<Shape_, IteratorA_, SmemIteratorA_, CacheOpA, IteratorB_, SmemIteratorB_, CacheOpB, ElementC_, LayoutC_, Policy_, Stages, SharedMemoryClear, Enable>::IteratorB &, int, int) [with Shape_=cutlass::gemm::GemmShape<256, 128, 64>, IteratorA_=cutlass::transform::threadblock::PredicatedTileAccessIterator<cutlass::MatrixShape<256, 64>, cutlass::half_t, cutlass::layout::RowMajor, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<64, 256>, 256, cutlass::PitchLinearShape<8, 4>, 8>, cutlass::Array<cutlass::half_t, 8, false>, false, cutlass::layout::NoPermute>, SmemIteratorA_=cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<256, 64>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCrosswise<16, 64>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<64, 256>, 256, cutlass::PitchLinearShape<8, 4>, 8>, 16>, CacheOpA=cutlass::arch::CacheOperation::Global, IteratorB_=cutlass::transform::threadblock::PredicatedTileAccessIterator<cutlass::MatrixShape<64, 128>, cutlass::half_t, cutlass::layout::RowMajor, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<128, 64>, 256, cutlass::PitchLinearShape<8, 4>, 8>, cutlass::Array<cutlass::half_t, 1, false>, false, cutlass::layout::NoPermute>, SmemIteratorB_=cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 128>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<16, 64>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<128, 64>, 256, cutlass::PitchLinearShape<8, 4>, 8>, 16>, CacheOpB=cutlass::arch::CacheOperation::Always, ElementC_=cutlass::half_t, LayoutC_=cutlass::layout::RowMajor, Policy_=cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 64>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCrosswise<16, 64>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<16, 64>, cutlass::half_t, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 16>, 32, cutlass::half_t, cutlass::layout::RowMajor, cutlass::half_t, cutlass::layout::ColumnMajor, cutlass::half_t, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1>>, 1, false, __nv_bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, Stages=3, SharedMemoryClear=cutlass::gemm::SharedMemoryClearOption::kNone, Enable=__nv_bool]" 
/fsx/quentin/jacob/gpt-neox-stuff/GEMMs_project/transformer_sizing/experiments/scripts/cutlass/python/cutlass/../..//include/cutlass/gemm/threadblock/mma_multistage.h(557): here
            instantiation of "void cutlass::gemm::threadblock::MmaMultistage<Shape_, IteratorA_, SmemIteratorA_, CacheOpA, IteratorB_, SmemIteratorB_, CacheOpB, ElementC_, LayoutC_, Policy_, Stages, SharedMemoryClear, Enable>::mac_loop_iter(cutlass::gemm::threadblock::MmaMultistage<Shape_, IteratorA_, SmemIteratorA_, CacheOpA, IteratorB_, SmemIteratorB_, CacheOpB, ElementC_, LayoutC_, Policy_, Stages, SharedMemoryClear, Enable>::PipeState &, cutlass::gemm::threadblock::MmaMultistage<Shape_, IteratorA_, SmemIteratorA_, CacheOpA, IteratorB_, SmemIteratorB_, CacheOpB, ElementC_, LayoutC_, Policy_, Stages, SharedMemoryClear, Enable>::FragmentC &, cutlass::gemm::threadblock::MmaMultistage<Shape_, IteratorA_, SmemIteratorA_, CacheOpA, IteratorB_, SmemIteratorB_, CacheOpB, ElementC_, LayoutC_, Policy_, Stages, SharedMemoryClear, Enable>::IteratorA &, cutlass::gemm::threadblock::MmaMultistage<Shape_, IteratorA_, SmemIteratorA_, CacheOpA, IteratorB_, SmemIteratorB_, CacheOpB, ElementC_, LayoutC_, Policy_, Stages, SharedMemoryClear, Enable>::IteratorB &, int &) [with Shape_=cutlass::gemm::GemmShape<256, 128, 64>, IteratorA_=cutlass::transform::threadblock::PredicatedTileAccessIterator<cutlass::MatrixShape<256, 64>, cutlass::half_t, cutlass::layout::RowMajor, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<64, 256>, 256, cutlass::PitchLinearShape<8, 4>, 8>, cutlass::Array<cutlass::half_t, 8, false>, false, cutlass::layout::NoPermute>, SmemIteratorA_=cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<256, 64>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCrosswise<16, 64>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<64, 256>, 256, cutlass::PitchLinearShape<8, 4>, 8>, 16>, CacheOpA=cutlass::arch::CacheOperation::Global, IteratorB_=cutlass::transform::threadblock::PredicatedTileAccessIterator<cutlass::MatrixShape<64, 128>, cutlass::half_t, cutlass::layout::RowMajor, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<128, 64>, 256, cutlass::PitchLinearShape<8, 4>, 8>, cutlass::Array<cutlass::half_t, 1, false>, false, cutlass::layout::NoPermute>, SmemIteratorB_=cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 128>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<16, 64>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<128, 64>, 256, cutlass::PitchLinearShape<8, 4>, 8>, 16>, CacheOpB=cutlass::arch::CacheOperation::Always, ElementC_=cutlass::half_t, LayoutC_=cutlass::layout::RowMajor, Policy_=cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 64>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCrosswise<16, 64>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<16, 64>, cutlass::half_t, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 16>, 32, cutlass::half_t, cutlass::layout::RowMajor, cutlass::half_t, cutlass::layout::ColumnMajor, cutlass::half_t, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1>>, 1, false, __nv_bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, Stages=3, SharedMemoryClear=cutlass::gemm::SharedMemoryClearOption::kNone, Enable=__nv_bool]" 
/fsx/quentin/jacob/gpt-neox-stuff/GEMMs_project/transformer_sizing/experiments/scripts/cutlass/python/cutlass/../..//include/cutlass/gemm/threadblock/mma_multistage.h(650): here
            instantiation of "void cutlass::gemm::threadblock::MmaMultistage<Shape_, IteratorA_, SmemIteratorA_, CacheOpA, IteratorB_, SmemIteratorB_, CacheOpB, ElementC_, LayoutC_, Policy_, Stages, SharedMemoryClear, Enable>::gemm_iters(int, cutlass::gemm::threadblock::MmaMultistage<Shape_, IteratorA_, SmemIteratorA_, CacheOpA, IteratorB_, SmemIteratorB_, CacheOpB, ElementC_, LayoutC_, Policy_, Stages, SharedMemoryClear, Enable>::FragmentC &, cutlass::gemm::threadblock::MmaMultistage<Shape_, IteratorA_, SmemIteratorA_, CacheOpA, IteratorB_, SmemIteratorB_, CacheOpB, ElementC_, LayoutC_, Policy_, Stages, SharedMemoryClear, Enable>::IteratorA &, cutlass::gemm::threadblock::MmaMultistage<Shape_, IteratorA_, SmemIteratorA_, CacheOpA, IteratorB_, SmemIteratorB_, CacheOpB, ElementC_, LayoutC_, Policy_, Stages, SharedMemoryClear, Enable>::IteratorB &) [with Shape_=cutlass::gemm::GemmShape<256, 128, 64>, IteratorA_=cutlass::transform::threadblock::PredicatedTileAccessIterator<cutlass::MatrixShape<256, 64>, cutlass::half_t, cutlass::layout::RowMajor, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<64, 256>, 256, cutlass::PitchLinearShape<8, 4>, 8>, cutlass::Array<cutlass::half_t, 8, false>, false, cutlass::layout::NoPermute>, SmemIteratorA_=cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<256, 64>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCrosswise<16, 64>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<64, 256>, 256, cutlass::PitchLinearShape<8, 4>, 8>, 16>, CacheOpA=cutlass::arch::CacheOperation::Global, IteratorB_=cutlass::transform::threadblock::PredicatedTileAccessIterator<cutlass::MatrixShape<64, 128>, cutlass::half_t, cutlass::layout::RowMajor, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<128, 64>, 256, cutlass::PitchLinearShape<8, 4>, 8>, cutlass::Array<cutlass::half_t, 1, false>, false, cutlass::layout::NoPermute>, SmemIteratorB_=cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 128>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<16, 64>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<128, 64>, 256, cutlass::PitchLinearShape<8, 4>, 8>, 16>, CacheOpB=cutlass::arch::CacheOperation::Always, ElementC_=cutlass::half_t, LayoutC_=cutlass::layout::RowMajor, Policy_=cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 64>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCrosswise<16, 64>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<16, 64>, cutlass::half_t, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 16>, 32, cutlass::half_t, cutlass::layout::RowMajor, cutlass::half_t, cutlass::layout::ColumnMajor, cutlass::half_t, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1>>, 1, false, __nv_bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, Stages=3, SharedMemoryClear=cutlass::gemm::SharedMemoryClearOption::kNone, Enable=__nv_bool]" 
/fsx/quentin/jacob/gpt-neox-stuff/GEMMs_project/transformer_sizing/experiments/scripts/cutlass/python/cutlass/../..//include/cutlass/gemm/threadblock/mma_multistage.h(730): here
            instantiation of "void cutlass::gemm::threadblock::MmaMultistage<Shape_, IteratorA_, SmemIteratorA_, CacheOpA, IteratorB_, SmemIteratorB_, CacheOpB, ElementC_, LayoutC_, Policy_, Stages, SharedMemoryClear, Enable>::operator()(int, cutlass::gemm::threadblock::MmaMultistage<Shape_, IteratorA_, SmemIteratorA_, CacheOpA, IteratorB_, SmemIteratorB_, CacheOpB, ElementC_, LayoutC_, Policy_, Stages, SharedMemoryClear, Enable>::FragmentC &, cutlass::gemm::threadblock::MmaMultistage<Shape_, IteratorA_, SmemIteratorA_, CacheOpA, IteratorB_, SmemIteratorB_, CacheOpB, ElementC_, LayoutC_, Policy_, Stages, SharedMemoryClear, Enable>::IteratorA, cutlass::gemm::threadblock::MmaMultistage<Shape_, IteratorA_, SmemIteratorA_, CacheOpA, IteratorB_, SmemIteratorB_, CacheOpB, ElementC_, LayoutC_, Policy_, Stages, SharedMemoryClear, Enable>::IteratorB, const cutlass::gemm::threadblock::MmaMultistage<Shape_, IteratorA_, SmemIteratorA_, CacheOpA, IteratorB_, SmemIteratorB_, CacheOpB, ElementC_, LayoutC_, Policy_, Stages, SharedMemoryClear, Enable>::FragmentC &) [with Shape_=cutlass::gemm::GemmShape<256, 128, 64>, IteratorA_=cutlass::transform::threadblock::PredicatedTileAccessIterator<cutlass::MatrixShape<256, 64>, cutlass::half_t, cutlass::layout::RowMajor, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<64, 256>, 256, cutlass::PitchLinearShape<8, 4>, 8>, cutlass::Array<cutlass::half_t, 8, false>, false, cutlass::layout::NoPermute>, SmemIteratorA_=cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<256, 64>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCrosswise<16, 64>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<64, 256>, 256, cutlass::PitchLinearShape<8, 4>, 8>, 16>, CacheOpA=cutlass::arch::CacheOperation::Global, IteratorB_=cutlass::transform::threadblock::PredicatedTileAccessIterator<cutlass::MatrixShape<64, 128>, cutlass::half_t, cutlass::layout::RowMajor, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<128, 64>, 256, cutlass::PitchLinearShape<8, 4>, 8>, cutlass::Array<cutlass::half_t, 1, false>, false, cutlass::layout::NoPermute>, SmemIteratorB_=cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 128>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<16, 64>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<128, 64>, 256, cutlass::PitchLinearShape<8, 4>, 8>, 16>, CacheOpB=cutlass::arch::CacheOperation::Always, ElementC_=cutlass::half_t, LayoutC_=cutlass::layout::RowMajor, Policy_=cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 64>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCrosswise<16, 64>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<16, 64>, cutlass::half_t, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 16>, 32, cutlass::half_t, cutlass::layout::RowMajor, cutlass::half_t, cutlass::layout::ColumnMajor, cutlass::half_t, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1>>, 1, false, __nv_bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, Stages=3, SharedMemoryClear=cutlass::gemm::SharedMemoryClearOption::kNone, Enable=__nv_bool]" 
/fsx/quentin/jacob/gpt-neox-stuff/GEMMs_project/transformer_sizing/experiments/scripts/cutlass/python/cutlass/../..//include/cutlass/gemm/kernel/gemm_universal.h(573): here
            instantiation of "void cutlass::gemm::kernel::GemmUniversal<Mma_, Epilogue_, ThreadblockSwizzle_, void, std::enable_if_t<<expression>, void>>::operator()(const cutlass::gemm::kernel::GemmUniversal<Mma_, Epilogue_, ThreadblockSwizzle_, void, std::enable_if_t<<expression>, void>>::Params &, cutlass::gemm::kernel::GemmUniversal<Mma_, Epilogue_, ThreadblockSwizzle_, void, std::enable_if_t<<expression>, void>>::SharedStorage &) [with Mma_=cutlass::gemm::threadblock::MmaMultistage<cutlass::gemm::GemmShape<256, 128, 64>, cutlass::transform::threadblock::PredicatedTileAccessIterator<cutlass::MatrixShape<256, 64>, cutlass::half_t, cutlass::layout::RowMajor, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<64, 256>, 256, cutlass::PitchLinearShape<8, 4>, 8>, cutlass::Array<cutlass::half_t, 8, false>, false, cutlass::layout::NoPermute>, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<256, 64>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCrosswise<16, 64>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<64, 256>, 256, cutlass::PitchLinearShape<8, 4>, 8>, 16>, cutlass::arch::CacheOperation::Global, cutlass::transform::threadblock::PredicatedTileAccessIterator<cutlass::MatrixShape<64, 128>, cutlass::half_t, cutlass::layout::RowMajor, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<128, 64>, 256, cutlass::PitchLinearShape<8, 4>, 8>, cutlass::Array<cutlass::half_t, 1, false>, false, cutlass::layout::NoPermute>, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 128>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<16, 64>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<128, 64>, 256, cutlass::PitchLinearShape<8, 4>, 8>, 16>, cutlass::arch::CacheOperation::Always, cutlass::half_t, cutlass::layout::RowMajor, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 64>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCrosswise<16, 64>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<16, 64>, cutlass::half_t, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 16>, 32, cutlass::half_t, cutlass::layout::RowMajor, cutlass::half_t, cutlass::layout::ColumnMajor, cutlass::half_t, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1>>, 1, false, __nv_bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 3, cutlass::gemm::SharedMemoryClearOption::kNone, __nv_bool>, Epilogue_=cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<256, 128, 64>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 64>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCrosswise<16, 64>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<16, 64>, cutlass::half_t, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 16>, 32, cutlass::half_t, cutlass::layout::RowMajor, cutlass::half_t, cutlass::layout::ColumnMajor, cutlass::half_t, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1>>, 1, false, __nv_bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<128, 8, 4, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 16>, cutlass::half_t, false, cutlass::layout::NoPermute, false>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 64>, cutlass::gemm::GemmShape<16, 8, 16>, cutlass::half_t, cutlass::Array<cutlass::half_t, 4, false>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 64>, cutlass::gemm::GemmShape<16, 8, 16>, cutlass::half_t, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<128, 8, 4, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 16>::CompactedThreadMap, cutlass::half_t, 2>, cutlass::epilogue::thread::LinearCombination<cutlass::half_t, 1, cutlass::half_t, cutlass::half_t, cutlass::epilogue::thread::ScaleType::Default, cutlass::FloatRoundStyle::round_to_nearest, cutlass::half_t>, cutlass::MatrixShape<0, 16>, 1, 1>, ThreadblockSwizzle_=cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<1>]" 
/fsx/quentin/jacob/gpt-neox-stuff/GEMMs_project/transformer_sizing/experiments/scripts/cutlass/python/cutlass/../..//include/cutlass/gemm/kernel/gemm_universal.h(462): here
            instantiation of "void cutlass::gemm::kernel::GemmUniversal<Mma_, Epilogue_, ThreadblockSwizzle_, void, std::enable_if_t<<expression>, void>>::invoke(const cutlass::gemm::kernel::GemmUniversal<Mma_, Epilogue_, ThreadblockSwizzle_, void, std::enable_if_t<<expression>, void>>::Params &, cutlass::gemm::kernel::GemmUniversal<Mma_, Epilogue_, ThreadblockSwizzle_, void, std::enable_if_t<<expression>, void>>::SharedStorage &) [with Mma_=cutlass::gemm::threadblock::MmaMultistage<cutlass::gemm::GemmShape<256, 128, 64>, cutlass::transform::threadblock::PredicatedTileAccessIterator<cutlass::MatrixShape<256, 64>, cutlass::half_t, cutlass::layout::RowMajor, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<64, 256>, 256, cutlass::PitchLinearShape<8, 4>, 8>, cutlass::Array<cutlass::half_t, 8, false>, false, cutlass::layout::NoPermute>, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<256, 64>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCrosswise<16, 64>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<64, 256>, 256, cutlass::PitchLinearShape<8, 4>, 8>, 16>, cutlass::arch::CacheOperation::Global, cutlass::transform::threadblock::PredicatedTileAccessIterator<cutlass::MatrixShape<64, 128>, cutlass::half_t, cutlass::layout::RowMajor, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<128, 64>, 256, cutlass::PitchLinearShape<8, 4>, 8>, cutlass::Array<cutlass::half_t, 1, false>, false, cutlass::layout::NoPermute>, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 128>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<16, 64>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::PitchLinearShape<128, 64>, 256, cutlass::PitchLinearShape<8, 4>, 8>, 16>, cutlass::arch::CacheOperation::Always, cutlass::half_t, cutlass::layout::RowMajor, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 64>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCrosswise<16, 64>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<16, 64>, cutlass::half_t, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 16>, 32, cutlass::half_t, cutlass::layout::RowMajor, cutlass::half_t, cutlass::layout::ColumnMajor, cutlass::half_t, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1>>, 1, false, __nv_bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 3, cutlass::gemm::SharedMemoryClearOption::kNone, __nv_bool>, Epilogue_=cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<256, 128, 64>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 64>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCrosswise<16, 64>, cutlass::half_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<16, 64>, cutlass::half_t, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 16>, 32, cutlass::half_t, cutlass::layout::RowMajor, cutlass::half_t, cutlass::layout::ColumnMajor, cutlass::half_t, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1>>, 1, false, __nv_bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<128, 8, 4, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 16>, cutlass::half_t, false, cutlass::layout::NoPermute, false>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 64>, cutlass::gemm::GemmShape<16, 8, 16>, cutlass::half_t, cutlass::Array<cutlass::half_t, 4, false>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 64>, cutlass::gemm::GemmShape<16, 8, 16>, cutlass::half_t, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<128, 8, 4, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 16>::CompactedThreadMap, cutlass::half_t, 2>, cutlass::epilogue::thread::LinearCombination<cutlass::half_t, 1, cutlass::half_t, cutlass::half_t, cutlass::epilogue::thread::ScaleType::Default, cutlass::FloatRoundStyle::round_to_nearest, cutlass::half_t>, cutlass::MatrixShape<0, 16>, 1, 1>, ThreadblockSwizzle_=cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<1>]" 
/fsx/quentin/jacob/gpt-neox-stuff/GEMMs_project/transformer_sizing/experiments/scripts/kernel3_0lrcn6.cu(43): here

2 errors detected in the compilation of "/fsx/quentin/jacob/gpt-neox-stuff/GEMMs_project/transformer_sizing/experiments/scripts/kernel3_0lrcn6.cu".

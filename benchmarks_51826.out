1.13.1 

[2023-11-20 17:11:32,043] [INFO] [distributed.py:36:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...
[2023-11-20 17:11:32,821] [INFO] [distributed.py:83:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=26.0.144.211, master_port=6000
[2023-11-20 17:11:32,821] [INFO] [distributed.py:46:init_distributed] Initializing torch distributed with backend: nccl
[2023-11-20 17:11:35,949] [INFO] [checkpointing.py:223:model_parallel_cuda_manual_seed] > initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234
num_attention_heads: 20, hidden_size: 2560, train_micro_batch_size_per_gpu: 4, tensor_mp_size: 1, pipeline_mp_size: 1, dp_size: 1


Actual
------
QKV Transform: 2.2935431003570557
using-flash
Attention linproj: 0.0068302154541015625
QKV Transform: 0.0025315284729003906
using-flash
Attention linproj: 0.0005497932434082031
QKV Transform: 0.002099752426147461
using-flash
Attention linproj: 0.0005397796630859375
QKV Transform: 0.002203226089477539
using-flash
Attention linproj: 0.0005326271057128906
QKV Transform: 0.002100706100463867
using-flash
Attention linproj: 0.0005319118499755859
QKV Transform: 0.002194643020629883
using-flash
Attention linproj: 0.0005285739898681641
QKV Transform: 0.0022051334381103516
using-flash
Attention linproj: 0.0005309581756591797
QKV Transform: 0.002261638641357422
using-flash
Attention linproj: 0.0005290508270263672
QKV Transform: 0.0022644996643066406
using-flash
Attention linproj: 0.0005307197570800781
QKV Transform: 0.0022056102752685547
using-flash
Attention linproj: 0.000545501708984375
QKV Transform: 0.0022215843200683594
using-flash
Attention linproj: 0.0005359649658203125
QKV Transform: 0.0021631717681884766
using-flash
Attention linproj: 0.0005736351013183594
QKV Transform: 0.0025277137756347656
using-flash
Attention linproj: 0.0005366802215576172
QKV Transform: 0.0021715164184570312
using-flash
Attention linproj: 0.0005390644073486328
QKV Transform: 0.002094268798828125
using-flash
Attention linproj: 0.000530242919921875
QKV Transform: 0.002180337905883789
using-flash
Attention linproj: 0.0005326271057128906
QKV Transform: 0.002150297164916992
using-flash
Attention linproj: 0.0005300045013427734
QKV Transform: 0.0021309852600097656
using-flash
Attention linproj: 0.0005314350128173828
QKV Transform: 0.002238035202026367
using-flash
Attention linproj: 0.0005288124084472656
QKV Transform: 0.0022611618041992188
using-flash
Attention linproj: 0.0005309581756591797
QKV Transform: 0.002292633056640625
using-flash
Attention linproj: 0.0005345344543457031
QKV Transform: 0.0021758079528808594
using-flash
Attention linproj: 0.0005371570587158203
QKV Transform: 0.0029397010803222656
using-flash
Attention linproj: 0.0005285739898681641
QKV Transform: 0.002133607864379883
using-flash
Attention linproj: 0.0005314350128173828
QKV Transform: 0.002216339111328125
using-flash
Attention linproj: 0.0005300045013427734
QKV Transform: 0.002207517623901367
using-flash
Attention linproj: 0.0005331039428710938
QKV Transform: 0.0022933483123779297
using-flash
Attention linproj: 0.0005364418029785156
QKV Transform: 0.002293825149536133
using-flash
Attention linproj: 0.0005366802215576172
QKV Transform: 0.0022516250610351562
using-flash
Attention linproj: 0.0005359649658203125
QKV Transform: 0.0021970272064208984
using-flash
Attention linproj: 0.0005393028259277344
QKV Transform: 0.0021660327911376953
using-flash
Attention linproj: 0.0005309581756591797
QKV Transform: 0.002161741256713867
using-flash
Attention linproj: 0.0005292892456054688
QKV Transform: 0.002085447311401367
using-flash
Attention linproj: 0.0005300045013427734
QKV Transform: 0.001965761184692383
using-flash
Attention linproj: 0.0005297660827636719
QKV Transform: 0.0021419525146484375
using-flash
Attention linproj: 0.0005300045013427734
QKV Transform: 0.0022835731506347656
using-flash
Attention linproj: 0.0005300045013427734
QKV Transform: 0.0022902488708496094
using-flash
Attention linproj: 0.0005464553833007812
QKV Transform: 0.002212047576904297
using-flash
Attention linproj: 0.0005197525024414062
QKV Transform: 0.002223491668701172
using-flash
Attention linproj: 0.0005342960357666016
QKV Transform: 0.002292633056640625
using-flash
Attention linproj: 0.0005249977111816406
QKV Transform: 0.002217531204223633
using-flash
Attention linproj: 0.0005402565002441406
QKV Transform: 0.0022459030151367188
using-flash
Attention linproj: 0.0005385875701904297
QKV Transform: 0.0021135807037353516
using-flash
Attention linproj: 0.0005409717559814453
QKV Transform: 0.002129077911376953
using-flash
Attention linproj: 0.0005314350128173828
QKV Transform: 0.00212860107421875
using-flash
Attention linproj: 0.0005290508270263672
QKV Transform: 0.0020880699157714844
using-flash
Attention linproj: 0.0005290508270263672
QKV Transform: 0.002305269241333008
using-flash
Attention linproj: 0.0005359649658203125
QKV Transform: 0.0022115707397460938
using-flash
Attention linproj: 0.0005371570587158203
QKV Transform: 0.0022149085998535156
using-flash
Attention linproj: 0.0005311965942382812
QKV Transform: 0.0022177696228027344
using-flash
Attention linproj: 0.0005307197570800781
QKV Transform: 0.0019495487213134766
using-flash
Attention linproj: 0.0005345344543457031
QKV Transform: 0.0021331310272216797
using-flash
Attention linproj: 0.0005311965942382812
QKV Transform: 0.0022084712982177734
using-flash
Attention linproj: 0.0005295276641845703
QKV Transform: 0.002137422561645508
using-flash
Attention linproj: 0.0005297660827636719
QKV Transform: 0.0022525787353515625
using-flash
Attention linproj: 0.0005321502685546875
QKV Transform: 0.002262115478515625
using-flash
Attention linproj: 0.0005357265472412109
QKV Transform: 0.002220630645751953
using-flash
Attention linproj: 0.0005373954772949219
QKV Transform: 0.0022602081298828125
using-flash
Attention linproj: 0.0005357265472412109
QKV Transform: 0.0021643638610839844
using-flash
Attention linproj: 0.0005476474761962891
QKV Transform: 0.002218484878540039
using-flash
Attention linproj: 0.0005311965942382812
QKV Transform: 0.0021524429321289062
using-flash
Attention linproj: 0.0005314350128173828
QKV Transform: 0.0021867752075195312
using-flash
Attention linproj: 0.0005314350128173828
QKV Transform: 0.002172708511352539
using-flash
Attention linproj: 0.0005295276641845703
QKV Transform: 0.0021691322326660156
using-flash
Attention linproj: 0.0005295276641845703
QKV Transform: 0.0022563934326171875
using-flash
Attention linproj: 0.0005333423614501953
QKV Transform: 0.0021719932556152344
using-flash
Attention linproj: 0.0005292892456054688
QKV Transform: 0.0021049976348876953
using-flash
Attention linproj: 0.0005307197570800781
QKV Transform: 0.002215147018432617
using-flash
Attention linproj: 0.0005321502685546875
QKV Transform: 0.006205558776855469
using-flash
Attention linproj: 0.0005316734313964844
QKV Transform: 0.002298593521118164
using-flash
Attention linproj: 0.00052642822265625
QKV Transform: 0.002238750457763672
using-flash
Attention linproj: 0.0005390644073486328
QKV Transform: 0.002241849899291992
using-flash
Attention linproj: 0.0005373954772949219
QKV Transform: 0.0021491050720214844
using-flash
Attention linproj: 0.0005285739898681641
QKV Transform: 0.0022115707397460938
using-flash
Attention linproj: 0.0005316734313964844
QKV Transform: 0.002123594284057617
using-flash
Attention linproj: 0.0005304813385009766
QKV Transform: 0.0021872520446777344
using-flash
Attention linproj: 0.0005419254302978516
QKV Transform: 0.0021734237670898438
using-flash
Attention linproj: 0.0005292892456054688
QKV Transform: 0.0022335052490234375
using-flash
Attention linproj: 0.0005397796630859375
QKV Transform: 0.002257108688354492
using-flash
Attention linproj: 0.0005328655242919922
QKV Transform: 0.002222776412963867
using-flash
Attention linproj: 0.0005362033843994141
QKV Transform: 0.002269744873046875
using-flash
Attention linproj: 0.0005314350128173828
QKV Transform: 0.0024900436401367188
using-flash
Attention linproj: 0.0005486011505126953
QKV Transform: 0.0021860599517822266
using-flash
Attention linproj: 0.0005321502685546875
QKV Transform: 0.0021257400512695312
using-flash
Attention linproj: 0.0005328655242919922
QKV Transform: 0.002088785171508789
using-flash
Attention linproj: 0.0005300045013427734
QKV Transform: 0.0021431446075439453
using-flash
Attention linproj: 0.0005295276641845703
QKV Transform: 0.002117633819580078
using-flash
Attention linproj: 0.0005292892456054688
QKV Transform: 0.0022978782653808594
using-flash
Attention linproj: 0.0005316734313964844
QKV Transform: 0.0022821426391601562
using-flash
Attention linproj: 0.0005335807800292969
QKV Transform: 0.002240896224975586
using-flash
Attention linproj: 0.0005276203155517578
QKV Transform: 0.0022363662719726562
using-flash
Attention linproj: 0.0005371570587158203
QKV Transform: 0.0021893978118896484
using-flash
Attention linproj: 0.0005366802215576172
QKV Transform: 0.0022144317626953125
using-flash
Attention linproj: 0.0005400180816650391
QKV Transform: 0.0021538734436035156
using-flash
Attention linproj: 0.0005307197570800781
QKV Transform: 0.0021047592163085938
using-flash
Attention linproj: 0.0005183219909667969
QKV Transform: 0.002176523208618164
using-flash
Attention linproj: 0.0005316734313964844
QKV Transform: 0.0021326541900634766
using-flash
Attention linproj: 0.0005300045013427734
QKV Transform: 0.002281665802001953
using-flash
Attention linproj: 0.0005304813385009766
QKV Transform: 0.0022394657135009766
using-flash
Attention linproj: 0.0005338191986083984
QKV Transform: 0.0023179054260253906
using-flash
Attention linproj: 0.000537872314453125
QKV Transform: 0.0022552013397216797
using-flash
Attention linproj: 0.0005376338958740234
QKV Transform: 0.0022554397583007812
using-flash
Attention linproj: 0.0005357265472412109
QKV Transform: 0.0021970272064208984
using-flash
Attention linproj: 0.0005383491516113281
QKV Transform: 0.0021271705627441406
using-flash
Attention linproj: 0.0005311965942382812
QKV Transform: 0.002131223678588867
using-flash
Attention linproj: 0.0005311965942382812
QKV Transform: 0.0020990371704101562
using-flash
Attention linproj: 0.0005304813385009766
QKV Transform: 0.0022122859954833984
using-flash
Attention linproj: 0.0005304813385009766
QKV Transform: 0.002184152603149414
using-flash
Attention linproj: 0.0005300045013427734
QKV Transform: 0.002298593521118164
using-flash
Attention linproj: 0.0005316734313964844
QKV Transform: 0.002313375473022461
using-flash
Attention linproj: 0.0005354881286621094
QKV Transform: 0.002252340316772461
using-flash
Attention linproj: 0.0005376338958740234
QKV Transform: 0.002240896224975586
using-flash
Attention linproj: 0.000537872314453125
QKV Transform: 0.0021119117736816406
using-flash
Attention linproj: 0.0005373954772949219
QKV Transform: 0.0021457672119140625
using-flash
Attention linproj: 0.0005314350128173828
QKV Transform: 0.002161264419555664
using-flash
Attention linproj: 0.0005309581756591797
QKV Transform: 0.001962900161743164
using-flash
Attention linproj: 0.0005295276641845703
QKV Transform: 0.0021893978118896484
using-flash
Attention linproj: 0.000530242919921875
QKV Transform: 0.0021691322326660156
using-flash
Attention linproj: 0.0005297660827636719
QKV Transform: 0.002276897430419922
using-flash
Attention linproj: 0.0005326271057128906
QKV Transform: 0.0022792816162109375
using-flash
Attention linproj: 0.0005323886871337891
QKV Transform: 0.002293109893798828
using-flash
Attention linproj: 0.000537872314453125
QKV Transform: 0.0022826194763183594
using-flash
Attention linproj: 0.0005474090576171875
QKV Transform: 0.0022034645080566406
using-flash
Attention linproj: 0.0005366802215576172
QKV Transform: 0.0021820068359375
using-flash
Attention linproj: 0.0005316734313964844
QKV Transform: 0.0025446414947509766
using-flash
Attention linproj: 0.0005371570587158203
QKV Transform: 0.0022118091583251953
using-flash
Attention linproj: 0.0005295276641845703
QKV Transform: 0.002209901809692383
using-flash
Attention linproj: 0.0005283355712890625
QKV Transform: 0.0022058486938476562
using-flash
Attention linproj: 0.0005316734313964844
QKV Transform: 0.002272367477416992
using-flash
Attention linproj: 0.0005252361297607422
QKV Transform: 0.0022292137145996094
using-flash
Attention linproj: 0.0005366802215576172
QKV Transform: 0.0022897720336914062
using-flash
Attention linproj: 0.0005381107330322266
QKV Transform: 0.0021729469299316406
using-flash
Attention linproj: 0.0005369186401367188
QKV Transform: 0.0022306442260742188
using-flash
Attention linproj: 0.0005385875701904297
QKV Transform: 0.0022995471954345703
using-flash
Attention linproj: 0.0005373954772949219
QKV Transform: 0.002244710922241211
using-flash
Attention linproj: 0.0005257129669189453
QKV Transform: 0.0022237300872802734
using-flash
Attention linproj: 0.0005311965942382812
QKV Transform: 0.002153635025024414
using-flash
Attention linproj: 0.000530242919921875
QKV Transform: 0.0020813941955566406
using-flash
Attention linproj: 0.0005297660827636719
QKV Transform: 0.0021321773529052734
using-flash
Attention linproj: 0.0005307197570800781
QKV Transform: 0.002132415771484375
using-flash
Attention linproj: 0.0005328655242919922
QKV Transform: 0.0022847652435302734
using-flash
Attention linproj: 0.0005316734313964844
QKV Transform: 0.0022890567779541016
using-flash
Attention linproj: 0.0005426406860351562
QKV Transform: 0.002311229705810547
using-flash
Attention linproj: 0.000537872314453125
QKV Transform: 0.0020537376403808594
using-flash
Attention linproj: 0.0005376338958740234
QKV Transform: 0.0022115707397460938
using-flash
Attention linproj: 0.0005514621734619141
QKV Transform: 0.002167940139770508
using-flash
Attention linproj: 0.0005314350128173828
QKV Transform: 0.0021028518676757812
using-flash
Attention linproj: 0.0005309581756591797
QKV Transform: 0.002086162567138672
using-flash
Attention linproj: 0.0005321502685546875
QKV Transform: 0.0021457672119140625
using-flash
Attention linproj: 0.0005316734313964844
QKV Transform: 0.0021851062774658203
using-flash
Attention linproj: 0.000530242919921875
Attention duration (in seconds): 0.0116
Attention throughput (in TFLOP/s): 51.724
MLP_h_4h: 2.0699191093444824
MLP_4h_h: 0.0018258094787597656
MLP_h_4h: 0.0022826194763183594
MLP_4h_h: 0.0017294883728027344
MLP_h_4h: 0.002253293991088867
MLP_4h_h: 0.0017085075378417969
MLP_h_4h: 0.002249002456665039
MLP_4h_h: 0.0017049312591552734
MLP_h_4h: 0.0022499561309814453
MLP_4h_h: 0.0017006397247314453
MLP_h_4h: 0.002248048782348633
MLP_4h_h: 0.0017001628875732422
MLP_h_4h: 0.0022482872009277344
MLP_4h_h: 0.0016994476318359375
MLP_h_4h: 0.0022478103637695312
MLP_4h_h: 0.00170135498046875
MLP_h_4h: 0.0022535324096679688
MLP_4h_h: 0.0017025470733642578
MLP_h_4h: 0.002259969711303711
MLP_4h_h: 0.0017094612121582031
MLP_h_4h: 0.0022525787353515625
MLP_4h_h: 0.0017099380493164062
MLP_h_4h: 0.002265453338623047
MLP_4h_h: 0.0017063617706298828
MLP_h_4h: 0.002258777618408203
MLP_4h_h: 0.001705169677734375
MLP_h_4h: 0.002263307571411133
MLP_4h_h: 0.0017046928405761719
MLP_h_4h: 0.002263307571411133
MLP_4h_h: 0.0017125606536865234
MLP_h_4h: 0.0022614002227783203
MLP_4h_h: 0.001714468002319336
MLP_h_4h: 0.002279520034790039
MLP_4h_h: 0.0017104148864746094
MLP_h_4h: 0.0022759437561035156
MLP_4h_h: 0.0024139881134033203
MLP_h_4h: 0.0023131370544433594
MLP_4h_h: 0.0017192363739013672
MLP_h_4h: 0.002276182174682617
MLP_4h_h: 0.0017113685607910156
MLP_h_4h: 0.002275228500366211
MLP_4h_h: 0.0017108917236328125
MLP_h_4h: 0.0022766590118408203
MLP_4h_h: 0.001729726791381836
MLP_h_4h: 0.0022737979888916016
MLP_4h_h: 0.00173187255859375
MLP_h_4h: 0.002274751663208008
MLP_4h_h: 0.0017175674438476562
MLP_h_4h: 0.002269744873046875
MLP_4h_h: 0.0017168521881103516
MLP_h_4h: 0.002268075942993164
MLP_4h_h: 0.0017154216766357422
MLP_h_4h: 0.0022728443145751953
MLP_4h_h: 0.0017158985137939453
MLP_h_4h: 0.002271413803100586
MLP_4h_h: 0.0017163753509521484
MLP_h_4h: 0.002271413803100586
MLP_4h_h: 0.0017430782318115234
MLP_h_4h: 0.002282381057739258
MLP_4h_h: 0.0017180442810058594
MLP_h_4h: 0.0022656917572021484
MLP_4h_h: 0.001720428466796875
MLP_h_4h: 0.0022687911987304688
MLP_4h_h: 0.0017185211181640625
MLP_h_4h: 0.002268075942993164
MLP_4h_h: 0.0017201900482177734
MLP_h_4h: 0.0022666454315185547
MLP_4h_h: 0.0017359256744384766
MLP_h_4h: 0.0022716522216796875
MLP_4h_h: 0.0017201900482177734
MLP_h_4h: 0.002267122268676758
MLP_4h_h: 0.0017197132110595703
MLP_h_4h: 0.0022699832916259766
MLP_4h_h: 0.0017201900482177734
MLP_h_4h: 0.002284526824951172
MLP_4h_h: 0.0017230510711669922
MLP_h_4h: 0.0022830963134765625
MLP_4h_h: 0.0017237663269042969
MLP_h_4h: 0.002285480499267578
MLP_4h_h: 0.0017235279083251953
MLP_h_4h: 0.002283811569213867
MLP_4h_h: 0.0017249584197998047
MLP_h_4h: 0.002284526824951172
MLP_4h_h: 0.0017242431640625
MLP_h_4h: 0.0022840499877929688
MLP_4h_h: 0.0017244815826416016
MLP_h_4h: 0.002290487289428711
MLP_4h_h: 0.0017311573028564453
MLP_h_4h: 0.0022852420806884766
MLP_4h_h: 0.001730203628540039
MLP_h_4h: 0.002283811569213867
MLP_4h_h: 0.0017309188842773438
MLP_h_4h: 0.002283811569213867
MLP_4h_h: 0.0017247200012207031
MLP_h_4h: 0.0022847652435302734
MLP_4h_h: 0.0017251968383789062
MLP_h_4h: 0.002282381057739258
MLP_4h_h: 0.001733541488647461
MLP_h_4h: 0.0022840499877929688
MLP_4h_h: 0.001729726791381836
MLP_h_4h: 0.002282857894897461
MLP_4h_h: 0.0017299652099609375
MLP_h_4h: 0.0022830963134765625
MLP_4h_h: 0.0017261505126953125
MLP_h_4h: 0.0022857189178466797
MLP_4h_h: 0.001722097396850586
MLP_h_4h: 0.002285003662109375
MLP_4h_h: 0.0017266273498535156
MLP_h_4h: 0.002282857894897461
MLP_4h_h: 0.0017313957214355469
MLP_h_4h: 0.002283811569213867
MLP_4h_h: 0.0017313957214355469
MLP_h_4h: 0.0022840499877929688
MLP_4h_h: 0.0017211437225341797
MLP_h_4h: 0.0022842884063720703
MLP_4h_h: 0.0017273426055908203
MLP_h_4h: 0.0022852420806884766
MLP_4h_h: 0.0017285346984863281
MLP_h_4h: 0.002285480499267578
MLP_4h_h: 0.0017323493957519531
MLP_h_4h: 0.0022840499877929688
MLP_4h_h: 0.0017328262329101562
MLP_h_4h: 0.0022859573364257812
MLP_4h_h: 0.0017316341400146484
MLP_h_4h: 0.002286672592163086
MLP_4h_h: 0.001729726791381836
MLP_h_4h: 0.002302408218383789
MLP_4h_h: 0.0017337799072265625
MLP_h_4h: 0.0022912025451660156
MLP_4h_h: 0.0017333030700683594
MLP_h_4h: 0.0022974014282226562
MLP_4h_h: 0.0017361640930175781
MLP_h_4h: 0.0023026466369628906
MLP_4h_h: 0.001729726791381836
MLP_h_4h: 0.002295255661010742
MLP_4h_h: 0.0017282962799072266
MLP_h_4h: 0.002295255661010742
MLP_4h_h: 0.001720428466796875
MLP_h_4h: 0.0023119449615478516
MLP_4h_h: 0.001718759536743164
MLP_h_4h: 0.002297639846801758
MLP_4h_h: 0.0017180442810058594
MLP_h_4h: 0.0022995471954345703
MLP_4h_h: 0.0017185211181640625
MLP_h_4h: 0.002301454544067383
MLP_4h_h: 0.0017189979553222656
MLP_h_4h: 0.0022966861724853516
MLP_4h_h: 0.001718282699584961
MLP_h_4h: 0.0022950172424316406
MLP_4h_h: 0.0017199516296386719
MLP_h_4h: 0.002299785614013672
MLP_4h_h: 0.0017199516296386719
MLP_h_4h: 0.0022983551025390625
MLP_4h_h: 0.0017194747924804688
MLP_h_4h: 0.0022962093353271484
MLP_4h_h: 0.0017185211181640625
MLP_h_4h: 0.002294778823852539
MLP_4h_h: 0.001718282699584961
MLP_h_4h: 0.002298116683959961
MLP_4h_h: 0.0017135143280029297
MLP_h_4h: 0.0022771358489990234
MLP_4h_h: 0.00170135498046875
MLP_h_4h: 0.002274036407470703
MLP_4h_h: 0.00170135498046875
MLP_h_4h: 0.0022742748260498047
MLP_4h_h: 0.0017006397247314453
MLP_h_4h: 0.002283334732055664
MLP_4h_h: 0.0017018318176269531
MLP_h_4h: 0.002282381057739258
MLP_4h_h: 0.0017066001892089844
MLP_h_4h: 0.0022950172424316406
MLP_4h_h: 0.0017054080963134766
MLP_h_4h: 0.002287626266479492
MLP_4h_h: 0.001707315444946289
MLP_h_4h: 0.002285003662109375
MLP_4h_h: 0.0017094612121582031
MLP_h_4h: 0.0023109912872314453
MLP_4h_h: 0.0017063617706298828
MLP_h_4h: 0.0022971630096435547
MLP_4h_h: 0.0017056465148925781
MLP_h_4h: 0.00229644775390625
MLP_4h_h: 0.001703023910522461
MLP_h_4h: 0.002292633056640625
MLP_4h_h: 0.00170135498046875
MLP_h_4h: 0.002270221710205078
MLP_4h_h: 0.0017004013061523438
MLP_h_4h: 0.002283334732055664
MLP_4h_h: 0.0017025470733642578
MLP_h_4h: 0.002269744873046875
MLP_4h_h: 0.0017120838165283203
MLP_h_4h: 0.0022683143615722656
MLP_4h_h: 0.0017011165618896484
MLP_h_4h: 0.0022726058959960938
MLP_4h_h: 0.0017008781433105469
MLP_h_4h: 0.0022690296173095703
MLP_4h_h: 0.0017008781433105469
MLP_h_4h: 0.0022726058959960938
MLP_4h_h: 0.0017011165618896484
MLP_h_4h: 0.002271890640258789
MLP_4h_h: 0.0017001628875732422
MLP_h_4h: 0.0022742748260498047
MLP_4h_h: 0.0017018318176269531
MLP_h_4h: 0.0022737979888916016
MLP_4h_h: 0.0017008781433105469
MLP_h_4h: 0.002274036407470703
MLP_4h_h: 0.0017011165618896484
MLP_h_4h: 0.0022721290588378906
MLP_4h_h: 0.00170135498046875
MLP_h_4h: 0.0022733211517333984
MLP_4h_h: 0.0017015933990478516
MLP_h_4h: 0.0022766590118408203
MLP_4h_h: 0.001718759536743164
MLP_h_4h: 0.0022749900817871094
MLP_4h_h: 0.0017113685607910156
MLP_h_4h: 0.002269268035888672
MLP_4h_h: 0.0017290115356445312
MLP_h_4h: 0.002275705337524414
MLP_4h_h: 0.0017087459564208984
MLP_h_4h: 0.0022695064544677734
MLP_4h_h: 0.001707315444946289
MLP_h_4h: 0.0022695064544677734
MLP_4h_h: 0.0017092227935791016
MLP_h_4h: 0.002270221710205078
MLP_4h_h: 0.0017066001892089844
MLP_h_4h: 0.002269268035888672
MLP_4h_h: 0.0017082691192626953
MLP_h_4h: 0.002278566360473633
MLP_4h_h: 0.001707315444946289
MLP_h_4h: 0.002269744873046875
MLP_4h_h: 0.001707315444946289
MLP_h_4h: 0.0022673606872558594
MLP_4h_h: 0.001706838607788086
MLP_h_4h: 0.002272367477416992
MLP_4h_h: 0.0017352104187011719
MLP_h_4h: 0.002279996871948242
MLP_4h_h: 0.001708984375
MLP_h_4h: 0.0022649765014648438
MLP_4h_h: 0.0017092227935791016
MLP_h_4h: 0.002264738082885742
MLP_4h_h: 0.0017096996307373047
MLP_h_4h: 0.0022678375244140625
MLP_4h_h: 0.001708984375
MLP_h_4h: 0.0022666454315185547
MLP_4h_h: 0.001708984375
MLP_h_4h: 0.002266407012939453
MLP_4h_h: 0.0017082691192626953
MLP_h_4h: 0.0022644996643066406
MLP_4h_h: 0.001707315444946289
MLP_h_4h: 0.002266407012939453
MLP_4h_h: 0.0017101764678955078
MLP_h_4h: 0.0022644996643066406
MLP_4h_h: 0.0017085075378417969
MLP_h_4h: 0.0022630691528320312
MLP_4h_h: 0.0017108917236328125
MLP_h_4h: 0.0022652149200439453
MLP_4h_h: 0.0017082691192626953
MLP_h_4h: 0.0022649765014648438
MLP_4h_h: 0.0017080307006835938
MLP_h_4h: 0.002265453338623047
MLP_4h_h: 0.0017092227935791016
MLP_h_4h: 0.002262592315673828
MLP_4h_h: 0.0017096996307373047
MLP_h_4h: 0.0022695064544677734
MLP_4h_h: 0.0017173290252685547
MLP_h_4h: 0.0022661685943603516
MLP_4h_h: 0.0017271041870117188
MLP_h_4h: 0.0022695064544677734
MLP_4h_h: 0.001710653305053711
MLP_h_4h: 0.0022649765014648438
MLP_4h_h: 0.001712799072265625
MLP_h_4h: 0.002259969711303711
MLP_4h_h: 0.0017101764678955078
MLP_h_4h: 0.0022652149200439453
MLP_4h_h: 0.0017099380493164062
MLP_h_4h: 0.0022644996643066406
MLP_4h_h: 0.0017101764678955078
MLP_h_4h: 0.002267599105834961
MLP_4h_h: 0.0017092227935791016
MLP_h_4h: 0.0022673606872558594
MLP_4h_h: 0.0017085075378417969
MLP_h_4h: 0.0022649765014648438
MLP_4h_h: 0.0017082691192626953
MLP_h_4h: 0.002265453338623047
MLP_4h_h: 0.001711130142211914
MLP_h_4h: 0.0022661685943603516
MLP_4h_h: 0.0017104148864746094
MLP_h_4h: 0.002267122268676758
MLP_4h_h: 0.0017108917236328125
MLP_h_4h: 0.002269268035888672
MLP_4h_h: 0.0017096996307373047
MLP_h_4h: 0.0022673606872558594
MLP_4h_h: 0.0017108917236328125
MLP_h_4h: 0.0022649765014648438
MLP_4h_h: 0.0017101764678955078
MLP_h_4h: 0.002268552780151367
MLP_4h_h: 0.0017101764678955078
MLP_h_4h: 0.002267122268676758
MLP_4h_h: 0.0017092227935791016
MLP_h_4h: 0.002266407012939453
MLP_4h_h: 0.0017101764678955078
MLP duration (in seconds): 0.0040
MLP throughput (in TFLOP/s): 213.390
LN1: 0.0030465126037597656
QKV Transform: 0.0016868114471435547
using-flash
Attention linproj: 0.0005350112915039062
Post-attention Dropout: 0.06502366065979004
Post-attention residual: 0.003414630889892578
LN2: 0.00018930435180664062
MLP_h_4h: 0.002358675003051758
MLP_4h_h: 0.0017104148864746094
Post-MLP residual: 0.002012014389038086
Attention layer time: 0.08253693580627441
LN1: 0.00013399124145507812
QKV Transform: 0.002765655517578125
using-flash
Attention linproj: 0.0005352497100830078
Post-attention Dropout: 0.00033783912658691406
Post-attention residual: 0.00011086463928222656
LN2: 0.00011682510375976562
MLP_h_4h: 0.002650737762451172
MLP_4h_h: 0.001722574234008789
Post-MLP residual: 0.00033664703369140625
Attention layer time: 0.01636958122253418
LN1: 0.00013494491577148438
QKV Transform: 0.0020415782928466797
using-flash
Attention linproj: 0.0005304813385009766
Post-attention Dropout: 0.0003464221954345703
Post-attention residual: 0.00011467933654785156
LN2: 0.0001201629638671875
MLP_h_4h: 0.0036211013793945312
MLP_4h_h: 0.0017266273498535156
Post-MLP residual: 0.00033473968505859375
Attention layer time: 0.01664590835571289
LN1: 0.00013136863708496094
QKV Transform: 0.0025882720947265625
using-flash
Attention linproj: 0.0005326271057128906
Post-attention Dropout: 0.0003483295440673828
Post-attention residual: 0.00011324882507324219
LN2: 0.00013780593872070312
MLP_h_4h: 0.003581523895263672
MLP_4h_h: 0.0017209053039550781
Post-MLP residual: 0.00034046173095703125
Attention layer time: 0.017192840576171875
LN1: 0.0001327991485595703
QKV Transform: 0.002669095993041992
using-flash
Attention linproj: 0.0005364418029785156
Post-attention Dropout: 0.0003337860107421875
Post-attention residual: 0.00011014938354492188
LN2: 0.00011467933654785156
MLP_h_4h: 0.002718687057495117
MLP_4h_h: 0.0017158985137939453
Post-MLP residual: 0.0003273487091064453
Attention layer time: 0.03281712532043457
LN1: 0.00012922286987304688
QKV Transform: 0.0018532276153564453
using-flash
Attention linproj: 0.0005366802215576172
Post-attention Dropout: 0.0003421306610107422
Post-attention residual: 0.00011229515075683594
LN2: 0.00011515617370605469
MLP_h_4h: 0.003618478775024414
MLP_4h_h: 0.001711130142211914
Post-MLP residual: 0.0003352165222167969
Attention layer time: 0.017490863800048828
LN1: 0.00013375282287597656
QKV Transform: 0.002536773681640625
using-flash
Attention linproj: 0.0005278587341308594
Post-attention Dropout: 0.0003647804260253906
Post-attention residual: 0.00011515617370605469
LN2: 0.00011873245239257812
MLP_h_4h: 0.0036153793334960938
MLP_4h_h: 0.0017404556274414062
Post-MLP residual: 0.00033783912658691406
Attention layer time: 0.01715850830078125
LN1: 0.00013017654418945312
QKV Transform: 0.0025322437286376953
using-flash
Attention linproj: 0.0005259513854980469
Post-attention Dropout: 0.00033593177795410156
Post-attention residual: 0.00011539459228515625
LN2: 0.00011706352233886719
MLP_h_4h: 0.003632783889770508
MLP_4h_h: 0.0017211437225341797
Post-MLP residual: 0.00034165382385253906
Attention layer time: 0.017138957977294922
LN1: 0.0001316070556640625
QKV Transform: 0.0025644302368164062
using-flash
Attention linproj: 0.0005414485931396484
Post-attention Dropout: 0.00033926963806152344
Post-attention residual: 0.00011348724365234375
LN2: 0.00011682510375976562
MLP_h_4h: 0.0036263465881347656
MLP_4h_h: 0.0017189979553222656
Post-MLP residual: 0.0003476142883300781
Attention layer time: 0.01717853546142578
LN1: 0.0001285076141357422
QKV Transform: 0.002597332000732422
using-flash
Attention linproj: 0.0005352497100830078
Post-attention Dropout: 0.0003447532653808594
Post-attention residual: 0.00012564659118652344
LN2: 0.00012826919555664062
MLP_h_4h: 0.0035965442657470703
MLP_4h_h: 0.0017330646514892578
Post-MLP residual: 0.0003352165222167969
Attention layer time: 0.017197608947753906
LN1: 0.0001342296600341797
QKV Transform: 0.00254058837890625
using-flash
Attention linproj: 0.0005283355712890625
Post-attention Dropout: 0.0003368854522705078
Post-attention residual: 0.00011491775512695312
LN2: 0.00011968612670898438
MLP_h_4h: 0.003627777099609375
MLP_4h_h: 0.001722574234008789
Post-MLP residual: 0.000335693359375
Attention layer time: 0.017145872116088867
LN1: 0.00013065338134765625
QKV Transform: 0.002521991729736328
using-flash
Attention linproj: 0.0005259513854980469
Post-attention Dropout: 0.00033593177795410156
Post-attention residual: 0.00011372566223144531
LN2: 0.00011467933654785156
MLP_h_4h: 0.003651857376098633
MLP_4h_h: 0.001718282699584961
Post-MLP residual: 0.000339508056640625
Attention layer time: 0.0171356201171875
LN1: 0.00013208389282226562
QKV Transform: 0.0025098323822021484
using-flash
Attention linproj: 0.0005335807800292969
Post-attention Dropout: 0.0003364086151123047
Post-attention residual: 0.00011277198791503906
LN2: 0.00011539459228515625
MLP_h_4h: 0.003655672073364258
MLP_4h_h: 0.0017199516296386719
Post-MLP residual: 0.0003414154052734375
Attention layer time: 0.01714181900024414
LN1: 0.0001277923583984375
QKV Transform: 0.0024077892303466797
using-flash
Attention linproj: 0.0005354881286621094
Post-attention Dropout: 0.0003418922424316406
Post-attention residual: 0.00011467933654785156
LN2: 0.00011730194091796875
MLP_h_4h: 0.003641366958618164
MLP_4h_h: 0.0017135143280029297
Post-MLP residual: 0.00033783912658691406
Attention layer time: 0.01699233055114746
LN1: 0.00013375282287597656
QKV Transform: 0.002516031265258789
using-flash
Attention linproj: 0.0005288124084472656
Post-attention Dropout: 0.0003380775451660156
Post-attention residual: 0.00011563301086425781
LN2: 0.00011897087097167969
MLP_h_4h: 0.003634929656982422
MLP_4h_h: 0.001722574234008789
Post-MLP residual: 0.0003376007080078125
Attention layer time: 0.0171201229095459
LN1: 0.0001285076141357422
QKV Transform: 0.0026998519897460938
using-flash
Attention linproj: 0.0005254745483398438
Post-attention Dropout: 0.0003337860107421875
Post-attention residual: 0.00011348724365234375
LN2: 0.00011563301086425781
MLP_h_4h: 0.0036537647247314453
MLP_4h_h: 0.0017180442810058594
Post-MLP residual: 0.0003402233123779297
Attention layer time: 0.017301559448242188
LN1: 0.0001308917999267578
QKV Transform: 0.002580881118774414
using-flash
Attention linproj: 0.0005326271057128906
Post-attention Dropout: 0.0003376007080078125
Post-attention residual: 0.00011348724365234375
LN2: 0.00011515617370605469
MLP_h_4h: 0.003650665283203125
MLP_4h_h: 0.0017192363739013672
Post-MLP residual: 0.00033593177795410156
Attention layer time: 0.017155885696411133
LN1: 0.00012874603271484375
QKV Transform: 0.0025453567504882812
using-flash
Attention linproj: 0.0005350112915039062
Post-attention Dropout: 0.0003437995910644531
Post-attention residual: 0.00011372566223144531
LN2: 0.00012683868408203125
MLP_h_4h: 0.0036094188690185547
MLP_4h_h: 0.0017230510711669922
Post-MLP residual: 0.0003364086151123047
Attention layer time: 0.017138004302978516
LN1: 0.0001342296600341797
QKV Transform: 0.0025370121002197266
using-flash
Attention linproj: 0.0005307197570800781
Post-attention Dropout: 0.0003383159637451172
Post-attention residual: 0.00011420249938964844
LN2: 0.00011992454528808594
MLP_h_4h: 0.0036318302154541016
MLP_4h_h: 0.0017147064208984375
Post-MLP residual: 0.0003368854522705078
Attention layer time: 0.01713418960571289
LN1: 0.00013828277587890625
QKV Transform: 0.0026111602783203125
using-flash
Attention linproj: 0.0005273818969726562
Post-attention Dropout: 0.00033473968505859375
Post-attention residual: 0.00011277198791503906
LN2: 0.00011515617370605469
MLP_h_4h: 0.0036580562591552734
MLP_4h_h: 0.0017180442810058594
Post-MLP residual: 0.00033855438232421875
Attention layer time: 0.01721358299255371
LN1: 0.00013184547424316406
QKV Transform: 0.002522706985473633
using-flash
Attention linproj: 0.0005309581756591797
Post-attention Dropout: 0.0003368854522705078
Post-attention residual: 0.00011205673217773438
LN2: 0.00011563301086425781
MLP_h_4h: 0.003633737564086914
MLP_4h_h: 0.0017189979553222656
Post-MLP residual: 0.00033354759216308594
Attention layer time: 0.017108440399169922
LN1: 0.00012874603271484375
QKV Transform: 0.002454519271850586
using-flash
Attention linproj: 0.0005469322204589844
Post-attention Dropout: 0.0003440380096435547
Post-attention residual: 0.00011277198791503906
LN2: 0.00011610984802246094
MLP_h_4h: 0.00360870361328125
MLP_4h_h: 0.001722574234008789
Post-MLP residual: 0.00033354759216308594
Attention layer time: 0.017044544219970703
LN1: 0.0001342296600341797
QKV Transform: 0.0025625228881835938
using-flash
Attention linproj: 0.0005273818969726562
Post-attention Dropout: 0.0003361701965332031
Post-attention residual: 0.00011539459228515625
LN2: 0.000118255615234375
MLP_h_4h: 0.0036492347717285156
MLP_4h_h: 0.0017118453979492188
Post-MLP residual: 0.0003361701965332031
Attention layer time: 0.017174959182739258
LN1: 0.00012874603271484375
QKV Transform: 0.0026814937591552734
using-flash
Attention linproj: 0.0005252361297607422
Post-attention Dropout: 0.0003364086151123047
Post-attention residual: 0.00011563301086425781
LN2: 0.0001163482666015625
MLP_h_4h: 0.0036468505859375
MLP_4h_h: 0.0017194747924804688
Post-MLP residual: 0.00033974647521972656
Attention layer time: 0.0172884464263916
LN1: 0.00013184547424316406
QKV Transform: 0.002563953399658203
using-flash
Attention linproj: 0.0005447864532470703
Post-attention Dropout: 0.0003407001495361328
Post-attention residual: 0.00011420249938964844
LN2: 0.00011515617370605469
MLP_h_4h: 0.003619670867919922
MLP_4h_h: 0.0017092227935791016
Post-MLP residual: 0.00033593177795410156
Attention layer time: 0.0171663761138916
LN1: 0.00012969970703125
QKV Transform: 0.0025200843811035156
using-flash
Attention linproj: 0.0005495548248291016
Post-attention Dropout: 0.0003418922424316406
Post-attention residual: 0.00011372566223144531
LN2: 0.00012683868408203125
MLP_h_4h: 0.0036008358001708984
MLP_4h_h: 0.0017240047454833984
Post-MLP residual: 0.000335693359375
Attention layer time: 0.01711273193359375
LN1: 0.00013327598571777344
QKV Transform: 0.0025153160095214844
using-flash
Attention linproj: 0.0005269050598144531
Post-attention Dropout: 0.00033926963806152344
Post-attention residual: 0.00011515617370605469
LN2: 0.00011777877807617188
MLP_h_4h: 0.0036280155181884766
MLP_4h_h: 0.001735687255859375
Post-MLP residual: 0.0003390312194824219
Attention layer time: 0.017132043838500977
LN1: 0.00013399124145507812
QKV Transform: 0.002554178237915039
using-flash
Attention linproj: 0.0005269050598144531
Post-attention Dropout: 0.00033664703369140625
Post-attention residual: 0.00011467933654785156
LN2: 0.00011777877807617188
MLP_h_4h: 0.0036339759826660156
MLP_4h_h: 0.0017271041870117188
Post-MLP residual: 0.0003483295440673828
Attention layer time: 0.018215656280517578
LN1: 0.00013947486877441406
QKV Transform: 0.0025358200073242188
using-flash
Attention linproj: 0.0005304813385009766
Post-attention Dropout: 0.0003349781036376953
Post-attention residual: 0.00011372566223144531
LN2: 0.00011444091796875
MLP_h_4h: 0.004893779754638672
MLP_4h_h: 0.0017325878143310547
Post-MLP residual: 0.00033545494079589844
Attention layer time: 0.01840972900390625
LN1: 0.00013256072998046875
QKV Transform: 0.002238750457763672
using-flash
Attention linproj: 0.0005273818969726562
Post-attention Dropout: 0.00033545494079589844
Post-attention residual: 0.00011301040649414062
LN2: 0.00011491775512695312
MLP_h_4h: 0.0036525726318359375
MLP_4h_h: 0.0017185211181640625
Post-MLP residual: 0.00033926963806152344
Attention layer time: 0.016866207122802734
LN1: 0.00015163421630859375
QKV Transform: 0.0025496482849121094
using-flash
Attention linproj: 0.0005340576171875
Post-attention Dropout: 0.0003383159637451172
Post-attention residual: 0.00011229515075683594
LN2: 0.00011539459228515625
MLP_h_4h: 0.003623485565185547
MLP_4h_h: 0.0017189979553222656
Post-MLP residual: 0.0003361701965332031
Attention layer time: 0.017160654067993164
LN1: 0.0001285076141357422
QKV Transform: 0.002476930618286133
using-flash
Attention linproj: 0.0005490779876708984
Post-attention Dropout: 0.0003437995910644531
Post-attention residual: 0.00012350082397460938
LN2: 0.00011587142944335938
MLP_h_4h: 0.0036051273345947266
MLP_4h_h: 0.0017213821411132812
Post-MLP residual: 0.00033283233642578125
Attention layer time: 0.01706385612487793
LN1: 0.000133514404296875
QKV Transform: 0.002579927444458008
using-flash
Attention linproj: 0.0005285739898681641
Post-attention Dropout: 0.00033545494079589844
Post-attention residual: 0.00011396408081054688
LN2: 0.00011873245239257812
MLP_h_4h: 0.0036427974700927734
MLP_4h_h: 0.0017282962799072266
Post-MLP residual: 0.0003383159637451172
Attention layer time: 0.017194271087646484
LN1: 0.00012826919555664062
QKV Transform: 0.002688169479370117
using-flash
Attention linproj: 0.0005247592926025391
Post-attention Dropout: 0.00033664703369140625
Post-attention residual: 0.00011348724365234375
LN2: 0.00011539459228515625
MLP_h_4h: 0.0036468505859375
MLP_4h_h: 0.0017178058624267578
Post-MLP residual: 0.00033926963806152344
Attention layer time: 0.017279624938964844
LN1: 0.00013208389282226562
QKV Transform: 0.0023000240325927734
using-flash
Attention linproj: 0.0005233287811279297
Post-attention Dropout: 0.0003371238708496094
Post-attention residual: 0.0001125335693359375
LN2: 0.00011491775512695312
MLP_h_4h: 0.003648519515991211
MLP_4h_h: 0.001718759536743164
Post-MLP residual: 0.00033664703369140625
Attention layer time: 0.016885042190551758
LN1: 0.0001304149627685547
QKV Transform: 0.0025513172149658203
using-flash
Attention linproj: 0.0005335807800292969
Post-attention Dropout: 0.00034499168395996094
Post-attention residual: 0.00011372566223144531
LN2: 0.00011610984802246094
MLP_h_4h: 0.003620624542236328
MLP_4h_h: 0.0017223358154296875
Post-MLP residual: 0.0003352165222167969
Attention layer time: 0.01714491844177246
LN1: 0.00013375282287597656
QKV Transform: 0.002439260482788086
using-flash
Attention linproj: 0.0005269050598144531
Post-attention Dropout: 0.0003407001495361328
Post-attention residual: 0.00011515617370605469
LN2: 0.00011801719665527344
MLP_h_4h: 0.003625631332397461
MLP_4h_h: 0.0017180442810058594
Post-MLP residual: 0.0003349781036376953
Attention layer time: 0.017040491104125977
LN1: 0.0001277923583984375
QKV Transform: 0.0026502609252929688
using-flash
Attention linproj: 0.0005476474761962891
Post-attention Dropout: 0.00034427642822265625
Post-attention residual: 0.00011491775512695312
LN2: 0.00011515617370605469
MLP_h_4h: 0.0036144256591796875
MLP_4h_h: 0.0017213821411132812
Post-MLP residual: 0.00033402442932128906
Attention layer time: 0.01933145523071289
LN1: 0.00013327598571777344
QKV Transform: 0.002439260482788086
using-flash
Attention linproj: 0.0005276203155517578
Post-attention Dropout: 0.0003376007080078125
Post-attention residual: 0.00011515617370605469
LN2: 0.0001327991485595703
MLP_h_4h: 0.003626585006713867
MLP_4h_h: 0.0017130374908447266
Post-MLP residual: 0.00033664703369140625
Attention layer time: 0.017049074172973633
LN1: 0.00026726722717285156
QKV Transform: 0.002552509307861328
using-flash
Attention linproj: 0.0005364418029785156
Post-attention Dropout: 0.00038170814514160156
Post-attention residual: 0.00011658668518066406
LN2: 0.000118255615234375
MLP_h_4h: 0.003571033477783203
MLP_4h_h: 0.0017344951629638672
Post-MLP residual: 0.00033974647521972656
Attention layer time: 0.017306804656982422
LN1: 0.00013399124145507812
QKV Transform: 0.0024127960205078125
using-flash
Attention linproj: 0.0005285739898681641
Post-attention Dropout: 0.00033664703369140625
Post-attention residual: 0.00011396408081054688
LN2: 0.00011563301086425781
MLP_h_4h: 0.0036449432373046875
MLP_4h_h: 0.0017180442810058594
Post-MLP residual: 0.00033974647521972656
Attention layer time: 0.017031431198120117
LN1: 0.0001316070556640625
QKV Transform: 0.0023403167724609375
using-flash
Attention linproj: 0.0005247592926025391
Post-attention Dropout: 0.0003368854522705078
Post-attention residual: 0.00011396408081054688
LN2: 0.00011515617370605469
MLP_h_4h: 0.0036461353302001953
MLP_4h_h: 0.0017163753509521484
Post-MLP residual: 0.0003418922424316406
Attention layer time: 0.016945600509643555
LN1: 0.00013136863708496094
QKV Transform: 0.0025696754455566406
using-flash
Attention linproj: 0.0005295276641845703
Post-attention Dropout: 0.0003380775451660156
Post-attention residual: 0.00011277198791503906
LN2: 0.00011610984802246094
MLP_h_4h: 0.003637075424194336
MLP_4h_h: 0.001718759536743164
Post-MLP residual: 0.0003559589385986328
Attention layer time: 0.0171816349029541
LN1: 0.00012874603271484375
QKV Transform: 0.002544403076171875
using-flash
Attention linproj: 0.0005342960357666016
Post-attention Dropout: 0.00034165382385253906
Post-attention residual: 0.00011396408081054688
LN2: 0.00011420249938964844
MLP_h_4h: 0.003632068634033203
MLP_4h_h: 0.0017175674438476562
Post-MLP residual: 0.0003330707550048828
Attention layer time: 0.01712965965270996
LN1: 0.00013399124145507812
QKV Transform: 0.0025658607482910156
using-flash
Attention linproj: 0.0005297660827636719
Post-attention Dropout: 0.0003631114959716797
Post-attention residual: 0.00011396408081054688
LN2: 0.00011777877807617188
MLP_h_4h: 0.003601551055908203
MLP_4h_h: 0.0017349720001220703
Post-MLP residual: 0.0003342628479003906
Attention layer time: 0.017184972763061523
LN1: 0.00013065338134765625
QKV Transform: 0.002644062042236328
using-flash
Attention linproj: 0.0005271434783935547
Post-attention Dropout: 0.00033473968505859375
Post-attention residual: 0.00011396408081054688
LN2: 0.00011515617370605469
MLP_h_4h: 0.003649473190307617
MLP_4h_h: 0.001718759536743164
Post-MLP residual: 0.000339508056640625
Attention layer time: 0.01728081703186035
LN1: 0.0001308917999267578
QKV Transform: 0.0025653839111328125
using-flash
Attention linproj: 0.0005319118499755859
Post-attention Dropout: 0.0003371238708496094
Post-attention residual: 0.00011277198791503906
LN2: 0.00011515617370605469
MLP_h_4h: 0.003631591796875
MLP_4h_h: 0.0017085075378417969
Post-MLP residual: 0.0003452301025390625
Attention layer time: 0.017163753509521484
LN1: 0.00012874603271484375
QKV Transform: 0.0025060176849365234
using-flash
Attention linproj: 0.0005338191986083984
Post-attention Dropout: 0.0003445148468017578
Post-attention residual: 0.00011396408081054688
LN2: 0.00011467933654785156
MLP_h_4h: 0.0036232471466064453
MLP_4h_h: 0.001722574234008789
Post-MLP residual: 0.0003371238708496094
Attention layer time: 0.01709771156311035
LN1: 0.0001404285430908203
QKV Transform: 0.0023813247680664062
using-flash
Attention linproj: 0.0005280971527099609
Post-attention Dropout: 0.00034880638122558594
Post-attention residual: 0.00011396408081054688
LN2: 0.000118255615234375
MLP_h_4h: 0.003623485565185547
MLP_4h_h: 0.0017387866973876953
Post-MLP residual: 0.0003361701965332031
Attention layer time: 0.017005205154418945
LN1: 0.0001304149627685547
QKV Transform: 0.0026192665100097656
using-flash
Attention linproj: 0.0005259513854980469
Post-attention Dropout: 0.0003390312194824219
Post-attention residual: 0.00011277198791503906
LN2: 0.00011491775512695312
MLP_h_4h: 0.003650188446044922
MLP_4h_h: 0.0017173290252685547
Post-MLP residual: 0.0003387928009033203
Attention layer time: 0.017216920852661133
LN1: 0.0001308917999267578
QKV Transform: 0.002652883529663086
using-flash
Attention linproj: 0.0005414485931396484
Post-attention Dropout: 0.0003371238708496094
Post-attention residual: 0.00011324882507324219
LN2: 0.00011587142944335938
MLP_h_4h: 0.005725383758544922
MLP_4h_h: 0.0017235279083251953
Post-MLP residual: 0.00033926963806152344
Attention layer time: 0.01935577392578125
LN1: 0.0001308917999267578
QKV Transform: 0.0023915767669677734
using-flash
Attention linproj: 0.0005271434783935547
Post-attention Dropout: 0.0003337860107421875
Post-attention residual: 0.00011324882507324219
LN2: 0.00011610984802246094
MLP_h_4h: 0.003654003143310547
MLP_4h_h: 0.0017173290252685547
Post-MLP residual: 0.0003409385681152344
Attention layer time: 0.016994476318359375
LN1: 0.00013113021850585938
QKV Transform: 0.002599954605102539
using-flash
Attention linproj: 0.0005319118499755859
Post-attention Dropout: 0.0003380775451660156
Post-attention residual: 0.00011324882507324219
LN2: 0.0001163482666015625
MLP_h_4h: 0.004671573638916016
MLP_4h_h: 0.0017175674438476562
Post-MLP residual: 0.0003409385681152344
Attention layer time: 0.018247604370117188
LN1: 0.00012826919555664062
QKV Transform: 0.00264739990234375
using-flash
Attention linproj: 0.0005307197570800781
Post-attention Dropout: 0.0003376007080078125
Post-attention residual: 0.00011348724365234375
LN2: 0.0001163482666015625
MLP_h_4h: 0.0036246776580810547
MLP_4h_h: 0.0017178058624267578
Post-MLP residual: 0.00033974647521972656
Attention layer time: 0.01724839210510254
LN1: 0.00013184547424316406
QKV Transform: 0.002605438232421875
using-flash
Attention linproj: 0.0005388259887695312
Post-attention Dropout: 0.0003478527069091797
Post-attention residual: 0.00011372566223144531
LN2: 0.00011587142944335938
MLP_h_4h: 0.003624439239501953
MLP_4h_h: 0.0017223358154296875
Post-MLP residual: 0.0003457069396972656
Attention layer time: 0.017215251922607422
LN1: 0.0001354217529296875
QKV Transform: 0.002445220947265625
using-flash
Attention linproj: 0.0005321502685546875
Post-attention Dropout: 0.000362396240234375
Post-attention residual: 0.00011372566223144531
LN2: 0.00011682510375976562
MLP_h_4h: 0.0036163330078125
MLP_4h_h: 0.0017209053039550781
Post-MLP residual: 0.00033402442932128906
Attention layer time: 0.017055034637451172
LN1: 0.00014925003051757812
QKV Transform: 0.0025005340576171875
using-flash
Attention linproj: 0.0005276203155517578
Post-attention Dropout: 0.0003352165222167969
Post-attention residual: 0.00011229515075683594
LN2: 0.00011491775512695312
MLP_h_4h: 0.003642559051513672
MLP_4h_h: 0.0017197132110595703
Post-MLP residual: 0.0003387928009033203
Attention layer time: 0.017124414443969727
LN1: 0.00012826919555664062
QKV Transform: 0.002546548843383789
using-flash
Attention linproj: 0.000518798828125
Post-attention Dropout: 0.0003352165222167969
Post-attention residual: 0.00011324882507324219
LN2: 0.00011444091796875
MLP_h_4h: 0.002611398696899414
MLP_4h_h: 0.0017218589782714844
Post-MLP residual: 0.0003349781036376953
Attention layer time: 0.016084671020507812
LN1: 0.000133514404296875
QKV Transform: 0.0025320053100585938
using-flash
Attention linproj: 0.0005276203155517578
Post-attention Dropout: 0.00034618377685546875
Post-attention residual: 0.00011467933654785156
LN2: 0.00011873245239257812
MLP_h_4h: 0.004671812057495117
MLP_4h_h: 0.0017299652099609375
Post-MLP residual: 0.0003349781036376953
Attention layer time: 0.018194913864135742
LN1: 0.0001316070556640625
QKV Transform: 0.002573728561401367
using-flash
Attention linproj: 0.00052642822265625
Post-attention Dropout: 0.000362396240234375
Post-attention residual: 0.00011515617370605469
LN2: 0.00011706352233886719
MLP_h_4h: 0.0035943984985351562
MLP_4h_h: 0.001743316650390625
Post-MLP residual: 0.0003352165222167969
Attention layer time: 0.017180442810058594
LN1: 0.00013756752014160156
QKV Transform: 0.0025529861450195312
using-flash
Attention linproj: 0.0005266666412353516
Post-attention Dropout: 0.0003361701965332031
Post-attention residual: 0.00011348724365234375
LN2: 0.00011539459228515625
MLP_h_4h: 0.0036470890045166016
MLP_4h_h: 0.0017192363739013672
Post-MLP residual: 0.0003409385681152344
Attention layer time: 0.0171663761138916
LN1: 0.00012731552124023438
QKV Transform: 0.0026106834411621094
using-flash
Attention linproj: 0.0005235671997070312
Post-attention Dropout: 0.0003364086151123047
Post-attention residual: 0.00011372566223144531
LN2: 0.00011515617370605469
MLP_h_4h: 0.003664731979370117
MLP_4h_h: 0.0017173290252685547
Post-MLP residual: 0.0003440380096435547
Attention layer time: 0.017221450805664062
LN1: 0.0001323223114013672
QKV Transform: 0.002563953399658203
using-flash
Attention linproj: 0.0005342960357666016
Post-attention Dropout: 0.0003445148468017578
Post-attention residual: 0.00011396408081054688
LN2: 0.00011587142944335938
MLP_h_4h: 0.0036156177520751953
MLP_4h_h: 0.0017120838165283203
Post-MLP residual: 0.0003345012664794922
Attention layer time: 0.017149925231933594
LN1: 0.00013017654418945312
QKV Transform: 0.0025658607482910156
using-flash
Attention linproj: 0.0005271434783935547
Post-attention Dropout: 0.0003407001495361328
Post-attention residual: 0.00012826919555664062
LN2: 0.00011801719665527344
MLP_h_4h: 0.0036325454711914062
MLP_4h_h: 0.0017206668853759766
Post-MLP residual: 0.00033473968505859375
Attention layer time: 0.017159223556518555
LN1: 0.0001480579376220703
QKV Transform: 0.002507925033569336
using-flash
Attention linproj: 0.0005297660827636719
Post-attention Dropout: 0.000339508056640625
Post-attention residual: 0.00011324882507324219
LN2: 0.00011682510375976562
MLP_h_4h: 0.003638744354248047
MLP_4h_h: 0.0017175674438476562
Post-MLP residual: 0.00033736228942871094
Attention layer time: 0.017136573791503906
LN1: 0.00012922286987304688
QKV Transform: 0.002531766891479492
using-flash
Attention linproj: 0.0005297660827636719
Post-attention Dropout: 0.00033473968505859375
Post-attention residual: 0.00011277198791503906
LN2: 0.00011491775512695312
MLP_h_4h: 0.0036525726318359375
MLP_4h_h: 0.0017154216766357422
Post-MLP residual: 0.0003337860107421875
Attention layer time: 0.0171205997467041
LN1: 0.0001308917999267578
QKV Transform: 0.002558469772338867
using-flash
Attention linproj: 0.0005364418029785156
Post-attention Dropout: 0.0003464221954345703
Post-attention residual: 0.00011348724365234375
LN2: 0.0001163482666015625
MLP_h_4h: 0.003607034683227539
MLP_4h_h: 0.0017247200012207031
Post-MLP residual: 0.00033354759216308594
Attention layer time: 0.017153263092041016
LN1: 0.00013017654418945312
QKV Transform: 0.0025653839111328125
using-flash
Attention linproj: 0.00052642822265625
Post-attention Dropout: 0.00033593177795410156
Post-attention residual: 0.00011539459228515625
LN2: 0.00011873245239257812
MLP_h_4h: 0.003629446029663086
MLP_4h_h: 0.001722097396850586
Post-MLP residual: 0.0003380775451660156
Attention layer time: 0.017186403274536133
LN1: 0.00014972686767578125
QKV Transform: 0.0025887489318847656
using-flash
Attention linproj: 0.0005285739898681641
Post-attention Dropout: 0.0003387928009033203
Post-attention residual: 0.00011301040649414062
LN2: 0.00011491775512695312
MLP_h_4h: 0.003644227981567383
MLP_4h_h: 0.001718759536743164
Post-MLP residual: 0.00033736228942871094
Attention layer time: 0.01721048355102539
LN1: 0.0001270771026611328
QKV Transform: 0.0026314258575439453
using-flash
Attention linproj: 0.0005290508270263672
Post-attention Dropout: 0.00033664703369140625
Post-attention residual: 0.00011348724365234375
LN2: 0.00011491775512695312
MLP_h_4h: 0.003645658493041992
MLP_4h_h: 0.00171661376953125
Post-MLP residual: 0.00033664703369140625
Attention layer time: 0.01719498634338379
LN1: 0.0001316070556640625
QKV Transform: 0.0025815963745117188
using-flash
Attention linproj: 0.0005359649658203125
Post-attention Dropout: 0.0003464221954345703
Post-attention residual: 0.00011348724365234375
LN2: 0.00011658668518066406
MLP_h_4h: 0.003615140914916992
MLP_4h_h: 0.0017242431640625
Post-MLP residual: 0.00033402442932128906
Attention layer time: 0.017175674438476562
LN1: 0.0001308917999267578
QKV Transform: 0.0024220943450927734
using-flash
Attention linproj: 0.0005261898040771484
Post-attention Dropout: 0.000335693359375
Post-attention residual: 0.00011682510375976562
LN2: 0.0001227855682373047
MLP_h_4h: 0.0025916099548339844
MLP_4h_h: 0.0017180442810058594
Post-MLP residual: 0.0003371238708496094
Attention layer time: 0.015977144241333008
LN1: 0.0001316070556640625
QKV Transform: 0.0025839805603027344
using-flash
Attention linproj: 0.0005404949188232422
Post-attention Dropout: 0.0003361701965332031
Post-attention residual: 0.0001125335693359375
LN2: 0.00011610984802246094
MLP_h_4h: 0.003645658493041992
MLP_4h_h: 0.0017201900482177734
Post-MLP residual: 0.00033593177795410156
Attention layer time: 0.017177581787109375
LN1: 0.0001289844512939453
QKV Transform: 0.0025513172149658203
using-flash
Attention linproj: 0.0005478858947753906
Post-attention Dropout: 0.00034427642822265625
Post-attention residual: 0.00012421607971191406
LN2: 0.00011706352233886719
MLP_h_4h: 0.0036025047302246094
MLP_4h_h: 0.0017137527465820312
Post-MLP residual: 0.0003364086151123047
Attention layer time: 0.01714015007019043
LN1: 0.00013399124145507812
QKV Transform: 0.0024688243865966797
using-flash
Attention linproj: 0.0005276203155517578
Post-attention Dropout: 0.00033926963806152344
Post-attention residual: 0.00011491775512695312
LN2: 0.00011801719665527344
MLP_h_4h: 0.0036344528198242188
MLP_4h_h: 0.001729726791381836
Post-MLP residual: 0.000335693359375
Attention layer time: 0.017087936401367188
LN1: 0.0001289844512939453
QKV Transform: 0.002614736557006836
using-flash
Attention linproj: 0.00052642822265625
Post-attention Dropout: 0.000335693359375
Post-attention residual: 0.00011372566223144531
LN2: 0.00011491775512695312
MLP_h_4h: 0.003648996353149414
MLP_4h_h: 0.0017192363739013672
Post-MLP residual: 0.0003418922424316406
Attention layer time: 0.017212629318237305
LN1: 0.0001316070556640625
QKV Transform: 0.002590179443359375
using-flash
Attention linproj: 0.0005245208740234375
Post-attention Dropout: 0.0003380775451660156
Post-attention residual: 0.00011372566223144531
LN2: 0.00011563301086425781
MLP_h_4h: 0.0036444664001464844
MLP_4h_h: 0.001718282699584961
Post-MLP residual: 0.0003368854522705078
Attention layer time: 0.01718282699584961
LN1: 0.00012946128845214844
QKV Transform: 0.0025849342346191406
using-flash
Attention linproj: 0.0005331039428710938
Post-attention Dropout: 0.0003452301025390625
Post-attention residual: 0.00011444091796875
LN2: 0.00011610984802246094
MLP_h_4h: 0.0036237239837646484
MLP_4h_h: 0.0017228126525878906
Post-MLP residual: 0.0003337860107421875
Attention layer time: 0.017178773880004883
LN1: 0.00013375282287597656
QKV Transform: 0.0025544166564941406
using-flash
Attention linproj: 0.0005295276641845703
Post-attention Dropout: 0.00034546852111816406
Post-attention residual: 0.00011372566223144531
LN2: 0.00011730194091796875
MLP_h_4h: 0.0036270618438720703
MLP_4h_h: 0.0017178058624267578
Post-MLP residual: 0.0003361701965332031
Attention layer time: 0.017152786254882812
LN1: 0.0001285076141357422
QKV Transform: 0.0025975704193115234
using-flash
Attention linproj: 0.0005257129669189453
Post-attention Dropout: 0.0003364086151123047
Post-attention residual: 0.00011420249938964844
LN2: 0.00011491775512695312
MLP_h_4h: 0.0036373138427734375
MLP_4h_h: 0.0017189979553222656
Post-MLP residual: 0.0003399848937988281
Attention layer time: 0.017198801040649414
LN1: 0.00013113021850585938
QKV Transform: 0.0025162696838378906
using-flash
Attention linproj: 0.0005357265472412109
Post-attention Dropout: 0.0003402233123779297
Post-attention residual: 0.00011515617370605469
LN2: 0.00011587142944335938
MLP_h_4h: 0.0036399364471435547
MLP_4h_h: 0.0017194747924804688
Post-MLP residual: 0.0003383159637451172
Attention layer time: 0.017127275466918945
LN1: 0.00012969970703125
QKV Transform: 0.0023162364959716797
using-flash
Attention linproj: 0.0005240440368652344
Post-attention Dropout: 0.0003457069396972656
Post-attention residual: 0.00011467933654785156
LN2: 0.00011730194091796875
MLP_h_4h: 0.0036301612854003906
MLP_4h_h: 0.0017387866973876953
Post-MLP residual: 0.0003345012664794922
Attention layer time: 0.01692938804626465
LN1: 0.0001342296600341797
QKV Transform: 0.0025026798248291016
using-flash
Attention linproj: 0.0005316734313964844
Post-attention Dropout: 0.00033855438232421875
Post-attention residual: 0.00011420249938964844
LN2: 0.00011754035949707031
MLP_h_4h: 0.0036399364471435547
MLP_4h_h: 0.0017192363739013672
Post-MLP residual: 0.00033736228942871094
Attention layer time: 0.01711416244506836
LN1: 0.00012803077697753906
QKV Transform: 0.002608060836791992
using-flash
Attention linproj: 0.0005280971527099609
Post-attention Dropout: 0.0003337860107421875
Post-attention residual: 0.0001125335693359375
LN2: 0.00011420249938964844
MLP_h_4h: 0.004669904708862305
MLP_4h_h: 0.0017435550689697266
Post-MLP residual: 0.000362396240234375
Attention layer time: 0.018273115158081055
LN1: 0.0001418590545654297
QKV Transform: 0.0025827884674072266
using-flash
Attention linproj: 0.0005278587341308594
Post-attention Dropout: 0.0003402233123779297
Post-attention residual: 0.00011539459228515625
LN2: 0.00011610984802246094
MLP_h_4h: 0.0036437511444091797
MLP_4h_h: 0.0017180442810058594
Post-MLP residual: 0.0003390312194824219
Attention layer time: 0.01720404624938965
LN1: 0.0001285076141357422
QKV Transform: 0.002640247344970703
using-flash
Attention linproj: 0.0005342960357666016
Post-attention Dropout: 0.0003337860107421875
Post-attention residual: 0.00011301040649414062
LN2: 0.00011587142944335938
MLP_h_4h: 0.002604246139526367
MLP_4h_h: 0.0017228126525878906
Post-MLP residual: 0.0003352165222167969
Attention layer time: 0.01620006561279297
LN1: 0.00013399124145507812
QKV Transform: 0.002541065216064453
using-flash
Attention linproj: 0.0005283355712890625
Post-attention Dropout: 0.0003376007080078125
Post-attention residual: 0.00011324882507324219
LN2: 0.00011897087097167969
MLP_h_4h: 0.003621816635131836
MLP_4h_h: 0.0017178058624267578
Post-MLP residual: 0.00033593177795410156
Attention layer time: 0.017140865325927734
LN1: 0.0001277923583984375
QKV Transform: 0.0026264190673828125
using-flash
Attention linproj: 0.0005259513854980469
Post-attention Dropout: 0.0003352165222167969
Post-attention residual: 0.00011348724365234375
LN2: 0.00011467933654785156
MLP_h_4h: 0.0036509037017822266
MLP_4h_h: 0.0017168521881103516
Post-MLP residual: 0.0003387928009033203
Attention layer time: 0.017214298248291016
LN1: 0.00014519691467285156
QKV Transform: 0.0024824142456054688
using-flash
Attention linproj: 0.0005347728729248047
Post-attention Dropout: 0.0003581047058105469
Post-attention residual: 0.00011348724365234375
LN2: 0.00011706352233886719
MLP_h_4h: 0.0035867691040039062
MLP_4h_h: 0.0017197132110595703
Post-MLP residual: 0.0003337860107421875
Attention layer time: 0.0170896053314209
LN1: 0.0001285076141357422
QKV Transform: 0.0025482177734375
using-flash
Attention linproj: 0.0005373954772949219
Post-attention Dropout: 0.00034332275390625
Post-attention residual: 0.00011539459228515625
LN2: 0.00012087821960449219
MLP_h_4h: 0.0036232471466064453
MLP_4h_h: 0.0017228126525878906
Post-MLP residual: 0.00033402442932128906
Attention layer time: 0.017143726348876953
LN1: 0.0001342296600341797
QKV Transform: 0.002582550048828125
using-flash
Attention linproj: 0.0005290508270263672
Post-attention Dropout: 0.0003376007080078125
Post-attention residual: 0.00011372566223144531
LN2: 0.00013518333435058594
MLP_h_4h: 0.0036249160766601562
MLP_4h_h: 0.0017185211181640625
Post-MLP residual: 0.0003383159637451172
Attention layer time: 0.017189741134643555
LN1: 0.0001285076141357422
QKV Transform: 0.0026166439056396484
using-flash
Attention linproj: 0.0005295276641845703
Post-attention Dropout: 0.00033664703369140625
Post-attention residual: 0.00011444091796875
LN2: 0.00011563301086425781
MLP_h_4h: 0.0036406517028808594
MLP_4h_h: 0.0017175674438476562
Post-MLP residual: 0.0003402233123779297
Attention layer time: 0.017211198806762695
LN1: 0.00013065338134765625
QKV Transform: 0.0025904178619384766
using-flash
Attention linproj: 0.0005354881286621094
Post-attention Dropout: 0.00033783912658691406
Post-attention residual: 0.00011301040649414062
LN2: 0.00011563301086425781
MLP_h_4h: 0.0036482810974121094
MLP_4h_h: 0.001720428466796875
Post-MLP residual: 0.0003345012664794922
Attention layer time: 0.017190217971801758
LN1: 0.0001285076141357422
QKV Transform: 0.0025148391723632812
using-flash
Attention linproj: 0.0005426406860351562
Post-attention Dropout: 0.00034546852111816406
Post-attention residual: 0.00011348724365234375
LN2: 0.00011610984802246094
MLP_h_4h: 0.003614187240600586
MLP_4h_h: 0.001722097396850586
Post-MLP residual: 0.0003345012664794922
Attention layer time: 0.0171051025390625
LN1: 0.000133514404296875
QKV Transform: 0.0024602413177490234
using-flash
Attention linproj: 0.0005271434783935547
Post-attention Dropout: 0.0003387928009033203
Post-attention residual: 0.00011444091796875
LN2: 0.000125885009765625
MLP_h_4h: 0.0025870800018310547
MLP_4h_h: 0.0017087459564208984
Post-MLP residual: 0.0003399848937988281
Attention layer time: 0.01601719856262207
LN1: 0.00012755393981933594
QKV Transform: 0.002608776092529297
using-flash
Attention linproj: 0.0005335807800292969
Post-attention Dropout: 0.00033473968505859375
Post-attention residual: 0.00011372566223144531
LN2: 0.00011420249938964844
MLP_h_4h: 0.0036427974700927734
MLP_4h_h: 0.0017180442810058594
Post-MLP residual: 0.0003330707550048828
Attention layer time: 0.01719498634338379
LN1: 0.0001327991485595703
QKV Transform: 0.002503633499145508
using-flash
Attention linproj: 0.0005295276641845703
Post-attention Dropout: 0.000347137451171875
Post-attention residual: 0.00011301040649414062
LN2: 0.00011706352233886719
MLP_h_4h: 0.003625631332397461
MLP_4h_h: 0.001725912094116211
Post-MLP residual: 0.00033736228942871094
Attention layer time: 0.01711273193359375
LN1: 0.00013399124145507812
QKV Transform: 0.0024416446685791016
using-flash
Attention linproj: 0.0005300045013427734
Post-attention Dropout: 0.00033545494079589844
Post-attention residual: 0.00011205673217773438
LN2: 0.00011444091796875
MLP_h_4h: 0.003645658493041992
MLP_4h_h: 0.0017197132110595703
Post-MLP residual: 0.0003485679626464844
Attention layer time: 0.01705646514892578
LN1: 0.00013136863708496094
QKV Transform: 0.0025980472564697266
using-flash
Attention linproj: 0.000530242919921875
Post-attention Dropout: 0.00033664703369140625
Post-attention residual: 0.00011229515075683594
LN2: 0.00011491775512695312
MLP_h_4h: 0.0036592483520507812
MLP_4h_h: 0.0017194747924804688
Post-MLP residual: 0.0003390312194824219
Attention layer time: 0.017206430435180664
LN1: 0.00012826919555664062
QKV Transform: 0.002568483352661133
using-flash
Attention linproj: 0.0005345344543457031
Post-attention Dropout: 0.0003476142883300781
Post-attention residual: 0.00011277198791503906
LN2: 0.00011515617370605469
MLP_h_4h: 0.0036318302154541016
MLP_4h_h: 0.0017223358154296875
Post-MLP residual: 0.00033473968505859375
Attention layer time: 0.01715850830078125
LN1: 0.000133514404296875
QKV Transform: 0.0025701522827148438
using-flash
Attention linproj: 0.0005314350128173828
Post-attention Dropout: 0.000347137451171875
Post-attention residual: 0.00011277198791503906
LN2: 0.00011801719665527344
MLP_h_4h: 0.0036215782165527344
MLP_4h_h: 0.0017232894897460938
Post-MLP residual: 0.00033473968505859375
Attention layer time: 0.01715087890625
LN1: 0.0001308917999267578
QKV Transform: 0.0025877952575683594
using-flash
Attention linproj: 0.0005273818969726562
Post-attention Dropout: 0.000335693359375
Post-attention residual: 0.00011181831359863281
LN2: 0.00011491775512695312
MLP_h_4h: 0.00365447998046875
MLP_4h_h: 0.00171661376953125
Post-MLP residual: 0.00033783912658691406
Attention layer time: 0.01717972755432129
LN1: 0.0001347064971923828
QKV Transform: 0.0025587081909179688
using-flash
Attention linproj: 0.0005278587341308594
Post-attention Dropout: 0.0003380775451660156
Post-attention residual: 0.00011396408081054688
LN2: 0.00011491775512695312
MLP_h_4h: 0.0036313533782958984
MLP_4h_h: 0.0017189979553222656
Post-MLP residual: 0.00033974647521972656
Attention layer time: 0.017163515090942383
LN1: 0.00012755393981933594
QKV Transform: 0.0025229454040527344
using-flash
Attention linproj: 0.0005345344543457031
Post-attention Dropout: 0.0003383159637451172
Post-attention residual: 0.00011277198791503906
LN2: 0.00011467933654785156
MLP_h_4h: 0.0036530494689941406
MLP_4h_h: 0.0017201900482177734
Post-MLP residual: 0.0003361701965332031
Attention layer time: 0.017110824584960938
LN1: 0.00013208389282226562
QKV Transform: 0.0023298263549804688
using-flash
Attention linproj: 0.0005297660827636719
Post-attention Dropout: 0.0003502368927001953
Post-attention residual: 0.00011420249938964844
LN2: 0.000118255615234375
MLP_h_4h: 0.003618478775024414
MLP_4h_h: 0.0017235279083251953
Post-MLP residual: 0.0003325939178466797
Attention layer time: 0.01693129539489746
LN1: 0.0001304149627685547
QKV Transform: 0.002622842788696289
using-flash
Attention linproj: 0.0005316734313964844
Post-attention Dropout: 0.0003345012664794922
Post-attention residual: 0.0001125335693359375
LN2: 0.00011467933654785156
MLP_h_4h: 0.003643035888671875
MLP_4h_h: 0.0017185211181640625
Post-MLP residual: 0.00033736228942871094
Attention layer time: 0.017222881317138672
LN1: 0.0001316070556640625
QKV Transform: 0.002604961395263672
using-flash
Attention linproj: 0.0005290508270263672
Post-attention Dropout: 0.0003345012664794922
Post-attention residual: 0.00011277198791503906
LN2: 0.00011610984802246094
MLP_h_4h: 0.0036530494689941406
MLP_4h_h: 0.0017256736755371094
Post-MLP residual: 0.0003387928009033203
Attention layer time: 0.017220020294189453
LN1: 0.00012993812561035156
QKV Transform: 0.002517223358154297
using-flash
Attention linproj: 0.0005335807800292969
Post-attention Dropout: 0.0003399848937988281
Post-attention residual: 0.00011396408081054688
LN2: 0.0001163482666015625
MLP_h_4h: 0.0036377906799316406
MLP_4h_h: 0.0017199516296386719
Post-MLP residual: 0.0003345012664794922
Attention layer time: 0.01710820198059082
LN1: 0.00013303756713867188
QKV Transform: 0.002516031265258789
using-flash
Attention linproj: 0.0005297660827636719
Post-attention Dropout: 0.0003476142883300781
Post-attention residual: 0.00011396408081054688
LN2: 0.00011682510375976562
MLP_h_4h: 0.003609180450439453
MLP_4h_h: 0.0017237663269042969
Post-MLP residual: 0.00033402442932128906
Attention layer time: 0.0171205997467041
LN1: 0.00012993812561035156
QKV Transform: 0.0025856494903564453
using-flash
Attention linproj: 0.0005273818969726562
Post-attention Dropout: 0.0003349781036376953
Post-attention residual: 0.00011277198791503906
LN2: 0.00013518333435058594
MLP_h_4h: 0.003608226776123047
MLP_4h_h: 0.0017175674438476562
Post-MLP residual: 0.0003380775451660156
Attention layer time: 0.017187833786010742
LN1: 0.00013184547424316406
QKV Transform: 0.002613544464111328
using-flash
Attention linproj: 0.0005326271057128906
Post-attention Dropout: 0.0003380775451660156
Post-attention residual: 0.00011372566223144531
LN2: 0.00011563301086425781
MLP_h_4h: 0.0036640167236328125
MLP_4h_h: 0.0017175674438476562
Post-MLP residual: 0.0003554821014404297
Attention layer time: 0.01724982261657715
LN1: 0.00012755393981933594
QKV Transform: 0.0024743080139160156
using-flash
Attention linproj: 0.0005412101745605469
Post-attention Dropout: 0.0003387928009033203
Post-attention residual: 0.0001125335693359375
LN2: 0.00011563301086425781
MLP_h_4h: 0.0036339759826660156
MLP_4h_h: 0.0017175674438476562
Post-MLP residual: 0.0003330707550048828
Attention layer time: 0.017060041427612305
LN1: 0.00013184547424316406
QKV Transform: 0.0025115013122558594
using-flash
Attention linproj: 0.0005304813385009766
Post-attention Dropout: 0.00036454200744628906
Post-attention residual: 0.00011324882507324219
LN2: 0.00011658668518066406
MLP_h_4h: 0.0036172866821289062
MLP_4h_h: 0.0017240047454833984
Post-MLP residual: 0.00033354759216308594
Attention layer time: 0.017115354537963867
LN1: 0.00013017654418945312
QKV Transform: 0.002623319625854492
using-flash
Attention linproj: 0.0005276203155517578
Post-attention Dropout: 0.0003368854522705078
Post-attention residual: 0.00011372566223144531
LN2: 0.00011587142944335938
MLP_h_4h: 0.0036458969116210938
MLP_4h_h: 0.0017175674438476562
Post-MLP residual: 0.00034427642822265625
Attention layer time: 0.017232418060302734
LN1: 0.0001308917999267578
QKV Transform: 0.002599954605102539
using-flash
Attention linproj: 0.0005321502685546875
Post-attention Dropout: 0.00033855438232421875
Post-attention residual: 0.0001125335693359375
LN2: 0.00011515617370605469
MLP_h_4h: 0.0036530494689941406
MLP_4h_h: 0.001718282699584961
Post-MLP residual: 0.0003371238708496094
Attention layer time: 0.017213106155395508
LN1: 0.0001277923583984375
QKV Transform: 0.0025625228881835938
using-flash
Attention linproj: 0.0005350112915039062
Post-attention Dropout: 0.0003437995910644531
Post-attention residual: 0.00011348724365234375
LN2: 0.00011491775512695312
MLP_h_4h: 0.0036394596099853516
MLP_4h_h: 0.001711130142211914
Post-MLP residual: 0.0003345012664794922
Attention layer time: 0.017137527465820312
LN1: 0.0001316070556640625
QKV Transform: 0.0025472640991210938
using-flash
Attention linproj: 0.000530242919921875
Post-attention Dropout: 0.0003478527069091797
Post-attention residual: 0.00011420249938964844
LN2: 0.00011706352233886719
MLP_h_4h: 0.003632068634033203
MLP_4h_h: 0.0017237663269042969
Post-MLP residual: 0.0003333091735839844
Attention layer time: 0.017145156860351562
LN1: 0.0001308917999267578
QKV Transform: 0.0024955272674560547
using-flash
Attention linproj: 0.0005276203155517578
Post-attention Dropout: 0.0003376007080078125
Post-attention residual: 0.0001125335693359375
LN2: 0.00011491775512695312
MLP_h_4h: 0.002607107162475586
MLP_4h_h: 0.0017170906066894531
Post-MLP residual: 0.0003387928009033203
Attention layer time: 0.01605367660522461
LN1: 0.00013136863708496094
QKV Transform: 0.0025556087493896484
using-flash
Attention linproj: 0.0005359649658203125
Post-attention Dropout: 0.0003445148468017578
Post-attention residual: 0.00011277198791503906
LN2: 0.00011515617370605469
MLP_h_4h: 0.003628969192504883
MLP_4h_h: 0.0017237663269042969
Post-MLP residual: 0.00035309791564941406
Attention layer time: 0.017169713973999023
LN1: 0.00012969970703125
QKV Transform: 0.0025093555450439453
using-flash
Attention linproj: 0.0005280971527099609
Post-attention Dropout: 0.0003485679626464844
Post-attention residual: 0.00011467933654785156
LN2: 0.00011682510375976562
MLP_h_4h: 0.003628253936767578
MLP_4h_h: 0.0017228126525878906
Post-MLP residual: 0.0003368854522705078
Attention layer time: 0.017099618911743164
LN1: 0.0001342296600341797
QKV Transform: 0.0024857521057128906
using-flash
Attention linproj: 0.0005273818969726562
Post-attention Dropout: 0.0003371238708496094
Post-attention residual: 0.00011324882507324219
LN2: 0.00011420249938964844
MLP_h_4h: 0.0036590099334716797
MLP_4h_h: 0.0017192363739013672
Post-MLP residual: 0.0003399848937988281
Attention layer time: 0.017116785049438477
LN1: 0.00012755393981933594
QKV Transform: 0.002593517303466797
using-flash
Attention linproj: 0.0005297660827636719
Post-attention Dropout: 0.0003352165222167969
Post-attention residual: 0.00011301040649414062
LN2: 0.00011444091796875
MLP_h_4h: 0.003646373748779297
MLP_4h_h: 0.0017309188842773438
Post-MLP residual: 0.0003376007080078125
Attention layer time: 0.017189502716064453
LN1: 0.0001308917999267578
QKV Transform: 0.002565145492553711
using-flash
Attention linproj: 0.0005352497100830078
Post-attention Dropout: 0.0003457069396972656
Post-attention residual: 0.00011396408081054688
LN2: 0.00011539459228515625
MLP_h_4h: 0.0036077499389648438
MLP_4h_h: 0.0017213821411132812
Post-MLP residual: 0.0003337860107421875
Attention layer time: 0.017163515090942383
LN1: 0.00013065338134765625
QKV Transform: 0.002574920654296875
using-flash
Attention linproj: 0.0005273818969726562
Post-attention Dropout: 0.0003447532653808594
Post-attention residual: 0.00011444091796875
LN2: 0.00011706352233886719
MLP_h_4h: 0.003612518310546875
MLP_4h_h: 0.0017116069793701172
Post-MLP residual: 0.0003333091735839844
Attention layer time: 0.017162561416625977
LN1: 0.00013303756713867188
QKV Transform: 0.0025925636291503906
using-flash
Attention linproj: 0.0005304813385009766
Post-attention Dropout: 0.0003376007080078125
Post-attention residual: 0.00011181831359863281
LN2: 0.00011467933654785156
MLP_h_4h: 0.003647327423095703
MLP_4h_h: 0.0017192363739013672
Post-MLP residual: 0.0003407001495361328
Attention layer time: 0.017181396484375
LN1: 0.00012826919555664062
QKV Transform: 0.0025899410247802734
using-flash
Attention linproj: 0.0005285739898681641
Post-attention Dropout: 0.000335693359375
Post-attention residual: 0.00011324882507324219
LN2: 0.00011587142944335938
MLP_h_4h: 0.0036597251892089844
MLP_4h_h: 0.0017180442810058594
Post-MLP residual: 0.00035452842712402344
Attention layer time: 0.01720118522644043
LN1: 0.0001323223114013672
QKV Transform: 0.0024678707122802734
using-flash
Attention linproj: 0.0005331039428710938
Post-attention Dropout: 0.00034356117248535156
Post-attention residual: 0.00011467933654785156
LN2: 0.00011420249938964844
MLP_h_4h: 0.003633737564086914
MLP_4h_h: 0.0017218589782714844
Post-MLP residual: 0.0003352165222167969
Attention layer time: 0.017070293426513672
LN1: 0.00013017654418945312
QKV Transform: 0.0025463104248046875
using-flash
Attention linproj: 0.00052642822265625
Post-attention Dropout: 0.0003573894500732422
Post-attention residual: 0.00011491775512695312
LN2: 0.00011873245239257812
MLP_h_4h: 0.003612518310546875
MLP_4h_h: 0.0017642974853515625
Post-MLP residual: 0.000335693359375
Attention layer time: 0.017187833786010742
LN1: 0.000133514404296875
QKV Transform: 0.002574920654296875
using-flash
Attention linproj: 0.0005276203155517578
Post-attention Dropout: 0.0003383159637451172
Post-attention residual: 0.00011277198791503906
LN2: 0.00011658668518066406
MLP_h_4h: 0.0038411617279052734
MLP_4h_h: 0.0017189979553222656
Post-MLP residual: 0.000339508056640625
Attention layer time: 0.017403364181518555
LN1: 0.0001347064971923828
QKV Transform: 0.002408266067504883
using-flash
Attention linproj: 0.0005397796630859375
Post-attention Dropout: 0.000335693359375
Post-attention residual: 0.00011301040649414062
LN2: 0.0001163482666015625
MLP_h_4h: 0.0036373138427734375
MLP_4h_h: 0.0017189979553222656
Post-MLP residual: 0.0003466606140136719
Attention layer time: 0.017009258270263672
LN1: 0.00013184547424316406
QKV Transform: 0.0025594234466552734
using-flash
Attention linproj: 0.0005357265472412109
Post-attention Dropout: 0.0003426074981689453
Post-attention residual: 0.00011324882507324219
LN2: 0.00011491775512695312
MLP_h_4h: 0.0036284923553466797
MLP_4h_h: 0.0017502307891845703
Post-MLP residual: 0.0003364086151123047
Attention layer time: 0.017214298248291016
LN1: 0.00014162063598632812
QKV Transform: 0.0024871826171875
using-flash
Attention linproj: 0.0005278587341308594
Post-attention Dropout: 0.00034427642822265625
Post-attention residual: 0.00011515617370605469
LN2: 0.00011897087097167969
MLP_h_4h: 0.0036211013793945312
MLP_4h_h: 0.0017216205596923828
Post-MLP residual: 0.0003337860107421875
Attention layer time: 0.01708507537841797
LN1: 0.00013446807861328125
QKV Transform: 0.002631664276123047
using-flash
Attention linproj: 0.0005283355712890625
Post-attention Dropout: 0.00033664703369140625
Post-attention residual: 0.00011301040649414062
LN2: 0.00011515617370605469
MLP_h_4h: 0.003646373748779297
MLP_4h_h: 0.0017192363739013672
Post-MLP residual: 0.00034046173095703125
Attention layer time: 0.01726388931274414
LN1: 0.00012826919555664062
QKV Transform: 0.002591848373413086
using-flash
Attention linproj: 0.0005283355712890625
Post-attention Dropout: 0.00033593177795410156
Post-attention residual: 0.00011301040649414062
LN2: 0.00011563301086425781
MLP_h_4h: 0.0036606788635253906
MLP_4h_h: 0.001708984375
Post-MLP residual: 0.00033783912658691406
Attention layer time: 0.017182111740112305
LN1: 0.000133514404296875
QKV Transform: 0.0022110939025878906
using-flash
Attention linproj: 0.0005352497100830078
Post-attention Dropout: 0.0003452301025390625
Post-attention residual: 0.00011372566223144531
LN2: 0.00011491775512695312
MLP_h_4h: 0.0036249160766601562
MLP_4h_h: 0.0017130374908447266
Post-MLP residual: 0.0003349781036376953
Attention layer time: 0.01680612564086914
LN1: 0.00013065338134765625
QKV Transform: 0.002521991729736328
using-flash
Attention linproj: 0.0005266666412353516
Post-attention Dropout: 0.00033855438232421875
Post-attention residual: 0.00011467933654785156
LN2: 0.00011944770812988281
MLP_h_4h: 0.00363922119140625
MLP_4h_h: 0.0017218589782714844
Post-MLP residual: 0.0003383159637451172
Attention layer time: 0.017119646072387695
LN1: 0.00013136863708496094
QKV Transform: 0.0026862621307373047
using-flash
Attention linproj: 0.0005273818969726562
Post-attention Dropout: 0.0003383159637451172
Post-attention residual: 0.00011372566223144531
LN2: 0.00011515617370605469
MLP_h_4h: 0.0025975704193115234
MLP_4h_h: 0.0017194747924804688
Post-MLP residual: 0.0003349781036376953
Attention layer time: 0.016231298446655273
LN1: 0.00012874603271484375
QKV Transform: 0.0025739669799804688
using-flash
Attention linproj: 0.0005474090576171875
Post-attention Dropout: 0.0003426074981689453
Post-attention residual: 0.00011420249938964844
LN2: 0.00011515617370605469
MLP_h_4h: 0.003619670867919922
MLP_4h_h: 0.0017232894897460938
Post-MLP residual: 0.000335693359375
Attention layer time: 0.017172813415527344
LN1: 0.00013446807861328125
QKV Transform: 0.002536296844482422
using-flash
Attention linproj: 0.0005283355712890625
Post-attention Dropout: 0.00034308433532714844
Post-attention residual: 0.0001266002655029297
LN2: 0.00011920928955078125
MLP_h_4h: 0.0025763511657714844
MLP_4h_h: 0.0017192363739013672
Post-MLP residual: 0.00034117698669433594
Attention layer time: 0.016106128692626953
LN1: 0.00012755393981933594
QKV Transform: 0.0026483535766601562
using-flash
Attention linproj: 0.0005228519439697266
Post-attention Dropout: 0.000335693359375
Post-attention residual: 0.00011372566223144531
LN2: 0.00011444091796875
MLP_h_4h: 0.003653287887573242
MLP_4h_h: 0.0017189979553222656
Post-MLP residual: 0.0003371238708496094
Attention layer time: 0.017233610153198242
LN1: 0.00013208389282226562
QKV Transform: 0.002486705780029297
using-flash
Attention linproj: 0.0005340576171875
Post-attention Dropout: 0.00034737586975097656
Post-attention residual: 0.00011348724365234375
LN2: 0.00011706352233886719
MLP_h_4h: 0.0036270618438720703
MLP_4h_h: 0.0017228126525878906
Post-MLP residual: 0.0003349781036376953
Attention layer time: 0.01709270477294922
LN1: 0.00013065338134765625
QKV Transform: 0.0024499893188476562
using-flash
Attention linproj: 0.0005261898040771484
Post-attention Dropout: 0.0003371238708496094
Post-attention residual: 0.00011396408081054688
LN2: 0.00011706352233886719
MLP_h_4h: 0.0036385059356689453
MLP_4h_h: 0.0017337799072265625
Post-MLP residual: 0.0003361701965332031
Attention layer time: 0.017059803009033203
LN1: 0.00013136863708496094
QKV Transform: 0.0026454925537109375
using-flash
Attention linproj: 0.0005280971527099609
Post-attention Dropout: 0.0003368854522705078
Post-attention residual: 0.00011205673217773438
LN2: 0.00011515617370605469
MLP_h_4h: 0.0025887489318847656
MLP_4h_h: 0.0017180442810058594
Post-MLP residual: 0.0003323554992675781
Attention layer time: 0.016197681427001953
LN1: 0.00012922286987304688
QKV Transform: 0.0024764537811279297
using-flash
Attention linproj: 0.0005238056182861328
Post-attention Dropout: 0.0003457069396972656
Post-attention residual: 0.00011348724365234375
LN2: 0.00011706352233886719
MLP_h_4h: 0.0036537647247314453
MLP_4h_h: 0.0017232894897460938
Post-MLP residual: 0.0003345012664794922
Attention layer time: 0.017074108123779297
LN1: 0.0001342296600341797
QKV Transform: 0.0025861263275146484
using-flash
Attention linproj: 0.0005278587341308594
Post-attention Dropout: 0.00033783912658691406
Post-attention residual: 0.0001227855682373047
LN2: 0.00011801719665527344
MLP_h_4h: 0.0036318302154541016
MLP_4h_h: 0.001718282699584961
Post-MLP residual: 0.00033593177795410156
Attention layer time: 0.017189979553222656
LN1: 0.00012731552124023438
QKV Transform: 0.0027055740356445312
using-flash
Attention linproj: 0.0005285739898681641
Post-attention Dropout: 0.0003361701965332031
Post-attention residual: 0.0001125335693359375
LN2: 0.00011491775512695312
MLP_h_4h: 0.002600431442260742
MLP_4h_h: 0.0017168521881103516
Post-MLP residual: 0.0003349781036376953
Attention layer time: 0.01623678207397461
LN1: 0.00013256072998046875
QKV Transform: 0.0024683475494384766
using-flash
Attention linproj: 0.0005400180816650391
Post-attention Dropout: 0.00034618377685546875
Post-attention residual: 0.00011467933654785156
LN2: 0.00011730194091796875
MLP_h_4h: 0.0036132335662841797
MLP_4h_h: 0.0017228126525878906
Post-MLP residual: 0.00033545494079589844
Attention layer time: 0.0170743465423584
LN1: 0.00013017654418945312
QKV Transform: 0.0025184154510498047
using-flash
Attention linproj: 0.0005276203155517578
Post-attention Dropout: 0.0003349781036376953
Post-attention residual: 0.00011277198791503906
LN2: 0.000133514404296875
MLP_h_4h: 0.0036325454711914062
MLP_4h_h: 0.0017178058624267578
Post-MLP residual: 0.00033664703369140625
Attention layer time: 0.017115354537963867
LN1: 0.00013113021850585938
QKV Transform: 0.0025610923767089844
using-flash
Attention linproj: 0.0005290508270263672
Post-attention Dropout: 0.0003364086151123047
Post-attention residual: 0.00011134147644042969
LN2: 0.00011515617370605469
MLP_h_4h: 0.0036497116088867188
MLP_4h_h: 0.001718759536743164
Post-MLP residual: 0.0003440380096435547
Attention layer time: 0.01717209815979004
LN1: 0.00012874603271484375
QKV Transform: 0.002619504928588867
using-flash
Attention linproj: 0.0005331039428710938
Post-attention Dropout: 0.0003368854522705078
Post-attention residual: 0.00011277198791503906
LN2: 0.00011563301086425781
MLP_h_4h: 0.0025942325592041016
MLP_4h_h: 0.0017242431640625
Post-MLP residual: 0.0003342628479003906
Attention layer time: 0.016166210174560547
Transformer duration (in seconds): 0.0190
Transformer throughput (in TFLOP/s): 76.926
========================================================================================================================
